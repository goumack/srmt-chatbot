"""
LexFin - Assistant IA Sp√©cialis√© Fiscal et Douanier (MODE RAG STRICT)
Assistant IA intelligent pour les contribuables s√©n√©galais
Focalis√© exclusivement sur les documents fiscaux et douaniers index√©s
Version optimis√©e - Mode RAG strict - R√©ponses bas√©es uniquement sur les documents
"""
import os
from flask import Flask, render_template_string, request, jsonify
import requests
import json
from typing import List, Dict, Optional
import chromadb
from chromadb.config import Settings
from dotenv import load_dotenv
import logging
import threading
import time
import hashlib
from pathlib import Path
from watchdog.observers import Observer
from watchdog.events import FileSystemEventHandler
from datetime import datetime
import re
from collections import Counter
import math

# Import du syst√®me hi√©rarchique V2.0 (import conditionnel pour √©viter circularit√©)
try:
    from systeme_hierarchique_v2 import HierarchieJuridiqueClient
    HIERARCHIE_AVAILABLE = True
except ImportError:
    HIERARCHIE_AVAILABLE = False
    HierarchieJuridiqueClient = None

# Configuration des logs
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Charger la configuration
load_dotenv()

class BM25:
    """Impl√©mentation simple de BM25 pour recherche textuelle"""
    def __init__(self, k1=1.5, b=0.75):
        self.k1 = k1
        self.b = b
        
    def tokenize(self, text):
        """Tokenize le texte en mots"""
        text = text.lower()
        # Garder les chiffres et lettres
        tokens = re.findall(r'\b\w+\b', text)
        return tokens
    
    def compute_idf(self, documents):
        """Calcule l'IDF pour chaque terme"""
        N = len(documents)
        idf = {}
        
        # Compter dans combien de documents chaque terme appara√Æt
        df = Counter()
        for doc in documents:
            tokens = set(self.tokenize(doc))
            df.update(tokens)
        
        # Calculer IDF
        for term, freq in df.items():
            idf[term] = math.log((N - freq + 0.5) / (freq + 0.5) + 1)
        
        return idf
    
    def score(self, query, document, avg_doc_len, idf):
        """Calcule le score BM25 pour un document"""
        query_tokens = self.tokenize(query)
        doc_tokens = self.tokenize(document)
        doc_len = len(doc_tokens)
        
        score = 0.0
        doc_term_freq = Counter(doc_tokens)
        
        for term in query_tokens:
            if term not in idf:
                continue
                
            tf = doc_term_freq.get(term, 0)
            
            # BM25 formula
            numerator = tf * (self.k1 + 1)
            denominator = tf + self.k1 * (1 - self.b + self.b * (doc_len / avg_doc_len))
            
            score += idf[term] * (numerator / denominator)
        
        return score

class LexFinConfig:
    """Configuration LexFin - Assistant Fiscal et Douanier"""
    OLLAMA_BASE_URL = os.getenv("OLLAMA_BASE_URL", "https://ollamaaccel-chatbotaccel.apps.senum.heritage.africa")
    OLLAMA_CHAT_MODEL = os.getenv("OLLAMA_CHAT_MODEL", "mistral:7b")
    OLLAMA_EMBEDDING_MODEL = os.getenv("OLLAMA_EMBEDDING_MODEL", "nomic-embed-text")
    CHROMA_PERSIST_DIRECTORY = os.getenv("CHROMA_PERSIST_DIRECTORY", "./chroma_db")
    WATCH_DIRECTORY = os.getenv("WATCH_DIRECTORY", "./documents")  # R√©pertoire √† surveiller
    SUPPORTED_EXTENSIONS = ['.txt', '.pdf', '.docx', '.md', '.json', '.csv', '.odt', '.xlsx', '.xls']

class DocumentWatcherHandler(FileSystemEventHandler):
    """Gestionnaire de surveillance automatique en arri√®re-plan"""
    
    def __init__(self, lexfin_client):
        self.lexfin_client = lexfin_client
        self.processing_queue = []
        self.last_processed = {}
        super().__init__()
    
    def on_created(self, event):
        """Nouveau fichier cr√©√© - Indexation automatique en arri√®re-plan"""
        if not event.is_directory:
            file_path = event.src_path
            
        # Ignorer les fichiers temporaires
        if Path(file_path).name.startswith(('~$', '.')):
            return
            
        logger.info(f"üìÅ [AUTO] Nouveau fichier d√©tect√©: {Path(file_path).name}")
        
        # Traitement asynchrone en arri√®re-plan
        import threading
        def delayed_process():
            try:
                time.sleep(2)  # Attendre que le fichier soit compl√®tement √©crit
                if self.lexfin_client.is_supported_file(file_path):
                    self.lexfin_client.process_new_file_background(file_path)
                    logger.info(f" [AUTO] Fichier index√© automatiquement: {Path(file_path).name}")
                else:
                    logger.debug(f"‚è≠ [AUTO] Fichier ignor√© (format non support√©): {Path(file_path).name}")
            except Exception as e:
                logger.error(f" [AUTO] Erreur indexation automatique {Path(file_path).name}: {e}")
        
        # Lancer en thread s√©par√© pour ne pas bloquer le syst√®me
        thread = threading.Thread(target=delayed_process, daemon=True)
        thread.start()
    
    def on_modified(self, event):
        """Fichier modifi√© - R√©indexation automatique si n√©cessaire"""
        if not event.is_directory:
            file_path = event.src_path
            
            # Ignorer les fichiers temporaires et √©viter les doublons rapides
            if Path(file_path).name.startswith(('~$', '.')):
                return
                
            # √âviter le traitement en boucle (limitation par temps)
            current_time = time.time()
            if file_path in self.last_processed:
                if current_time - self.last_processed[file_path] < 5:  # 5 secondes minimum
                    return
            
            self.last_processed[file_path] = current_time
            logger.info(f"[AUTO] Modification d√©tect√©e: {Path(file_path).name}")
            
            # Traitement asynchrone en arri√®re-plan
            import threading
            def delayed_reprocess():
                try:
                    time.sleep(1)  # Attendre la fin de l'√©criture
                    if self.lexfin_client.is_supported_file(file_path):
                        self.lexfin_client.process_modified_file_background(file_path)
                        logger.info(f" [AUTO] Fichier r√©index√© automatiquement: {Path(file_path).name}")
                except Exception as e:
                    logger.error(f" [AUTO] Erreur r√©indexation automatique {Path(file_path).name}: {e}")
            
            # Lancer en thread s√©par√©
            thread = threading.Thread(target=delayed_reprocess, daemon=True)
            thread.start()

class ConversationManager:
    """Gestionnaire de conversations avec m√©moire contextuelle pour discussions intelligentes"""
    
    def __init__(self, max_history_length=10):
        self.conversations = {}  # {conversation_id: conversation_data}
        self.max_history_length = max_history_length
        
    def create_conversation(self, conversation_id=None):
        """Cr√©e une nouvelle conversation"""
        if conversation_id is None:
            conversation_id = str(int(time.time()))
        
        self.conversations[conversation_id] = {
            'id': conversation_id,
            'created_at': time.time(),
            'last_updated': time.time(),
            'history': [],  # [{'role': 'user'/'assistant', 'content': str, 'timestamp': float, 'references': []}]
            'context_keywords': set(),  # Mots-cl√©s extraits pour le contexte
            'current_topics': [],  # Sujets actuels de discussion
        }
        
        logger.info(f"üó®Ô∏è Nouvelle conversation cr√©√©e: {conversation_id}")
        return conversation_id
    
    def add_message(self, conversation_id, role, content, references=None):
        """Ajoute un message √† l'historique de conversation"""
        if conversation_id not in self.conversations:
            conversation_id = self.create_conversation(conversation_id)
        
        conversation = self.conversations[conversation_id]
        
        message = {
            'role': role,
            'content': content,
            'timestamp': time.time(),
            'references': references or []
        }
        
        conversation['history'].append(message)
        conversation['last_updated'] = time.time()
        
        # Limiter la taille de l'historique
        if len(conversation['history']) > self.max_history_length * 2:  # user + assistant = 2 messages
            conversation['history'] = conversation['history'][-self.max_history_length * 2:]
        
        # Extraire les mots-cl√©s pour le contexte
        if role == 'user':
            self._extract_keywords(conversation, content)
        
        logger.info(f"üí¨ Message ajout√© √† la conversation {conversation_id}: {role}")
        return conversation_id
    
    def _extract_keywords(self, conversation, content):
        """Extrait les mots-cl√©s importants du message utilisateur"""
        import re
        
        # Mots-cl√©s fiscaux et juridiques importants
        fiscal_keywords = [
            'tva', 'taxe', 'impot', 'imp√¥t', 'douane', 'article', 'code',
            'marchandise', 'importation', 'exportation', 'soci√©t√©', 'soci√©t√©s',
            'fiscal', 'b√©n√©fice', 'revenus', 'd√©claration', 'assujetti',
            'redevable', 'exon√©ration', 'd√©duction', 'cr√©dit', 'loi', 'finances',
            'budget', 'recettes', 'd√©penses', 'investissement', '√©conomique'
        ]
        
        # Extraire les mots-cl√©s du contenu
        content_lower = content.lower()
        for keyword in fiscal_keywords:
            if keyword in content_lower:
                conversation['context_keywords'].add(keyword)
        
        # Extraire les num√©ros d'articles
        articles = re.findall(r'article\s+(\d+)', content_lower)
        for article in articles:
            conversation['context_keywords'].add(f'article_{article}')
        
        # Extraire les valeurs num√©riques importantes
        montants = re.findall(r'(\d+(?:\s\d+)*(?:,\d+)?\s*(?:millions?|milliards?)\s*(?:fcfa|euros?))', content_lower)
        for montant in montants:
            conversation['context_keywords'].add(f'montant_{montant.replace(" ", "_")}')
    
    def get_conversation_context(self, conversation_id, max_messages=6):
        """R√©cup√®re le contexte de la conversation pour alimenter le prompt"""
        if conversation_id not in self.conversations:
            return ""
        
        conversation = self.conversations[conversation_id]
        history = conversation['history']
        
        if not history:
            return ""
        
        # Prendre les derniers messages (max_messages)
        recent_history = history[-max_messages:]
        
        context_parts = []
        context_parts.append("HISTORIQUE DE LA CONVERSATION ACTUELLE:")
        
        for i, message in enumerate(recent_history, 1):
            role_label = "UTILISATEUR" if message['role'] == 'user' else "ASSISTANT"
            context_parts.append(f"{i}. {role_label}: {message['content'][:200]}...")
            
            # Ajouter les r√©f√©rences si disponibles
            if message.get('references') and message['role'] == 'assistant':
                refs = message['references'][:2]  # Limiter √† 2 r√©f√©rences
                for ref in refs:
                    article = ref.get('article_ref', 'N/A')
                    context_parts.append(f"   ‚Üí R√©f√©rence: {article}")
        
        # Ajouter les mots-cl√©s contextuels
        if conversation['context_keywords']:
            keywords = list(conversation['context_keywords'])[:8]  # Limiter √† 8 mots-cl√©s
            context_parts.append(f"MOTS-CL√âS DU CONTEXTE: {', '.join(keywords)}")
        
        return "\n".join(context_parts)
    
    def analyze_follow_up_question(self, conversation_id, current_question):
        """Analyse si la question actuelle fait r√©f√©rence √† la conversation pr√©c√©dente"""
        if conversation_id not in self.conversations:
            return False, ""
        
        conversation = self.conversations[conversation_id]
        history = conversation['history']
        
        if len(history) < 2:  # Pas assez d'historique
            return False, ""
        
        # Mots indicateurs de questions de suivi
        follow_up_indicators = [
            'ce taux', 'cette taxe', 'cet imp√¥t', 'cette loi', 'cet article',
            'il', 'elle', 'ils', 'elles', 'le', 'la', 'les', 'du', 'de la',
            'aussi', '√©galement', 'en plus', 'et', 'mais', 'cependant',
            'est-il', 'est-elle', 'sont-ils', 'sont-elles',
            'comment', 'pourquoi', 'quand', 'o√π', 'qui', 'que'
        ]
        
        current_lower = current_question.lower()
        is_follow_up = any(indicator in current_lower for indicator in follow_up_indicators)
        
        if is_follow_up:
            # R√©cup√©rer la derni√®re question de l'utilisateur
            last_user_message = None
            for message in reversed(history):
                if message['role'] == 'user':
                    last_user_message = message
                    break
            
            if last_user_message:
                context_hint = f"QUESTION PR√âC√âDENTE: {last_user_message['content']}"
                logger.info(f"üîó Question de suivi d√©tect√©e - Contexte: {last_user_message['content'][:50]}...")
                return True, context_hint
        
        return False, ""
    
    def get_conversation_ids(self):
        """Retourne la liste des IDs de conversations"""
        return list(self.conversations.keys())
    
    def delete_conversation(self, conversation_id):
        """Supprime une conversation"""
        if conversation_id in self.conversations:
            del self.conversations[conversation_id]
            logger.info(f"üóëÔ∏è Conversation supprim√©e: {conversation_id}")

class LexFinClient:
    """Client LexFin optimis√© avec surveillance automatique pour la fiscalit√© et douanes s√©n√©galaises"""
    
    def __init__(self):
        self.config = LexFinConfig()
        self.indexed_files = {}  # Cache des fichiers index√©s {path: hash}
        self.observer = None  # R√©f√©rence au watcher
        
        # üó®Ô∏è NOUVEAU: Gestionnaire de conversations intelligentes
        self.conversation_manager = ConversationManager(max_history_length=8)
        self.current_conversation_id = None
        
        self.setup_chroma()
        self.setup_watch_directory()
        
        # Initialiser le syst√®me hi√©rarchique V2.0 (√† la demande)
        self.hierarchie_client = None
        self._hierarchie_initialized = False
        
        # D√©marrer automatiquement la surveillance en arri√®re-plan
        surveillance_ok = False
        try:
            surveillance_ok = self.start_file_watcher()
        except Exception as e:
            logger.warning(f"  Surveillance automatique d√©sactiv√©e: {e}")
        
        if surveillance_ok:
            logger.info("   DOCUMIND initialis√© - Surveillance automatique active")
        else:
            logger.info("   DOCUMIND initialis√© - Mode manuel activ√©")
    
    def start_new_conversation(self):
        """D√©marre une nouvelle conversation"""
        self.current_conversation_id = self.conversation_manager.create_conversation()
        logger.info(f"üÜï Nouvelle conversation d√©marr√©e: {self.current_conversation_id}")
        return self.current_conversation_id
    
    def set_conversation(self, conversation_id):
        """Change la conversation active"""
        if conversation_id in self.conversation_manager.conversations:
            self.current_conversation_id = conversation_id
            logger.info(f"üîÑ Conversation active chang√©e: {conversation_id}")
        else:
            logger.warning(f"‚ö†Ô∏è Conversation introuvable: {conversation_id}")
    
    def get_conversations_list(self):
        """Retourne la liste des conversations avec r√©sum√©s"""
        conversations = []
        for conv_id, conv_data in self.conversation_manager.conversations.items():
            # Prendre le premier message utilisateur comme titre
            title = "Nouvelle conversation"
            if conv_data['history']:
                first_user_msg = next((msg for msg in conv_data['history'] if msg['role'] == 'user'), None)
                if first_user_msg:
                    title = first_user_msg['content'][:50] + "..." if len(first_user_msg['content']) > 50 else first_user_msg['content']
            
            conversations.append({
                'id': conv_id,
                'title': title,
                'created_at': conv_data['created_at'],
                'last_updated': conv_data['last_updated'],
                'message_count': len(conv_data['history'])
            })
        
        # Trier par derni√®re mise √† jour
        conversations.sort(key=lambda x: x['last_updated'], reverse=True)
        return conversations
    
    def setup_chroma(self):
        """Initialise ChromaDB avec gestion automatique de la dimension d'embeddings"""
        try:
            self.chroma_client = chromadb.PersistentClient(
                path=self.config.CHROMA_PERSIST_DIRECTORY,
                settings=Settings(allow_reset=True, anonymized_telemetry=False)
            )
            
            collection_found = False
            
            # Essayer de r√©cup√©rer une collection existante
            for collection_name in ["alex_documents", "alex_pro_docs"]:
                try:
                    self.collection = self.chroma_client.get_collection(collection_name)
                    collection_found = True
                    logger.info(f"‚úÖ Collection trouv√©e: {collection_name}")
                    
                    # Tester la compatibilit√© des embeddings
                    try:
                        test_embedding = self.generate_embeddings("test")
                        if test_embedding:
                            # Test avec un petit √©chantillon
                            self.collection.query(
                                query_embeddings=[test_embedding],
                                n_results=1
                            )
                            logger.info(f"‚úÖ Dimension d'embeddings compatible: {len(test_embedding)}")
                            break
                    except Exception as dim_error:
                        if "dimension" in str(dim_error).lower():
                            logger.warning(f"‚ö†Ô∏è Incompatibilit√© dimension embeddings d√©tect√©e: {dim_error}")
                            logger.info(f"üîÑ Recr√©ation de la collection {collection_name} n√©cessaire...")
                            
                            # Supprimer l'ancienne collection
                            self.chroma_client.delete_collection(collection_name)
                            
                            # Cr√©er une nouvelle collection
                            self.collection = self.chroma_client.create_collection(
                                name=collection_name,
                                metadata={"description": "Documents ALEX - Nouvelle dimension embeddings"}
                            )
                            
                            # R√©initialiser le cache des fichiers index√©s
                            self.indexed_files = {}
                            
                            logger.info(f"‚úÖ Collection {collection_name} recr√©√©e avec nouvelle dimension")
                            break
                        else:
                            raise dim_error
                            
                except Exception as e:
                    if "does not exist" not in str(e).lower():
                        logger.warning(f"Erreur collection {collection_name}: {e}")
                    continue
            
            # Si aucune collection trouv√©e, en cr√©er une nouvelle
            if not collection_found or not self.collection:
                self.collection = self.chroma_client.create_collection(
                    name="alex_pro_docs",
                    metadata={"description": "Documents ALEX - Nouvelle installation"}
                )
                logger.info("‚úÖ Nouvelle collection cr√©√©e: alex_pro_docs")
            
            # Charger la liste des fichiers d√©j√† index√©s
            self.load_indexed_files_cache()
            
        except Exception as e:
            logger.error(f"Erreur ChromaDB: {e}")
            self.collection = None
    
    def create_vector_store(self):
        """Cr√©e une nouvelle collection ChromaDB"""
        try:
            # Supprimer l'ancienne collection si elle existe
            try:
                self.chroma_client.delete_collection("alex_documents")
            except:
                pass
            
            # Cr√©er une nouvelle collection
            collection = self.chroma_client.create_collection(
                name="alex_documents",
                metadata={"hnsw:space": "cosine", "description": "Documents ALEX"}
            )
            self.collection = collection
            return collection
        except Exception as e:
            logger.error(f"Erreur cr√©ation collection: {e}")
            return self.collection
    
    def setup_watch_directory(self):
        """Configure le r√©pertoire √† surveiller"""
        self.watch_dir = Path(self.config.WATCH_DIRECTORY)
        self.watch_dir.mkdir(exist_ok=True)
        logger.info(f"   R√©pertoire surveill√©: {self.watch_dir.absolute()}")
    
    def start_file_watcher(self):
        """D√©marre la surveillance automatique du r√©pertoire avec red√©marrage automatique"""
        try:
            if not self.watch_dir.exists():
                logger.warning(f"  R√©pertoire de surveillance introuvable: {self.watch_dir}")
                return False
                
            # Arr√™ter l'ancien observer s'il existe
            if hasattr(self, 'observer') and self.observer and self.observer.is_alive():
                self.observer.stop()
                self.observer.join()
            
            # Cr√©er et d√©marrer le nouvel observer
            from watchdog.observers import Observer
            self.observer = Observer()
            handler = DocumentWatcherHandler(self)
            self.observer.schedule(handler, str(self.watch_dir), recursive=True)
            self.observer.daemon = True  # Thread daemon pour ne pas bloquer l'arr√™t
            self.observer.start()
            
            logger.info(f"   [AUTO] Surveillance automatique active: {self.watch_dir}")
            logger.info("   [AUTO] Les nouveaux fichiers seront index√©s automatiquement en arri√®re-plan")
            
            # D√©marrer le monitoring de la surveillance
            self.start_watcher_monitor()
            
            # Scan initial en mode intelligent (respecte le cache)
            import threading
            def initial_scan():
                try:
                    time.sleep(1)  # Petite pause pour laisser le syst√®me s'initialiser
                    self.scan_existing_files()
                except Exception as e:
                    logger.warning(f"  [AUTO] Scan initial diff√©r√©: {e}")
            
            # Scan initial en arri√®re-plan
            scan_thread = threading.Thread(target=initial_scan, daemon=True)
            scan_thread.start()
            
            return True
            
        except Exception as e:
            logger.warning(f"  Impossible de d√©marrer la surveillance automatique: {e}")
            logger.info("üìö Fonctionnement en mode manuel - utilisez les boutons pour indexer")
            self.observer = None
            return False

    def start_watcher_monitor(self):
        """D√©marre un thread de surveillance pour red√©marrer automatiquement l'observer si n√©cessaire"""
        import threading
        
        def monitor_watcher():
            """Surveille l'√©tat de l'observer et le red√©marre si n√©cessaire"""
            while True:
                try:
                    time.sleep(30)  # V√©rifier toutes les 30 secondes
                    
                    # V√©rifier si l'observer existe et fonctionne
                    if not hasattr(self, 'observer') or not self.observer:
                        logger.warning("   [AUTO] Observer non initialis√© - Red√©marrage...")
                        self.start_file_watcher()
                        continue
                    
                    if not self.observer.is_alive():
                        logger.warning("   [AUTO] Observer arr√™t√© - Red√©marrage automatique...")
                        self.start_file_watcher()
                        continue
                        
                except Exception as e:
                    logger.error(f"   [AUTO] Erreur monitoring surveillance: {e}")
                    try:
                        self.start_file_watcher()
                    except:
                        pass
                    
        # Lancer le monitoring en thread daemon
        monitor_thread = threading.Thread(target=monitor_watcher, daemon=True)
        monitor_thread.start()
    
    def load_indexed_files_cache(self):
        """Charge le cache des fichiers index√©s depuis ChromaDB"""
        try:
            if self.collection:
                # R√©cup√©rer tous les documents avec leurs m√©tadonn√©es
                results = self.collection.get(include=['metadatas'])
                if results and results['metadatas']:
                    for metadata in results['metadatas']:
                        if metadata and 'file_path' in metadata and 'file_hash' in metadata:
                            self.indexed_files[metadata['file_path']] = metadata['file_hash']
                    
                    cache_count = len(self.indexed_files)
                    logger.info(f"üìö Cache charg√©: {cache_count} fichiers index√©s")
                    
                    # Si la collection √©tait vide (recr√©√©e), forcer la r√©indexation
                    if cache_count == 0:
                        logger.info("üîÑ Collection vide d√©tect√©e - R√©indexation des documents n√©cessaire")
                        self.indexed_files = {}  # Vider le cache pour forcer la r√©indexation
                else:
                    logger.info("üìö Collection vide - Tous les fichiers seront index√©s")
                    self.indexed_files = {}
        except Exception as e:
            logger.error(f"Erreur chargement cache: {e}")
            self.indexed_files = {}
    
    def get_file_hash(self, file_path: str) -> str:
        """Calcule le hash MD5 d'un fichier"""
        try:
            with open(file_path, 'rb') as f:
                file_hash = hashlib.md5()
                for chunk in iter(lambda: f.read(4096), b""):
                    file_hash.update(chunk)
                return file_hash.hexdigest()
        except Exception as e:
            logger.error(f"Erreur calcul hash pour {file_path}: {e}")
            return ""
    
    def is_supported_file(self, file_path: str) -> bool:
        """V√©rifie si le fichier est support√© et pas temporaire"""
        file_name = Path(file_path).name
        
        # Ignorer les fichiers temporaires
        if file_name.startswith('~$') or file_name.startswith('.'):
            return False
            
        return Path(file_path).suffix.lower() in self.config.SUPPORTED_EXTENSIONS
    
    def is_file_already_indexed(self, file_path: str) -> bool:
        """V√©rifie si le fichier est d√©j√† index√© (m√™me contenu)"""
        if file_path not in self.indexed_files:
            return False
        
        current_hash = self.get_file_hash(file_path)
        stored_hash = self.indexed_files.get(file_path, "")
        
        return current_hash == stored_hash and current_hash != ""
    
    def read_file_content(self, file_path: str) -> str:
        """Lit le contenu d'un fichier"""
        try:
            file_ext = Path(file_path).suffix.lower()
            
            if file_ext == '.txt' or file_ext == '.md':
                with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                    return f.read()
            
            elif file_ext == '.json':
                with open(file_path, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    return json.dumps(data, indent=2, ensure_ascii=False)
            
            elif file_ext == '.csv':
                import pandas as pd
                df = pd.read_csv(file_path)
                return df.to_string()
            
            elif file_ext == '.odt':
                try:
                    # Essayer d'extraire le texte des fichiers ODT
                    import zipfile
                    import xml.etree.ElementTree as ET
                    
                    with zipfile.ZipFile(file_path, 'r') as zip_file:
                        if 'content.xml' in zip_file.namelist():
                            content_xml = zip_file.read('content.xml')
                            root = ET.fromstring(content_xml)
                            
                            # Extraire tout le texte
                            text_content = []
                            for elem in root.iter():
                                if elem.text:
                                    text_content.append(elem.text.strip())
                                if elem.tail:
                                    text_content.append(elem.tail.strip())
                            
                            return ' '.join(filter(None, text_content))
                    return ""
                except Exception as odt_error:
                    logger.warning(f"Erreur lecture ODT {file_path}: {odt_error}")
                    return ""
            
            elif file_ext == '.pdf':
                try:
                    # Extraction PDF avec PyPDF2 ou pdfplumber - conservation des num√©ros de page r√©els
                    try:
                        import PyPDF2
                        with open(file_path, 'rb') as pdf_file:
                            pdf_reader = PyPDF2.PdfReader(pdf_file)
                            # Extraction page par page pour conserver les vrais num√©ros
                            text_content = []
                            page_info = []  # Stocker les infos de page
                            
                            for page_num, page in enumerate(pdf_reader.pages, 1):
                                page_text = page.extract_text()
                                if page_text.strip():  # Seulement si la page a du contenu
                                    # Marquer le d√©but de chaque page
                                    page_marker = f"\n--- PAGE {page_num} ---\n"
                                    text_content.append(page_marker + page_text)
                                    page_info.append((len('\n'.join(text_content[:len(text_content)])), page_num))
                            
                            return '\n'.join(text_content)
                    except ImportError:
                        try:
                            import pdfplumber
                            with pdfplumber.open(file_path) as pdf:
                                text_content = []
                                for page_num, page in enumerate(pdf.pages, 1):
                                    page_text = page.extract_text() or ''
                                    
                                    # Essayer d'extraire les tableaux d'abord
                                    tables = page.extract_tables()
                                    
                                    if tables:
                                        # Si des tableaux sont d√©tect√©s, les formater proprement
                                        page_text_with_tables = f"\n--- PAGE {page_num} ---\n"
                                        
                                        # Ajouter le texte normal
                                        if page_text.strip():
                                            page_text_with_tables += page_text + "\n\n"
                                        
                                        # Ajouter les tableaux format√©s
                                        for i, table in enumerate(tables):
                                            page_text_with_tables += f"TABLEAU {i+1} (Page {page_num}):\n"
                                            if table and len(table) > 0:
                                                # Cr√©er un tableau lisible
                                                for row_idx, row in enumerate(table):
                                                    if row_idx == 0 and any(cell for cell in row if cell):
                                                        # En-t√™tes
                                                        page_text_with_tables += "COLONNES: " + " | ".join(str(cell or '') for cell in row) + "\n"
                                                        page_text_with_tables += "-" * 80 + "\n"
                                                    else:
                                                        # Donn√©es avec labels
                                                        if any(cell for cell in row if cell):
                                                            formatted_row = []
                                                            for cell in row:
                                                                cell_text = str(cell or '').strip()
                                                                if cell_text:
                                                                    formatted_row.append(cell_text)
                                                            if formatted_row:
                                                                page_text_with_tables += "LIGNE: " + " | ".join(formatted_row) + "\n"
                                            page_text_with_tables += "\n"
                                        
                                        text_content.append(page_text_with_tables)
                                    else:
                                        # Pas de tableau, texte normal
                                        if page_text.strip():
                                            page_marker = f"\n--- PAGE {page_num} ---\n"
                                            text_content.append(page_marker + page_text)
                                            
                                return '\n'.join(text_content)
                        except ImportError:
                            logger.warning(f"üìÑ PyPDF2 et pdfplumber non install√©s pour: {file_path}")
                            return f"Fichier PDF d√©tect√©: {Path(file_path).name} - Contenu non extractible"
                except Exception as pdf_error:
                    logger.error(f"Erreur extraction PDF {file_path}: {pdf_error}")
                    # Retourner au moins les m√©tadonn√©es du fichier
                    return f"Document PDF: {Path(file_path).name} - Fichier d√©tect√© mais extraction √©chou√©e. Document disponible pour traitement."
            
            elif file_ext in ['.xlsx', '.xls']:
                try:
                    import pandas as pd
                    # Lire le fichier Excel avec limitation pour √©viter les fichiers trop volumineux
                    excel_file = pd.ExcelFile(file_path)
                    text_content = []
                    total_rows_processed = 0
                    max_rows_per_file = 1000  # Limiter √† 1000 lignes max par fichier Excel
                    
                    # Traiter chaque feuille avec limitation
                    for sheet_name in excel_file.sheet_names:
                        if total_rows_processed >= max_rows_per_file:
                            text_content.append(f"... [FICHIER TRONQU√â - Plus de {max_rows_per_file} lignes] ...")
                            break
                            
                        text_content.append(f"=== Feuille: {sheet_name} ===")
                        
                        # Lire seulement les premi√®res lignes de chaque feuille
                        rows_to_read = min(200, max_rows_per_file - total_rows_processed)
                        df = pd.read_excel(file_path, sheet_name=sheet_name, nrows=rows_to_read)
                        
                        if len(df) > 0:
                            # R√©sum√© de la feuille plut√¥t que tout le contenu
                            text_content.append(f"Nombre de lignes: {len(df)}")
                            text_content.append(f"Colonnes: {', '.join(df.columns.astype(str))}")
                            
                            # Ajouter les premi√®res lignes seulement
                            first_rows = df.head(10).to_string(index=False, na_rep='', max_cols=10)
                            text_content.append("Premi√®res lignes:")
                            text_content.append(first_rows)
                            
                            total_rows_processed += len(df)
                        else:
                            text_content.append("Feuille vide")
                            
                        text_content.append("")  # Ligne vide entre les feuilles
                    
                    # Ajouter un r√©sum√© du fichier
                    summary = f"R√âSUM√â FICHIER EXCEL: {Path(file_path).name}\n"
                    summary += f"Nombre de feuilles: {len(excel_file.sheet_names)}\n"
                    summary += f"Feuilles: {', '.join(excel_file.sheet_names)}\n"
                    summary += f"Lignes trait√©es: {total_rows_processed}\n"
                    
                    return summary + "\n" + '\n'.join(text_content)
                except ImportError:
                    logger.warning(f"üìä pandas/openpyxl non install√©s pour Excel: {file_path}")
                    return f"Fichier Excel d√©tect√©: {Path(file_path).name} - Installer pandas et openpyxl pour l'extraction"
                except Exception as excel_error:
                    logger.error(f"Erreur lecture Excel {file_path}: {excel_error}")
                    return f"Fichier Excel: {Path(file_path).name} - Erreur d'extraction: {str(excel_error)}"
            
            elif file_ext == '.docx':
                try:
                    import docx
                    doc = docx.Document(file_path)
                    text_content = []
                    for paragraph in doc.paragraphs:
                        text_content.append(paragraph.text)
                    return '\n'.join(text_content)
                except ImportError:
                    logger.warning(f"üìÑ python-docx non install√© pour: {file_path}")
                    return f"Fichier DOCX d√©tect√©: {Path(file_path).name} - Contenu non extractible"
                except Exception as docx_error:
                    logger.error(f"Erreur extraction DOCX {file_path}: {docx_error}")
                    return f"Fichier DOCX: {Path(file_path).name}"
            
            # Pour d'autres types de fichiers, essayer la lecture basique
            else:
                with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                    return f.read()
                    
        except Exception as e:
            logger.error(f"Erreur lecture fichier {file_path}: {e}")
            return ""
    
    def process_new_file(self, file_path: str):
        """Traite un nouveau fichier"""
        if not self.is_supported_file(file_path):
            logger.info(f"‚è≠Ô∏è Type de fichier non support√©: {file_path}")
            return
        
        if self.is_file_already_indexed(file_path):
            logger.info(f"‚úÖ Fichier d√©j√† index√©: {Path(file_path).name}")
            return
        
        self.index_file(file_path)
    
    def process_new_file_background(self, file_path: str):
        """Traite un nouveau fichier en arri√®re-plan (ne bloque pas le chatbot)"""
        try:
            if not self.is_supported_file(file_path):
                return
            
            if self.is_file_already_indexed(file_path):
                logger.debug(f"‚è≠Ô∏è [AUTO] Fichier d√©j√† index√©: {Path(file_path).name}")
                return
            
            logger.info(f"üîÑ [AUTO] Indexation en arri√®re-plan: {Path(file_path).name}")
            self.index_file(file_path)
            
        except Exception as e:
            logger.error(f"  [AUTO] Erreur traitement nouveau fichier {file_path}: {e}")
    
    def process_modified_file_background(self, file_path: str):
        """Traite un fichier modifi√© en arri√®re-plan"""
        try:
            if not self.is_supported_file(file_path):
                return
            
            current_hash = self.get_file_hash(file_path)
            stored_hash = self.indexed_files.get(file_path, "")
            
            if current_hash != stored_hash:
                logger.info(f"üîÑ [AUTO] R√©indexation automatique: {Path(file_path).name}")
                # Supprimer l'ancienne version
                self.remove_file_from_index(file_path)
                # R√©indexer
                self.index_file(file_path)
            else:
                logger.debug(f"‚è≠Ô∏è [AUTO] Fichier inchang√©: {Path(file_path).name}")
                
        except Exception as e:
            logger.error(f"  [AUTO] Erreur traitement fichier modifi√© {file_path}: {e}")
    
    def process_modified_file(self, file_path: str):
        """Traite un fichier modifi√© (version manuelle)"""
        if not self.is_supported_file(file_path):
            return
        
        current_hash = self.get_file_hash(file_path)
        stored_hash = self.indexed_files.get(file_path, "")
        
        if current_hash != stored_hash:
            logger.info(f"üîÑ R√©indexation du fichier modifi√©: {Path(file_path).name}")
            # Supprimer l'ancienne version
            self.remove_file_from_index(file_path)
            # R√©indexer
            self.index_file(file_path)
    
    def index_file(self, file_path: str):
        """Indexe un fichier dans ChromaDB avec positions pr√©cises"""
        try:
            content = self.read_file_content(file_path)
            if not content.strip():
                logger.warning(f"  Fichier vide: {file_path}")
                return
            
            # D√©couper le contenu en chunks avec positions
            chunks_with_positions = self.chunk_text_with_positions(content, file_path)
            if not chunks_with_positions:
                return
            
            logger.info(f"üîÑ Indexation de {Path(file_path).name} ({len(chunks_with_positions)} chunks)")
            
            # G√©n√©rer les embeddings en batch pour optimiser
            embeddings = []
            valid_chunks = []
            valid_positions = []
            
            # Traitement par petits groupes pour √©viter les timeouts
            batch_size = 3
            for i in range(0, len(chunks_with_positions), batch_size):
                batch_chunks = chunks_with_positions[i:i + batch_size]
                
                for chunk_info in batch_chunks:
                    embedding = self.generate_embeddings(chunk_info['text'])
                    if embedding:
                        embeddings.append(embedding)
                        valid_chunks.append(chunk_info['text'])
                        valid_positions.append(chunk_info)
                
                # Petit d√©lai entre les batches pour √©viter de surcharger Ollama
                if i + batch_size < len(chunks_with_positions):
                    time.sleep(0.1)
            
            if not embeddings:
                logger.error(f"  Impossible de g√©n√©rer les embeddings pour: {file_path}")
                return
            
            # Ajouter √† ChromaDB avec m√©tadonn√©es de position
            file_hash = self.get_file_hash(file_path)
            file_name = Path(file_path).name
            
            ids = [f"{file_name}_{i}_{file_hash[:8]}" for i in range(len(valid_chunks))]
            metadatas = [
                {
                    "file_path": pos_info['file_path'],
                    "file_name": file_name,
                    "file_hash": file_hash,
                    "chunk_index": i,
                    "indexed_at": time.strftime("%Y-%m-%d %H:%M:%S"),
                    "start_pos": pos_info['start_pos'],
                    "end_pos": pos_info['end_pos'],
                    "line_start": pos_info['line_start'],
                    "line_end": pos_info['line_end'],
                    "page_start": pos_info['page_start'],
                    "page_end": pos_info['page_end'],
                    "article_ref": pos_info.get('article_ref', 'Section g√©n√©rale'),
                    "article_number": pos_info.get('article_number', ''),
                    "section": pos_info.get('section', ''),
                    "sous_section": pos_info.get('sous_section', ''),
                    "chapitre": pos_info.get('chapitre', ''),
                    "titre": pos_info.get('titre', '')
                }
                for i, pos_info in enumerate(valid_positions)
            ]
            
            self.collection.add(
                embeddings=embeddings,
                documents=valid_chunks,
                metadatas=metadatas,
                ids=ids
            )
            
            # Mettre √† jour le cache
            self.indexed_files[file_path] = file_hash
            
            logger.info(f"‚úÖ Fichier index√©: {file_name} ({len(valid_chunks)} chunks)")
            
        except Exception as e:
            logger.error(f"  Erreur indexation {file_path}: {e}")
    
    def remove_file_from_index(self, file_path: str):
        """Supprime un fichier de l'index"""
        try:
            # Trouver tous les documents de ce fichier
            results = self.collection.get(
                where={"file_path": file_path},
                include=['metadatas']
            )
            
            if results and results['ids']:
                self.collection.delete(ids=results['ids'])
                logger.info(f"üóëÔ∏è Ancien index supprim√© pour: {Path(file_path).name}")
                
        except Exception as e:
            logger.error(f"Erreur suppression index: {e}")
    
    def chunk_text_with_positions(self, text: str, file_path: str, chunk_size: int = 1500, overlap: int = 100) -> List[Dict]:
        """D√©coupe le texte en chunks avec positions pr√©cises pour r√©f√©rences - Optimis√© pour documents juridiques"""
        
        # D√©tecter si c'est un document juridique (Code des douanes, des imp√¥ts, etc.)
        is_legal_document = any(keyword in file_path.lower() for keyword in ['code', 'douane', 'impot', 'imp√¥t', 'fiscal', 'loi', 'cgi', 'dgi'])
        
        if is_legal_document:
            return self.chunk_legal_document(text, file_path, chunk_size, overlap)
        
        # D√©coupage standard pour autres documents
        if len(text) <= chunk_size:
            return [{
                'text': text,
                'file_path': file_path,
                'start_pos': 0,
                'end_pos': len(text),
                'line_start': 1,
                'line_end': len(text.split('\n')),
                'page_start': 1,
                'page_end': 1,
                'article_ref': 'Document complet'
            }]
        
        chunks = []
        lines = text.split('\n')
        start = 0
        current_line = 1
        
        while start < len(text):
            end = min(start + chunk_size, len(text))
            
            # Essayer de couper √† un point naturel (phrase)
            if end < len(text):
                last_sentence = max(
                    text.rfind('.', start, end),
                    text.rfind('\n', start, end),
                    text.rfind('!', start, end),
                    text.rfind('?', start, end)
                )
                
                if last_sentence > start + 200:
                    end = last_sentence + 1
            
            chunk_text = text[start:end].strip()
            if chunk_text:
                # Calculer les num√©ros de lignes
                text_before = text[:start]
                text_chunk = text[start:end]
                
                line_start = text_before.count('\n') + 1
                line_end = line_start + text_chunk.count('\n')
                
                # Extraction du vrai num√©ro de page depuis les marqueurs
                page_start = 1
                page_end = 1
                
                # Chercher les marqueurs de page dans le chunk et avant
                import re
                page_markers_before = re.findall(r'--- PAGE (\d+) ---', text_before)
                page_markers_in_chunk = re.findall(r'--- PAGE (\d+) ---', chunk_text)
                
                if page_markers_before:
                    page_start = int(page_markers_before[-1])  # Derni√®re page avant le chunk
                elif page_markers_in_chunk:
                    page_start = int(page_markers_in_chunk[0])  # Premi√®re page dans le chunk
                
                if page_markers_in_chunk:
                    page_end = int(page_markers_in_chunk[-1])  # Derni√®re page dans le chunk
                else:
                    page_end = page_start
                
                # Fallback: si pas de marqueurs trouv√©s, estimation basique
                if page_start == 1 and page_end == 1 and line_start > 50:
                    page_start = max(1, (line_start - 1) // 50 + 1)
                    page_end = max(1, (line_end - 1) // 50 + 1)
                
                chunks.append({
                    'text': chunk_text,
                    'file_path': file_path,
                    'start_pos': start,
                    'end_pos': end,
                    'line_start': line_start,
                    'line_end': line_end,
                    'page_start': page_start,
                    'page_end': page_end,
                    'article_ref': f'Section lignes {line_start}-{line_end}'
                })
            
            start = end - overlap if end < len(text) else end
        
        return chunks

    def chunk_legal_document(self, text: str, file_path: str, chunk_size: int = 2000, overlap: int = 200) -> List[Dict]:
        """D√©coupage sp√©cialis√© pour documents juridiques (codes) avec identification des articles"""
        import re
        
        chunks = []
        lines = text.split('\n')
        
        # Patterns pour identifier la structure hi√©rarchique du Code des Imp√¥ts et Douanes
        article_pattern = re.compile(r'^(Article\s*\d+(?:-\d+)?|Art\.\s*\d+(?:-\d+)?|ARTICLE\s*\d+(?:-\d+)?)', re.IGNORECASE)
        section_pattern = re.compile(r'^(SECTION\s*[IVX0-9]+|Section\s*[IVX0-9]+)', re.IGNORECASE)
        sous_section_pattern = re.compile(r'^(Sous-section\s*\d+|SOUS-SECTION\s*\d+)', re.IGNORECASE)
        chapitre_pattern = re.compile(r'^(CHAPITRE\s*[IVX0-9]+|Chapitre\s*[IVX0-9]+)', re.IGNORECASE)
        titre_pattern = re.compile(r'^(TITRE\s*[IVX0-9]+|Titre\s*[IVX0-9]+)', re.IGNORECASE)
        
        current_article = "Document"
        current_section = ""
        current_sous_section = ""
        current_chapitre = ""
        current_titre = ""
        
        i = 0
        while i < len(lines):
            chunk_lines = []
            chunk_start_line = i + 1
            article_ref = current_article
            
            # D√©tecter le d√©but d'un nouvel √©l√©ment hi√©rarchique
            line = lines[i].strip()
            
            if titre_pattern.match(line):
                current_titre = line
                current_chapitre = ""
                current_section = ""
                current_sous_section = ""
                current_article = line
                
            elif chapitre_pattern.match(line):
                current_chapitre = line
                current_section = ""
                current_sous_section = ""
                current_article = line
                
            elif section_pattern.match(line):
                current_section = line
                current_sous_section = ""
                current_article = line
                
            elif sous_section_pattern.match(line):
                current_sous_section = line
                current_article = line
                
            elif article_pattern.match(line):
                current_article = line
                article_ref = current_article
            
            # Collecter les lignes pour ce chunk
            chunk_size_lines = chunk_size // 50  # Estimation : ~50 caract√®res par ligne
            start_i = i
            
            while i < len(lines) and len('\n'.join(chunk_lines)) < chunk_size:
                current_line = lines[i].strip()
                
                # Arr√™ter si on trouve un nouvel article (sauf si on vient de commencer)
                if i > start_i and article_pattern.match(current_line):
                    break
                    
                chunk_lines.append(lines[i])
                i += 1
                
                # Limiter la taille pour √©viter des chunks trop gros
                if len(chunk_lines) > chunk_size_lines:
                    break
            
            # Cr√©er le chunk si on a du contenu
            if chunk_lines:
                chunk_text = '\n'.join(chunk_lines).strip()
                
                if chunk_text:
                    # Calculer les positions
                    text_before = '\n'.join(lines[:start_i])
                    start_pos = len(text_before) + (1 if text_before else 0)
                    end_pos = start_pos + len(chunk_text)
                    
                    line_start = start_i + 1
                    line_end = i
                    
                    # Extraction du vrai num√©ro de page depuis les marqueurs
                    page_start = 1
                    page_end = 1
                    
                    # Chercher les marqueurs de page dans le chunk et avant
                    import re
                    text_before = '\n'.join(lines[:start_i])
                    
                    page_markers_before = re.findall(r'--- PAGE (\d+) ---', text_before)
                    page_markers_in_chunk = re.findall(r'--- PAGE (\d+) ---', chunk_text)
                    
                    if page_markers_before:
                        page_start = int(page_markers_before[-1])
                    elif page_markers_in_chunk:
                        page_start = int(page_markers_in_chunk[0])
                    
                    if page_markers_in_chunk:
                        page_end = int(page_markers_in_chunk[-1])
                    else:
                        page_end = page_start
                    
                    # Fallback: si pas de marqueurs trouv√©s, estimation basique
                    if page_start == 1 and page_end == 1 and line_start > 50:
                        page_start = max(1, (line_start - 1) // 50 + 1)
                        page_end = max(1, (line_end - 1) // 50 + 1)
                    
                    # Cr√©er la r√©f√©rence hi√©rarchique compl√®te
                    ref_parts = []
                    if current_titre:
                        ref_parts.append(current_titre)
                    if current_chapitre:
                        ref_parts.append(current_chapitre)
                    if current_section:
                        ref_parts.append(current_section)
                    if current_sous_section:
                        ref_parts.append(current_sous_section)
                    if current_article and current_article not in ref_parts:
                        ref_parts.append(current_article)
                    
                    full_ref = " > ".join(ref_parts) if ref_parts else article_ref
                    
                    # üîß CORRECTION OCR: Normaliser les espaces dans les num√©ros d'articles
                    # Exemple: "Article 4 12" ‚Üí "Article 412"
                    import re
                    full_ref_normalized = re.sub(r'Article\s+(\d+)\s+(\d+)', r'Article \1\2', full_ref)
                    article_number_normalized = re.sub(r'Article\s+(\d+)\s+(\d+)', r'Article \1\2', current_article)
                    
                    chunks.append({
                        'text': chunk_text,
                        'file_path': file_path,
                        'start_pos': start_pos,
                        'end_pos': end_pos,
                        'line_start': line_start,
                        'line_end': line_end,
                        'page_start': page_start,
                        'page_end': page_end,
                        'article_ref': full_ref_normalized,  # Version corrig√©e
                        'article_ref_original': full_ref,     # Version originale conserv√©e
                        'article_number': article_number_normalized,
                        'section': current_section,
                        'sous_section': current_sous_section,
                        'chapitre': current_chapitre,
                        'titre': current_titre
                    })
            
            # √âviter les boucles infinies
            if i <= start_i:
                i += 1
        
        logger.info(f"üìñ Document juridique d√©coup√©: {len(chunks)} articles/sections identifi√©s")
        return chunks

    def chunk_text(self, text: str, chunk_size: int = 1500, overlap: int = 100) -> List[str]:
        """D√©coupe le texte en chunks (version simplifi√©e pour compatibilit√©)"""
        chunks_with_pos = self.chunk_text_with_positions(text, "", chunk_size, overlap)
        return [chunk['text'] for chunk in chunks_with_pos]
    
    def scan_existing_files(self):
        """Scanne les fichiers existants au d√©marrage avec optimisations"""
        logger.info("ÔøΩ Scan optimis√© des fichiers existants...")
        
        try:
            import concurrent.futures
            
            # Collecter tous les fichiers et classifier
            files_to_index = []
            already_indexed = []
            
            for file_path in self.watch_dir.rglob('*'):
                if file_path.is_file() and self.is_supported_file(str(file_path)):
                    if self.is_file_already_indexed(str(file_path)):
                        already_indexed.append(str(file_path))
                    else:
                        files_to_index.append(str(file_path))
            
            # Afficher le statut
            if already_indexed:
                logger.info(f"‚è≠Ô∏è {len(already_indexed)} fichiers d√©j√† index√©s (ignor√©s):")
                for file_path in already_indexed:
                    logger.info(f"   ‚è≠Ô∏è {Path(file_path).name}")
            
            if not files_to_index:
                logger.info("‚úÖ Tous les fichiers sont d√©j√† index√©s - Aucun nouveau fichier √† traiter")
                return
            
            logger.info(f"üìö Indexation de {len(files_to_index)} fichiers en parall√®le...")
            
            # Traitement parall√®le avec ThreadPoolExecutor
            with concurrent.futures.ThreadPoolExecutor(max_workers=3) as executor:
                # Soumettre tous les fichiers pour traitement
                future_to_file = {
                    executor.submit(self.index_file, file_path): file_path 
                    for file_path in files_to_index
                }
                
                # Collecter les r√©sultats
                count = 0
                for future in concurrent.futures.as_completed(future_to_file):
                    file_path = future_to_file[future]
                    try:
                        future.result()
                        count += 1
                        if count % 5 == 0:  # Progress indicator
                            logger.info(f"‚è≥ {count}/{len(files_to_index)} fichiers trait√©s...")
                    except Exception as e:
                        logger.error(f"  Erreur avec {file_path}: {e}")
            
            logger.info(f"üéØ {count} fichiers index√©s avec succ√®s!")
            
        except Exception as e:
            logger.warning(f"  Erreur lors du scan initial: {e}")
            logger.info("üìö Fallback: indexation s√©quentielle")
            # Fallback vers m√©thode s√©quentielle
            count = 0
            for file_path in self.watch_dir.rglob('*'):
                if file_path.is_file() and self.is_supported_file(str(file_path)):
                    if not self.is_file_already_indexed(str(file_path)):
                        self.index_file(str(file_path))
                        count += 1

    def _enhance_text_for_embedding(self, text: str) -> str:
        """
        Am√©liore subtilement le texte pour de meilleurs embeddings s√©mantiques
        Normalise les r√©f√©rences g√©ographiques car tous les documents concernent le S√©n√©gal
        """
        original_text = text.strip()
        enhanced_text = original_text
        
        # üá∏üá≥ NORMALISATION G√âOGRAPHIQUE INTELLIGENTE
        # Tous nos documents concernent le S√©n√©gal, donc "au S√©n√©gal" est redondant
        
        # Patterns de suppression g√©ographique (avec regex pour plus de pr√©cision)
        import re
        
        # Supprimer les r√©f√©rences g√©ographiques redondantes (case insensitive)
        geographic_patterns = [
            r'\bau s√©n√©gal\b', r'\bdu s√©n√©gal\b', r'\ben s√©n√©gal\b', r'\bs√©n√©galais\b',
            r'\bau senegal\b', r'\bdu senegal\b', r'\ben senegal\b', r'\bsenegalais\b',
            r'\bs√©n√©gal\b', r'\bsenegal\b'
        ]
        
        for pattern in geographic_patterns:
            if re.search(pattern, enhanced_text, re.IGNORECASE):
                enhanced_text = re.sub(pattern, '', enhanced_text, flags=re.IGNORECASE)
                enhanced_text = re.sub(r'\s+', ' ', enhanced_text).strip()  # Nettoyer espaces multiples
                logger.info(f"üá∏üá≥ Normalisation g√©ographique: '{original_text}' ‚Üí '{enhanced_text}'")
                break
        
        # Si c'est une courte question, l'√©tendre l√©g√®rement avec du contexte implicite
        if len(enhanced_text) < 50 and '?' in enhanced_text:
            # Questions sur les taux -> contexte fiscal/taxation
            if any(word in enhanced_text.lower() for word in ['taux', 'combien', 'pourcentage']):
                if any(word in enhanced_text.lower() for word in ['tva', 'taxe']):
                    # Ajouter un contexte fiscal implicite pour les questions TVA
                    return f"{enhanced_text} contexte fiscal taxation"
                elif any(word in enhanced_text.lower() for word in ['imp√¥t', 'soci√©t√©', 'is']):
                    return f"{enhanced_text} contexte fiscal imp√¥t"
                elif any(word in enhanced_text.lower() for word in ['douane', 'marchandise', 'importation']):
                    return f"{enhanced_text} contexte douanier"
            
            # Questions g√©n√©rales sur articles -> contexte juridique
            if 'article' in enhanced_text.lower():
                return f"{enhanced_text} contexte juridique code loi"
        
        # Pour les textes plus longs, retourner la version normalis√©e
        return enhanced_text

    def generate_embeddings(self, text: str, max_retries: int = 2) -> List[float]:
        """G√©n√®re des embeddings intelligents avec contextualisation s√©mantique"""
        
        # üß† AM√âLIORATION S√âMANTIQUE: Pr√©paration du texte pour meilleur embedding
        enhanced_text = self._enhance_text_for_embedding(text)
        
        for attempt in range(max_retries + 1):
            try:
                payload = {
                    "model": self.config.OLLAMA_EMBEDDING_MODEL,
                    "prompt": enhanced_text
                }
                
                # Timeout r√©duit et session r√©utilisable
                if not hasattr(self, '_session'):
                    self._session = requests.Session()
                    self._session.headers.update({'Connection': 'keep-alive'})
                
                # Timeout progressif selon l'essai
                timeout = 30 + (attempt * 15)  # 30s, 45s, 60s
                logger.info(f"üîÑ Tentative {attempt + 1}/{max_retries + 1} embedding (timeout: {timeout}s)")
                
                response = self._session.post(
                    f"{self.config.OLLAMA_BASE_URL}/api/embeddings",
                    json=payload,
                    timeout=timeout
                )
                
                if response.status_code == 200:
                    if enhanced_text != text:
                        logger.info(f"üß† Embedding contextualis√© g√©n√©r√© (tentative {attempt + 1})")
                    else:
                        logger.info(f"‚úÖ Embedding g√©n√©r√© avec succ√®s (tentative {attempt + 1})")
                    return response.json()['embedding']
                else:
                    logger.warning(f"‚ö†Ô∏è R√©ponse HTTP {response.status_code} (tentative {attempt + 1})")
                    
            except requests.exceptions.Timeout as e:
                logger.warning(f"‚è±Ô∏è Timeout tentative {attempt + 1}/{max_retries + 1}: {e}")
                if attempt < max_retries:
                    time.sleep(2)  # Pause avant retry
                    continue
            except Exception as e:
                logger.error(f"‚ùå Erreur embedding (tentative {attempt + 1}): {e}")
                if attempt < max_retries:
                    time.sleep(2)
                    continue
        
        logger.error(f"üí• √âchec g√©n√©ration embedding apr√®s {max_retries + 1} tentatives")
        return []
    
    def detect_legal_code_type(self, query: str) -> str:
        """EXPERTISE : D√©tecte le type de code juridique (CGI, Code des Douanes, etc.)"""
        query_lower = query.lower()
        
        # Indicateurs pour le Code G√©n√©ral des Imp√¥ts (CGI)
        cgi_indicators = [
            'code g√©n√©ral des imp√¥ts', 'code general des impots', 'cgi',
            'imp√¥t', 'impot', 'fiscal', 'fiscale', 'contribuable', 'tva',
            'b√©n√©fices imposables', 'benefices imposables', 'personnes imposables',
            'champ d\'application', 'soci√©t√©', 'soci√©t√©s', 'is', 'ir', 'ircm',
            'base imposable', 'assiette fiscale', 'd√©claration de revenus'
        ]
        
        # Indicateurs pour le Code des Douanes
        douane_indicators = [
            'code des douanes', 'douane', 'douanes', 'douanier', 'douani√®re',
            'importation', 'exportation', 'marchandise', 'marchandises',
            'd√©douanement', 'transit', 'bureau de douane', 'tarif douanier',
            'nomenclature', 'esp√®ce d\'une marchandise', 'origine des marchandises'
        ]
        
        # Calculer les scores
        cgi_score = sum(1 for indicator in cgi_indicators if indicator in query_lower)
        douane_score = sum(1 for indicator in douane_indicators if indicator in query_lower)
        
        if cgi_score > douane_score:
            return "Code G√©n√©ral des Imp√¥ts (CGI)"
        elif douane_score > cgi_score:
            return "Code des Douanes"
        else:
            return "Code G√©n√©ral (ind√©termin√©)"
    
    def analyze_hierarchical_context(self, query: str) -> Dict:
        """EXPERTISE : Analyse le contexte hi√©rarchique demand√© (Section, Sous-section, Chapitre, etc.)"""
        query_lower = query.lower()
        context = {
            'section': None,
            'sous_section': None,
            'chapitre': None,
            'titre': None,
            'theme': None
        }
        
        # D√©tecter BENEFICES IMPOSABLES - patterns plus pr√©cis
        if any(term in query_lower for term in ['benefices', 'b√©n√©fices']) and 'imposables' in query_lower:
            context['section'] = "SECTION II. BENEFICES IMPOSABLES"
            context['theme'] = "b√©n√©fices imposables"
            logger.info(f"üéØ Section d√©tect√©e: BENEFICES IMPOSABLES")
        
        # D√©tecter DETERMINATION DU BENEFICE NET IMPOSABLE
        if any(term in query_lower for term in ['determination', 'd√©termination']) and any(term in query_lower for term in ['benefice', 'b√©n√©fice']):
            context['sous_section'] = "Sous-section 1. DETERMINATION DU BENEFICE NET IMPOSABLE"
            context['theme'] = "d√©termination du b√©n√©fice net imposable"
            logger.info(f"üéØ Sous-section d√©tect√©e: DETERMINATION DU BENEFICE NET IMPOSABLE")
        
        # D√©tecter PERIODE D'IMPOSITION
        if any(term in query_lower for term in ['periode', 'p√©riode']) and 'imposition' in query_lower:
            context['theme'] = "p√©riode d'imposition"
            if not context['section']:
                context['section'] = "SECTION II. BENEFICES IMPOSABLES"
            if not context['sous_section']:
                context['sous_section'] = "Sous-section 1. DETERMINATION DU BENEFICE NET IMPOSABLE"
            logger.info(f"üéØ Th√®me d√©tect√©: p√©riode d'imposition")
        
        # D√©tecter les structures hi√©rarchiques explicites
        if 'section' in query_lower:
            # Extraire la section mentionn√©e
            if 'champ d\'application' in query_lower or 'personnes imposables' in query_lower:
                context['section'] = "SECTION I. CHAMP D'APPLICATION"
                context['theme'] = "personnes imposables"
            elif not context['section']:  # Si pas d√©j√† d√©tect√©
                if 'tva' in query_lower or 'taxe sur la valeur ajout√©e' in query_lower:
                    context['section'] = "SECTION TVA"
                    context['theme'] = "taxe sur la valeur ajout√©e"
        
        if 'sous-section' in query_lower or 'sous section' in query_lower:
            if 'personnes imposables' in query_lower:
                context['sous_section'] = "Sous-section 1. PERSONNES IMPOSABLES"
        
        # D√©tecter les th√®mes implicites bas√©s sur les mots-cl√©s
        if not context['theme']:
            if any(term in query_lower for term in ['soci√©t√©', 'soci√©t√©s', 'sarl', 'sa', 'sas']):
                context['theme'] = "soci√©t√©s"
            elif any(term in query_lower for term in ['base', 'assiette', 'calcul']):
                context['theme'] = "base imposable"
        
        return context
    
    def build_expert_search_strategy(self, article_num: str, code_type: str, hierarchical_context: Dict, query: str) -> List[str]:
        """EXPERTISE : Construit une strat√©gie de recherche experte bas√©e sur la structure juridique"""
        search_terms = []
        query_lower = query.lower()
        
        # Strat√©gie de base
        search_terms.extend([
            f"Article {article_num}",
            f"Article {article_num}.",
            query  # Requ√™te compl√®te de l'utilisateur
        ])
        
        # Strat√©gie sp√©cialis√©e par code juridique
        if code_type == "Code G√©n√©ral des Imp√¥ts (CGI)":
            search_terms.extend(self._build_cgi_search_terms(article_num, hierarchical_context, query_lower))
        elif code_type == "Code des Douanes":
            search_terms.extend(self._build_douane_search_terms(article_num, hierarchical_context, query_lower))
        
        # Strat√©gie hi√©rarchique intelligente
        if hierarchical_context['section']:
            search_terms.append(f"{hierarchical_context['section']} Article {article_num}")
        
        if hierarchical_context['sous_section']:
            search_terms.append(f"{hierarchical_context['sous_section']} Article {article_num}")
        
        if hierarchical_context['theme']:
            search_terms.extend([
                f"Article {article_num} {hierarchical_context['theme']}",
                f"{hierarchical_context['theme']} Article {article_num}"
            ])
        
        return search_terms
    
    def _build_cgi_search_terms(self, article_num: str, context: Dict, query_lower: str) -> List[str]:
        """Construit des termes de recherche sp√©cialis√©s pour le CGI"""
        terms = []
        
        # Article 4 CGI - Personnes imposables
        if article_num == "4" and any(term in query_lower for term in ['champ', 'application', 'personnes', 'imposables']):
            terms.extend([
                f"SECTION I. CHAMP D'APPLICATION Article {article_num}",
                f"Sous-section 1. PERSONNES IMPOSABLES Article {article_num}",
                f"Article {article_num}. I. (Loi",  # Pattern sp√©cifique CGI
                f"Les soci√©t√©s par actions Article {article_num}",
                f"soci√©t√©s √† responsabilit√© limit√©e Article {article_num}"
            ])
        
        # Article 7 CGI - B√©n√©fices imposables / P√©riode d'imposition (PRIORIT√â ABSOLUE)
        elif article_num == "7":
            # Si le contexte indique b√©n√©fices imposables, forcer cette recherche
            if context.get('section') == "SECTION II. BENEFICES IMPOSABLES" or any(term in query_lower for term in ['benefices', 'b√©n√©fices']):
                terms.extend([
                    f"SECTION II. BENEFICES IMPOSABLES Article {article_num}",
                    f"Sous-section 1. DETERMINATION DU BENEFICE NET IMPOSABLE Article {article_num}",
                    f"Article {article_num}. P√©riode d'imposition",
                    f"P√©riode d'imposition Article {article_num}",
                    f"BENEFICES IMPOSABLES Article {article_num}",
                    f"DETERMINATION DU BENEFICE NET IMPOSABLE Article {article_num}",
                    f"exercice comptable Article {article_num}",
                    f"exercice pr√©c√©dent Article {article_num}",
                    f"comptes √† la date du 31 d√©cembre Article {article_num}",
                    f"b√©n√©fices r√©alis√©s Article {article_num}"
                ])
                logger.info(f"üéØ Recherche sp√©cialis√©e Article 7 BENEFICES IMPOSABLES activ√©e")
            else:
                # Recherche g√©n√©rale pour Article 7
                terms.extend([
                    f"Article {article_num}. P√©riode d'imposition",
                    f"P√©riode d'imposition Article {article_num}"
                ])
        
        # Articles TVA
        elif any(term in query_lower for term in ['tva', 'taxe', 'valeur', 'ajout√©e']):
            terms.extend([
                f"TVA Article {article_num}",
                f"Taxe sur la valeur ajout√©e Article {article_num}",
                f"Article {article_num} assujetti",
                f"Article {article_num} redevable"
            ])
        
        return terms
    
    def _build_douane_search_terms(self, article_num: str, context: Dict, query_lower: str) -> List[str]:
        """Construit des termes de recherche sp√©cialis√©s pour le Code des Douanes"""
        terms = []
        
        # Termes g√©n√©raux douaniers
        terms.extend([
            f"Article {article_num} marchandise",
            f"Article {article_num} importation", 
            f"Article {article_num} exportation",
            f"Article {article_num} d√©douanement",
            f"Article {article_num} bureau de douane"
        ])
        
        # Contexte sp√©cialis√© selon la requ√™te
        if 'marchandise' in query_lower:
            terms.extend([
                f"esp√®ce d'une marchandise Article {article_num}",
                f"classification Article {article_num}",
                f"nomenclature Article {article_num}"
            ])
        
        if 'tarif' in query_lower or 'droit' in query_lower:
            terms.extend([
                f"tarif douanier Article {article_num}",
                f"droit de douane Article {article_num}"
            ])
        
        return terms
    
    def calculate_expert_priority_score(self, doc: str, metadata: Dict, article_num: str, 
                                       code_type: str, hierarchical_context: Dict, query_lower: str) -> int:
        """EXPERTISE : Calcule un score de priorit√© bas√© sur l'expertise juridique"""
        priority_score = 0
        doc_lower = doc.lower()
        
        # Score de base pour correspondance d'article exact
        if f"article {article_num}" in doc_lower:
            priority_score += 10
        
        # EXPERTISE CGI
        if code_type == "Code G√©n√©ral des Imp√¥ts (CGI)":
            priority_score += self._calculate_cgi_expertise_score(doc_lower, metadata, article_num, hierarchical_context, query_lower)
        
        # EXPERTISE Code des Douanes  
        elif code_type == "Code des Douanes":
            priority_score += self._calculate_douane_expertise_score(doc_lower, metadata, article_num, hierarchical_context, query_lower)
        
        # Score contextuel intelligent
        query_keywords = set(word for word in query_lower.split() if len(word) > 2)
        doc_keywords = set(word for word in doc_lower.split() if len(word) > 2)
        
        # Correspondance s√©mantique
        keyword_overlap = len(query_keywords.intersection(doc_keywords))
        priority_score += keyword_overlap * 3
        
        # Bonus pour structure hi√©rarchique
        hierarchical_terms = ['section', 'sous-section', 'chapitre', 'titre']
        hierarchical_bonus = sum(2 for term in hierarchical_terms if term in doc_lower)
        priority_score += hierarchical_bonus
        
        return priority_score
    
    def _calculate_cgi_expertise_score(self, doc_lower: str, metadata: Dict, article_num: str, context: Dict, query_lower: str) -> int:
        """Score d'expertise sp√©cialis√© CGI"""
        score = 0
        
        # Article 4 CGI - Expertise personnes imposables
        if article_num == "4" and any(term in query_lower for term in ['champ', 'application', 'personnes', 'imposables']):
            if any(term in doc_lower for term in [
                'personnes imposables', 'champ d\'application', 'section i',
                'soci√©t√©s par actions', 'responsabilit√© limit√©e', 'imp√¥t sur les soci√©t√©s'
            ]):
                score += 20
                logger.info(f"üéØ Expertise CGI Article 4 - Personnes imposables (+20)")
        
        # Article 7 CGI - PRIORIT√â ABSOLUE pour b√©n√©fices imposables
        elif article_num == "7":
            # Si la requ√™te mentionne explicitement b√©n√©fices imposables
            if any(term in query_lower for term in ['benefices', 'b√©n√©fices']) and 'imposables' in query_lower:
                if any(term in doc_lower for term in [
                    'b√©n√©fices imposables', 'benefices imposables', 'section ii',
                    'determination du benefice', 'd√©termination du b√©n√©fice',
                    'exercice pr√©c√©dent', 'comptes √† la date du 31 d√©cembre'
                ]):
                    score += 50  # SCORE MAXIMAL pour le bon Article 7
                    logger.info(f"üéØ PRIORIT√â ABSOLUE Article 7 - BENEFICES IMPOSABLES (+50)")
                else:
                    # P√©nalit√© s√©v√®re pour mauvais Article 7 (ex: m√©thode cadastrale)
                    score -= 30
                    logger.info(f"‚õî P√©nalit√© Article 7 non-b√©n√©fices imposables (-30)")
            
            # Si p√©riode d'imposition est mentionn√©e
            elif any(term in query_lower for term in ['periode', 'p√©riode']) and 'imposition' in query_lower:
                if 'p√©riode d\'imposition' in doc_lower or 'periode d\'imposition' in doc_lower:
                    score += 40
                    logger.info(f"üéØ Article 7 - P√©riode d'imposition (+40)")
                elif any(term in doc_lower for term in ['exercice pr√©c√©dent', 'exercice comptable', '31 d√©cembre']):
                    score += 35
                    logger.info(f"üéØ Article 7 - Contexte p√©riode (+35)")
                else:
                    score -= 25  # P√©nalit√© pour mauvais Article 7
                    logger.info(f"‚õî P√©nalit√© Article 7 hors p√©riode d'imposition (-25)")
            
            # Si d√©termination du b√©n√©fice
            elif any(term in query_lower for term in ['determination', 'd√©termination']) and any(term in query_lower for term in ['benefice', 'b√©n√©fice']):
                if any(term in doc_lower for term in [
                    'determination du benefice', 'd√©termination du b√©n√©fice',
                    'benefice net imposable', 'b√©n√©fice net imposable'
                ]):
                    score += 45
                    logger.info(f"üéØ Article 7 - D√©termination b√©n√©fice (+45)")
                else:
                    score -= 20
                    logger.info(f"‚õî P√©nalit√© Article 7 hors d√©termination b√©n√©fice (-20)")
        
        # Expertise TVA
        elif any(term in query_lower for term in ['tva', 'taxe']):
            if any(term in doc_lower for term in ['tva', 'taxe sur la valeur ajout√©e', 'assujetti', 'redevable']):
                score += 15
                logger.info(f"üéØ Expertise CGI TVA (+15)")
        
        return score
    
    def _calculate_douane_expertise_score(self, doc_lower: str, metadata: Dict, article_num: str, context: Dict, query_lower: str) -> int:
        """Score d'expertise sp√©cialis√© Code des Douanes"""
        score = 0
        
        # Expertise marchandises
        if 'marchandise' in query_lower:
            if any(term in doc_lower for term in ['marchandise', 'classification', 'nomenclature', 'esp√®ce']):
                score += 20
                logger.info(f"üéØ Expertise Douanes - Marchandises (+20)")
        
        # Expertise importation/exportation
        if any(term in query_lower for term in ['importation', 'exportation']):
            if any(term in doc_lower for term in ['importation', 'exportation', 'bureau de douane', 'transit']):
                score += 18
                logger.info(f"üéØ Expertise Douanes - Import/Export (+18)")
        
        # Expertise tarifs douaniers
        if any(term in query_lower for term in ['tarif', 'droit']):
            if any(term in doc_lower for term in ['tarif douanier', 'droit de douane', 'perception']):
                score += 16
                logger.info(f"üéØ Expertise Douanes - Tarifs (+16)")
        
        return score

    def deduplicate_references(self, references: List[Dict]) -> List[Dict]:
        """D√©duplique les r√©f√©rences intelligemment en gardant les plus pertinentes (score hybride)"""
        if not references:
            return []
        
        # IMPORTANT: Trier par score AVANT toute op√©ration pour garder les meilleurs
        # Le score hybride est dans '_score' - tri d√©croissant (meilleur score d'abord)
        references_sorted = sorted(references, key=lambda x: x.get('_score', 0), reverse=True)
        
        # Grouper par fichier
        file_groups = {}
        for ref in references_sorted:  # Utiliser la liste tri√©e par score
            file_name = ref.get('file_name', 'unknown')
            if file_name not in file_groups:
                file_groups[file_name] = []
            file_groups[file_name].append(ref)
        
        deduplicated = []
        
        for file_name, file_refs in file_groups.items():
            # Les r√©f√©rences sont d√©j√† tri√©es par score global
            # On garde juste les meilleures sans fusionner (pour garder la pr√©cision)
            
            # Limiter √† un nombre raisonnable par fichier TOUT EN GARDANT LES MEILLEURS
            # Augment√© √† 5 pour permettre plus de diversit√© (au lieu de 2)
            max_refs_per_file = 5
            top_refs = file_refs[:max_refs_per_file]
            
            deduplicated.extend(top_refs)
            
            logger.debug(f"ÔøΩ {file_name}: gard√© top {len(top_refs)} r√©f√©rences (score: {top_refs[0].get('_score', 0):.3f} √† {top_refs[-1].get('_score', 0) if top_refs else 0:.3f})")
        
        # Retrier par score global apr√®s d√©duplication
        deduplicated.sort(key=lambda x: x.get('_score', 0), reverse=True)
        
        logger.info(f"üîß D√©duplication intelligente: {len(references)} ‚Üí {len(deduplicated)} r√©f√©rences optimis√©es (tri√©es par score)")
        return deduplicated

    def analyze_search_results(self, query: str, references: List[Dict]) -> str:
        """Analyse les r√©sultats de recherche pour d√©terminer le type de contenu trouv√©"""
        if not references:
            return "general"
        
        # Analyser les sources des documents trouv√©s
        file_analysis = {}
        for ref in references:
            file_name = ref.get('file_name', '').lower()
            if file_name not in file_analysis:
                file_analysis[file_name] = 0
            file_analysis[file_name] += 1
        
        # Classifier selon les documents majoritaires
        impots_files = sum(1 for f in file_analysis.keys() if 'impot' in f or 'fiscal' in f)
        douanes_files = sum(1 for f in file_analysis.keys() if 'douane' in f)
        budget_files = sum(1 for f in file_analysis.keys() if any(x in f for x in ['budget', 'loi', 'finance', 'economique']))
        
        if budget_files > 0:
            logger.info(f"üìä Contenu BUDG√âTAIRE/√âCONOMIQUE d√©tect√©: {budget_files} fichiers")
            return "economique"
        elif impots_files > douanes_files:
            logger.info(f"üèõÔ∏è Contenu FISCAL d√©tect√©: {impots_files} fichiers")
            return "fiscal"
        elif douanes_files > 0:
            logger.info(f"üö¢ Contenu DOUANIER d√©tect√©: {douanes_files} fichiers")
            return "douanier"
        else:
            logger.info(f"üîÑ Contenu MIXTE d√©tect√©")
            return "mixte"

    def detect_query_domain(self, query: str) -> str:
        """D√©tecte si la question porte sur les imp√¥ts, les douanes, l'√©conomie, ou les deux"""
        query_lower = query.lower()
        
        # Mots-cl√©s sp√©cifiques aux technologies non fiscales
        non_fiscal_keywords = [
            'openshift', 'kubernetes', 'docker', 'flutter', 'android', 'ios', 
            'programmation', 'd√©veloppement', 'application mobile', 'mobile app', 
            'python', 'javascript', 'd√©velopper', 'programmer', 'coder',
            'web', 'site web', 'd√©ployer', 'cloud', 'aws', 'azure', 'git',
            'github', 'windows', 'linux', 'mac', 'apple', 'iphone', 'samsung',
            'facebook', 'instagram', 'twitter', 'r√©seau social'
        ]
        
        # Mots-cl√©s √©conomiques et budg√©taires (nouveaux documents)
        economie_keywords = [
            'pr√©vision', 'pr√©visions', 'croissance', 'secteur', 'secteurs',
            'agroalimentaire', 'chimique', 'industriel', 'industrie',
            'budget', 'budg√©taire', 'pib', '√©conomie', '√©conomique',
            'finances publiques', 'loi de finances', 'loi de finance', 'lfi', 'lfr',
            'investissement', 'investissements', 'd√©veloppement',
            'politique √©conomique', 'politique fiscale', 'strat√©gie', 'dette publique',
            'cadrage budg√©taire', 'projet de budget', 'gestion dette',
            'rapport √©conomique', 'financier', 'annex√©',
            'moyen terme', 'indicateur', 'performance', 'innovante', 'efficace',
            'r√©forme fiscale', 'modernisation', 'transformation'
        ]
        
        # NOUVEAU: Toujours rechercher dans tous les documents d'abord
        # La classification se fait APR√àS la recherche pour optimiser la r√©ponse
        logger.info(f"üåç RECHERCHE UNIVERSELLE - Tous les documents analys√©s")
        return "economie"  # Force la recherche universelle
        
        # V√©rifier d'abord si c'est une question clairement non fiscale
        # Mais √©viter les faux positifs avec des termes fiscaux
        fiscal_context_detected = any(term in query_lower for term in [
            'article', 'code', 'impot', 'imp√¥t', 'fiscal', 'douane', 'tva', 
            'champ d\'application', 'personnes imposables', 'contribuable'
        ])
        
        if not fiscal_context_detected:
            for keyword in non_fiscal_keywords:
                if keyword in query_lower:
                    logger.info(f"üö´ Question NON FISCALE d√©tect√©e: {keyword}")
                    return "non_fiscal"
        
        # Mots-cl√©s sp√©cifiques aux imp√¥ts
        impots_keywords = [
            'impot', 'imp√¥t', 'impots', 'imp√¥ts', 'fiscal', 'fiscale', 'fiscalit√©',
            'contribuable', 'contribuables', 'tva', 'is', 'ir', 'ircm', 'cgi',
            'd√©claration de revenus', 'assiette fiscale', 'base imposable',
            'personne imposable', 'personnes imposables', 'assujetti', 'redevable',
            'd√©duction fiscale', 'exon√©ration fiscale', 'cr√©dit d\'imp√¥t',
            # Termes juridiques des soci√©t√©s (domaine fiscal)
            'soci√©t√©', 'soci√©t√©s', 'societe', 'societes',
            'soci√©t√© par actions', 'soci√©t√© √† responsabilit√© limit√©e', 
            'sarl', 'sa', 'sas', 'soci√©t√© anonyme',
            'capital social', 'actionnaire', 'actionnaires', 'associ√©', 'associ√©s',
            'b√©n√©fice', 'b√©n√©fices', 'r√©sultat fiscal', 'imp√¥t sur les soci√©t√©s',
            'entreprise', 'entreprises', 'personne morale', 'personnes morales'
        ]
        
        # Mots-cl√©s sp√©cifiques aux douanes
        douanes_keywords = [
            'douane', 'douanes', 'douanier', 'douani√®re', 'd√©douanement',
            'importation', 'exportation', 'marchandise', 'marchandises',
            'bureau de douane', 'a√©roport douanier', 'port douanier',
            'transit', 'droit de douane', 'tarif douanier', 'nomenclature',
            'esp√®ce d\'une marchandise', 'classement douanier', 'origine des marchandises'
        ]
        
        # Compter les occurrences avec pond√©ration
        impots_score = 0
        douanes_score = 0
        
        # Termes √† fort poids pour les imp√¥ts (soci√©t√©s, fiscal)
        high_weight_impots = ['soci√©t√©', 'soci√©t√©s', 'societe', 'societes', 'sarl', 'sa', 'sas', 
                            'soci√©t√© par actions', 'soci√©t√© √† responsabilit√© limit√©e', 'imp√¥t sur les soci√©t√©s',
                            'capital social', 'actionnaire', 'b√©n√©fice', 'r√©sultat fiscal']
        
        # Termes √† fort poids pour les douanes
        high_weight_douanes = ['marchandise', 'marchandises', 'd√©douanement', 'importation', 'exportation',
                            'bureau de douane', 'tarif douanier', 'esp√®ce d\'une marchandise']
        
        # Calculer les scores avec pond√©ration
        for keyword in impots_keywords:
            if keyword in query_lower:
                weight = 3 if keyword in high_weight_impots else 1
                impots_score += weight
                
        for keyword in douanes_keywords:
            if keyword in query_lower:
                weight = 3 if keyword in high_weight_douanes else 1
                douanes_score += weight
        
        # D√©terminer le domaine
        if impots_score > douanes_score:
            logger.info(f"üèõÔ∏è Question d√©tect√©e comme FISCALE/IMP√îTS (score: {impots_score} vs {douanes_score})")
            return "impots"
        elif douanes_score > impots_score:
            logger.info(f"üö¢ Question d√©tect√©e comme DOUANI√àRE (score: {douanes_score} vs {impots_score})")
            return "douanes"
        else:
            logger.info(f"üîÑ Question G√âN√âRALE ou ambigu√´ (imp√¥ts: {impots_score}, douanes: {douanes_score})")
            return "general"

    def _init_hierarchie_client(self):
        """Initialise le syst√®me hi√©rarchique √† la demande"""
        if not self._hierarchie_initialized and HIERARCHIE_AVAILABLE:
            try:
                self.hierarchie_client = HierarchieJuridiqueClient(base_client=self)
                logger.info("‚úÖ Syst√®me hi√©rarchique V2.0 initialis√© √† la demande")
                self._hierarchie_initialized = True
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è Erreur initialisation syst√®me hi√©rarchique: {e}")
                self._hierarchie_initialized = True  # √âviter de retry
        elif not HIERARCHIE_AVAILABLE:
            logger.warning("‚ö†Ô∏è Syst√®me hi√©rarchique V2.0 non disponible")
            self._hierarchie_initialized = True

    def  search_context_with_references(self, query: str, limit: int = 5) -> Dict:
        """Recherche hybride avec syst√®me hi√©rarchique V2.0 en priorit√©"""
        if not self.collection:
            logger.warning("  Aucune collection ChromaDB disponible")
            return {"context": "", "references": []}
        
        try:
            # üî• TEMPORAIRE: D√©sactiver le syst√®me hi√©rarchique pour corriger les r√©f√©rences
            # self._init_hierarchie_client()  # Initialiser √† la demande
            
            # if self.hierarchie_client:
            #     logger.info("üèõÔ∏è Utilisation du syst√®me hi√©rarchique V2.0")
            #     hierarchie_result = self.hierarchie_client.rechercher_hierarchique(query)
            #     
            #     if hierarchie_result.get("context") and hierarchie_result.get("references"):
            #         logger.info(f"‚úÖ R√©sultat hi√©rarchique trouv√©: {hierarchie_result.get('type_recherche', 'N/A')}")
            #         return hierarchie_result
            #     else:
            #         logger.info("‚ö†Ô∏è Syst√®me hi√©rarchique: aucun r√©sultat, fallback vers recherche classique")
            
            # Utiliser directement la recherche classique qui fonctionne bien
            logger.info("üîÑ Utilisation recherche classique (temporaire - r√©f√©rences correctes)")
            
            # D√©tecter le domaine de la question
            query_domain = self.detect_query_domain(query)
            
            # Recherche sp√©cialis√©e pour les articles
            article_result = self.search_specific_article(query)
            if article_result["context"]:
                logger.info(f"üéØ Article sp√©cifique trouv√©: {query}")
                return article_result
            
            # G√©n√©rer embedding de la requ√™te pour recherche vectorielle pure
            query_embedding = self.generate_embeddings(query)
            if not query_embedding:
                logger.warning("  Impossible de g√©n√©rer embedding pour la requ√™te")
                return {"context": "", "references": []}
            
            # üî• RECHERCHE HYBRIDE: Vectoriel + BM25 (Intelligence naturelle)
            logger.info(f"üîç Recherche HYBRIDE INTELLIGENTE (Vectoriel + BM25): {query[:50]}...")
            
            # Pr√©parer les filtres selon le domaine
            where_filter = {}
            if query_domain == "impots":
                where_filter = {"file_name": {"$eq": "Senegal-Code-des-impot.pdf"}}
                logger.info("üìä Recherche limit√©e au Code des Imp√¥ts")
            elif query_domain == "douanes":
                where_filter = {"file_name": {"$eq": "Senegal-Code-2014-des-douanes.pdf"}}
                logger.info("üö¢ Recherche limit√©e au Code des Douanes")
            elif query_domain == "economie":
                # Pas de filtre = recherche dans TOUS les documents
                where_filter = {}
                logger.info("üåç Recherche √âCONOMIQUE dans TOUS les documents index√©s")
            else:
                # Domaine g√©n√©ral ou ambigu√´ = recherche dans tous les documents aussi
                where_filter = {}
                logger.info("üîÑ Recherche G√âN√âRALE dans tous les documents")
            
            # √âTAPE 1: Recherche VECTORIELLE (embeddings)
            # Augmenter significativement le nombre de r√©sultats pour mieux capturer les documents pertinents
            n_vectorial_results = min(100, limit * 20)  # Au moins 100 r√©sultats ou 20x la limite
            
            if where_filter:
                vectorial_results = self.collection.query(
                    query_embeddings=[query_embedding],
                    n_results=n_vectorial_results,
                    where=where_filter,
                    include=['documents', 'metadatas', 'distances']
                )
            else:
                vectorial_results = self.collection.query(
                    query_embeddings=[query_embedding],
                    n_results=n_vectorial_results,
                    include=['documents', 'metadatas', 'distances']
                )
            
            # √âTAPE 2: R√©cup√©rer TOUS les documents pour BM25
            # (Optimisation: on pourrait limiter au m√™me domaine)
            if where_filter:
                all_docs_data = self.collection.get(
                    where=where_filter,
                    include=['documents', 'metadatas']
                )
            else:
                all_docs_data = self.collection.get(
                    include=['documents', 'metadatas']
                )
            
            all_documents = all_docs_data['documents']
            all_metadatas = all_docs_data['metadatas']
            
            logger.info(f"üìö Corpus BM25: {len(all_documents)} documents")
            
            # Calculer BM25 scores
            bm25 = BM25()
            
            # Calculer IDF sur tout le corpus
            idf = bm25.compute_idf(all_documents)
            
            # Calculer longueur moyenne des documents
            avg_doc_len = sum(len(bm25.tokenize(doc)) for doc in all_documents) / len(all_documents)
            
            # Calculer le score BM25 pour chaque document
            bm25_scores = []
            for doc in all_documents:
                score = bm25.score(query, doc, avg_doc_len, idf)
                bm25_scores.append(score)
            
            logger.info(f"‚úÖ BM25 scores calcul√©s pour {len(bm25_scores)} documents")
            
            # √âTAPE 3: COMBINER les scores vectoriels et BM25
            # Normaliser les scores pour pouvoir les combiner
            
            # Scores vectoriels (distances ChromaDB - plus petit = meilleur)
            vectorial_docs = vectorial_results['documents'][0] if vectorial_results['documents'] else []
            vectorial_metas = vectorial_results['metadatas'][0] if vectorial_results['metadatas'] else []
            vectorial_distances = vectorial_results['distances'][0] if vectorial_results.get('distances') else []
            
            # Normaliser les distances vectorielles (0-1, o√π 1 = meilleur)
            if vectorial_distances:
                max_dist = max(vectorial_distances) if vectorial_distances else 1
                min_dist = min(vectorial_distances) if vectorial_distances else 0
                range_dist = max_dist - min_dist if max_dist != min_dist else 1
                
                vectorial_scores_normalized = [
                    1 - ((dist - min_dist) / range_dist) for dist in vectorial_distances
                ]
            else:
                vectorial_scores_normalized = [1.0] * len(vectorial_docs)
            
            # Normaliser les scores BM25 (0-1, o√π 1 = meilleur)
            if bm25_scores:
                max_bm25 = max(bm25_scores)
                min_bm25 = min(bm25_scores)
                range_bm25 = max_bm25 - min_bm25 if max_bm25 != min_bm25 else 1
                
                bm25_scores_normalized = [
                    (score - min_bm25) / range_bm25 for score in bm25_scores
                ]
            else:
                bm25_scores_normalized = [0.0] * len(all_documents)
            
            # √âTAPE 4: Combiner les r√©sultats
            # Cr√©er un dictionnaire doc_text -> (metadata, vectorial_score, bm25_score)
            combined_results = {}
            
            # Ajouter les r√©sultats vectoriels
            for i, doc in enumerate(vectorial_docs):
                combined_results[doc] = {
                    'metadata': vectorial_metas[i] if i < len(vectorial_metas) else {},
                    'vectorial_score': vectorial_scores_normalized[i] if i < len(vectorial_scores_normalized) else 0,
                    'bm25_score': 0,  # Sera mis √† jour ensuite
                    'content': doc
                }
            
            # Ajouter/mettre √† jour les scores BM25
            for i, doc in enumerate(all_documents):
                if doc in combined_results:
                    combined_results[doc]['bm25_score'] = bm25_scores_normalized[i]
                else:
                    # Document trouv√© par BM25 mais pas par vectoriel
                    combined_results[doc] = {
                        'metadata': all_metadatas[i] if i < len(all_metadatas) else {},
                        'vectorial_score': 0,
                        'bm25_score': bm25_scores_normalized[i],
                        'content': doc
                    }
            
            # Calculer le score hybride combin√© avec d√©tection de mots rares
            # D√©tecter si la requ√™te contient des mots rares (indicateur: mot peu fr√©quent)
            query_tokens = bm25.tokenize(query)
            rare_word_detected = False
            
            # Un mot est consid√©r√© comme rare si son IDF est √©lev√© (> seuil)
            if query_tokens:
                avg_idf = sum(idf.get(token, 0) for token in query_tokens) / len(query_tokens)
                # Si l'IDF moyen est √©lev√© (> 5), on a probablement des mots rares/sp√©cifiques
                if avg_idf > 5.0:
                    rare_word_detected = True
                    logger.info(f"üîç Mots rares d√©tect√©s (IDF moyen: {avg_idf:.2f}) - Privil√©gier BM25")
            
            # Ajuster les poids selon la pr√©sence de mots rares
            if rare_word_detected:
                # Pour mots rares: privil√©gier BM25 (matching exact)
                alpha = 0.3  # Poids vectoriel r√©duit
                beta = 0.7   # Poids BM25 augment√©
                logger.info("‚öñÔ∏è Poids: 30% Vectoriel + 70% BM25 (mots rares)")
            else:
                # Pour requ√™tes normales: √©quilibre 50/50
                alpha = 0.5  # Poids vectoriel
                beta = 0.5   # Poids BM25
                logger.info("‚öñÔ∏è Poids: 50% Vectoriel + 50% BM25 (√©quilibre)")
            
            for doc_text in combined_results:
                v_score = combined_results[doc_text]['vectorial_score']
                b_score = combined_results[doc_text]['bm25_score']
                combined_results[doc_text]['hybrid_score'] = alpha * v_score + beta * b_score
            
            # Trier par score hybride d√©croissant
            sorted_results = sorted(
                combined_results.items(),
                key=lambda x: x[1]['hybrid_score'],
                reverse=True
            )
            
            # Prendre beaucoup plus de r√©sultats pour maximiser les chances de trouver les bons documents
            # Augment√© √† 50 pour une meilleure couverture (au lieu de limit * 2)
            top_results = sorted_results[:min(50, len(sorted_results))]
            
            logger.info(f"üéØ Top 10 scores hybrides:")
            for i, (doc, data) in enumerate(top_results[:10]):
                article_ref = data['metadata'].get('article_ref', 'N/A')[:50]
                logger.info(f"  #{i+1}: {article_ref} - Hybride: {data['hybrid_score']:.3f} (V:{data['vectorial_score']:.3f} + BM25:{data['bm25_score']:.3f})")
            
            # √âTAPE 5: Construire les r√©f√©rences
            context_parts = []
            references = []
            
            for doc_text, data in top_results:
                metadata = data['metadata']
                
                if metadata:
                    file_name = metadata.get('file_name', 'Document inconnu')
                    file_path = metadata.get('file_path', '')
                    line_start = metadata.get('line_start', 1)
                    line_end = metadata.get('line_end', 1)
                    page_start = metadata.get('page_start', 1)
                    page_end = metadata.get('page_end', 1)
                    
                    # Cr√©er la r√©f√©rence pr√©cise
                    if line_start == line_end:
                        location = f"ligne {line_start}"
                    else:
                        location = f"lignes {line_start}-{line_end}"
                    
                    if page_start == page_end:
                        page_info = f"page {page_start}"
                    else:
                        page_info = f"pages {page_start}-{page_end}"
                    
                    # Extraire les informations d'article
                    article_ref = metadata.get('article_ref', 'Section g√©n√©rale')
                    article_number = metadata.get('article_number', '')
                    section = metadata.get('section', '')
                    titre = metadata.get('titre', '')
                    
                    reference = {
                        'file_name': file_name,
                        'file_path': file_path,
                        'location': location,
                        'page_info': page_info,
                        'line_start': line_start,
                        'line_end': line_end,
                        'page_start': page_start,
                        'page_end': page_end,
                        'article_ref': article_ref,
                        'article_number': article_number,
                        'section': section,
                        'titre': titre,
                        'snippet': doc_text[:150] + "..." if len(doc_text) > 150 else doc_text,
                        'content': doc_text,
                        '_score': data['hybrid_score']  # Score hybride pour tri
                    }
                    references.append(reference)
                    
                    # Cr√©er une source info enrichie
                    if article_ref and article_ref != 'Section g√©n√©rale':
                        source_info = f"[üìÑ {file_name} - {article_ref}, {page_info}, {location}]"
                    else:
                        source_info = f"[üìÑ {file_name}, {page_info}, {location}]"
                    
                    # üîß LIMITATION DRASTIQUE pour √©viter timeouts Mistral
                    # R√©duire le texte √† maximum 200 caract√®res par r√©f√©rence
                    truncated_text = doc_text[:200] + "..." if len(doc_text) > 200 else doc_text
                    context_parts.append(f"{source_info}\n{truncated_text}")
                else:
                    context_parts.append(doc_text)
            
            # D√©dupliquer les r√©f√©rences intelligemment
            deduplicated_references = self.deduplicate_references(references)
            
            # Augmenter la limite finale pour retourner plus de documents pertinents
            # R√©duction drastique pour √©viter les timeouts Mistral
            final_limit = min(10, max(limit * 2, 8))
            final_references = deduplicated_references[:final_limit]
            final_context_parts = context_parts[:len(final_references)]
            
            logger.info(f"‚úÖ Recherche HYBRIDE termin√©e: {len(final_references)} documents uniques (sur {len(deduplicated_references)} apr√®s d√©duplication)")
            
            # ANALYSE POST-RECHERCHE: Classifier le contenu trouv√©
            content_type = self.analyze_search_results(query, final_references)
            logger.info(f"üìã Analyse contenu trouv√©: {content_type}")
            
            return {
                "context": "\n\n".join(final_context_parts),
                "references": final_references,
                "content_type": content_type  # Nouveau: type de contenu d√©tect√©
            }
            
        except Exception as e:
            logger.error(f"‚ùå Erreur recherche HYBRIDE: {e}")
            import traceback
            logger.error(traceback.format_exc())
            return {"context": "", "references": []}

    def search_specific_article(self, query: str) -> Dict:
        """Recherche intelligente d'articles bas√©e sur la compr√©hension naturelle du contexte"""
        import re
        logger.info(f"üß† Recherche intelligente: {query}")
        
        if not self.collection:
            return {"context": "", "references": []}
        
        try:
            # Extraction simple des num√©ros d'articles
            article_numbers = re.findall(r'article\s+(\d+)', query.lower())
            if not article_numbers:
                article_numbers = re.findall(r'(\d+)', query)[:1]  # Premier nombre trouv√©
            
            if not article_numbers:
                return {"context": "", "references": []}
            
            unique_articles = list(dict.fromkeys(article_numbers))
            logger.info(f"üéØ Articles d√©tect√©s: {unique_articles}")
            
            # Recherche contextuelle simple et intelligente
            all_results = []
            
            for article_num in unique_articles:
                # Strat√©gies de recherche simples mais efficaces
                search_terms = [
                    query,  # Requ√™te compl√®te de l'utilisateur
                    f"Article {article_num}",
                    f"Article {article_num} " + " ".join([w for w in query.split() if w.lower() not in ['article', article_num, 'du', 'de', 'la', 'le']])
                ]
                
                for search_term in search_terms:
                    try:
                        # Recherche vectorielle simple
                        query_embedding = self.generate_embeddings(search_term)
                        if query_embedding:
                            results = self.collection.query(
                                query_embeddings=[query_embedding],
                                n_results=15,  # Plus de r√©sultats pour trouver le bon article
                                include=['documents', 'metadatas', 'distances']
                            )
                            
                            if results['documents'][0]:
                                for i, doc in enumerate(results['documents'][0]):
                                    metadata = results['metadatas'][0][i] if i < len(results['metadatas'][0]) else {}
                                    
                                    # Score intelligent bas√© sur la correspondance naturelle
                                    score = self._calculate_natural_score(doc, metadata, article_num, query.lower())
                                    
                                    # Seuil adaptatif selon le num√©ro d'article
                                    min_score = 5
                                    if len(article_num) == 1:  # Articles √† 1 chiffre plus rares
                                        min_score = -50  # Seuil plus bas pour Article 1, 2, etc.
                                    
                                    if score > min_score:  # Seuil de pertinence adaptatif
                                        result_item = {
                                            'document': doc,
                                            'metadata': metadata,
                                            'distance': results['distances'][0][i] if results.get('distances') and i < len(results['distances'][0]) else 1.0,
                                            'priority_score': score,
                                            'search_term': search_term
                                        }
                                        all_results.append(result_item)
                                        logger.info(f"‚úÖ Article {article_num} trouv√© (score naturel: {score})")
                                        
                    except Exception as e:
                        continue  # Passer au terme suivant silencieusement
            
            if not all_results:
                return {"context": "", "references": []}
            
            # Trier par score et prendre les meilleurs
            all_results.sort(key=lambda x: x['priority_score'], reverse=True)
            best_results = all_results[:5]  # Plus de r√©sultats pour analyse
            
            # Construire la r√©ponse
            context_parts = []
            references = []
            
            for result in best_results:
                doc = result['document']
                metadata = result['metadata']
                
                # üîß CORRECTION: Ajouter les propri√©t√©s manquantes pour JavaScript
                page_start = metadata.get('page_start', 1)
                page_end = metadata.get('page_end', page_start)
                line_start = metadata.get('line_start', 1)
                line_end = metadata.get('line_end', line_start)
                file_path = metadata.get('file_path', '')
                
                # Cr√©er page_info et location comme dans search_context_with_references
                if page_start == page_end:
                    page_info = f"page {page_start}"
                else:
                    page_info = f"pages {page_start}-{page_end}"
                
                if line_start == line_end:
                    location = f"ligne {line_start}"
                else:
                    location = f"lignes {line_start}-{line_end}"
                
                reference = {
                    'file_name': metadata.get('file_name', 'Document'),
                    'file_path': file_path,
                    'article_ref': metadata.get('article_ref', f'Article {article_numbers[0]}'),
                    'page': page_start,  # Garder l'ancienne propri√©t√© pour compatibilit√©
                    'page_info': page_info,  # ‚úÖ Nouvelle propri√©t√© attendue par JavaScript
                    'location': location,    # ‚úÖ Nouvelle propri√©t√© attendue par JavaScript
                    'line_start': line_start, # ‚úÖ Propri√©t√© attendue par JavaScript
                    'line_end': line_end,     # ‚úÖ Propri√©t√© attendue par JavaScript
                    'page_start': page_start,
                    'page_end': page_end,
                    'content': doc,
                    '_score': result['priority_score'],
                    'snippet': doc[:300] + "..." if len(doc) > 300 else doc
                }
                references.append(reference)
                
                source_info = f"[üìÑ {reference['file_name']} - {reference['article_ref']}, page {reference['page']}]"
                context_parts.append(f"{source_info}\n{doc}")
            
            logger.info(f"‚úÖ {len(references)} r√©sultat(s) intelligent(s)")
            return {
                "context": "\n\n".join(context_parts),
                "references": references
            }
                
        except Exception as e:
            logger.error(f"‚ùå Erreur recherche: {e}")
            return {"context": "", "references": []}


    def _calculate_natural_score(self, doc: str, metadata: Dict, article_num: str, query_lower: str) -> int:
        """Score naturel bas√© sur la compr√©hension du contexte sans r√®gles"""
        score = 0
        doc_lower = doc.lower()
        article_ref = metadata.get('article_ref', '').lower()
        
        # PRIORIT√â ABSOLUE: Article exact trouv√©
        if f"article {article_num}" in doc_lower:
            score += 50  # Score tr√®s √©lev√© pour article exact
        
        # V√©rification ULTRA STRICTE du num√©ro d'article dans article_ref
        import re
        
        # Extraction du num√©ro d'article exact avec patterns stricts
        article_patterns = [
            r'article\s+(\d+)(?:\s|\.|\:|$)',  # Article suivi d'espace, point, deux-points ou fin
            r'article\s+(\d+)(?:\s+[a-zA-Z])',  # Article suivi d'espace puis lettre
        ]
        
        found_article_num = None
        for pattern in article_patterns:
            article_match = re.search(pattern, article_ref)
            if article_match:
                found_article_num = article_match.group(1)
                break
        
        if found_article_num:
            if found_article_num == article_num:
                score += 200  # BONUS √âNORME pour article exact
                
                # BONUS SUPPL√âMENTAIRE pour correspondance exacte stricte
                # V√©rifier que ce n'est pas une sous-partie d'un autre num√©ro
                if f"article {article_num} " in article_ref or f"article {article_num}." in article_ref:
                    score += 50  # Bonus pour s√©parateur strict
                    
            elif article_num in found_article_num:
                # Cas o√π on cherche Article 1 mais on trouve Article 157
                if len(article_num) < len(found_article_num):
                    score -= 100  # GROSSE P√âNALIT√â pour faux positif (1 dans 157)
                else:
                    score -= 30   # P√©nalit√© moindre pour autres cas
            else:
                score -= 50   # P√âNALIT√â pour mauvais article
        
        # Correspondance des mots de la requ√™te utilisateur
        query_words = set(word for word in query_lower.split() if len(word) > 2)
        doc_words = set(word for word in doc_lower.split() if len(word) > 2)
        
        # Score bas√© sur la correspondance des mots
        common_words = query_words.intersection(doc_words)
        score += len(common_words) * 4
        
        # Bonus pour les concepts importants d√©tect√©s naturellement
        important_concepts = {
            'benefices': ['benefices', 'b√©n√©fices', 'imposables'],
            'determination': ['determination', 'd√©termination', 'benefice', 'b√©n√©fice'],
            'periode': ['periode', 'p√©riode', 'imposition', 'exercice'],
            'personnes': ['personnes', 'imposables', 'champ', 'application'],
            'societes': ['soci√©t√©', 'soci√©t√©s', 'sarl', 'sa'],
            'fiscal': ['fiscal', 'fiscale', 'impot', 'imp√¥t'],
            'douanes': ['douanes', 'douanier', 'marchandises'],
            'application': ['application', 'champ', 'dispositions']
        }
        
        for concept, terms in important_concepts.items():
            if any(term in query_lower for term in terms):
                concept_matches = sum(1 for term in terms if term in doc_lower)
                if concept_matches > 0:
                    score += concept_matches * 6
        
        # Bonus pour la pr√©sence de structure
        if any(struct in doc_lower for struct in ['section', 'sous-section', 'chapitre']):
            score += 3
        
        # BONUS SP√âCIAL pour "p√©riode d'imposition" si recherch√©
        if 'periode' in query_lower or 'p√©riode' in query_lower:
            if 'p√©riode d\'imposition' in doc_lower or 'periode d\'imposition' in doc_lower:
                score += 30  # Bonus important pour concept cl√©
        
        # BONUS pour correspondance de longueur de num√©ro d'article
        if found_article_num and len(found_article_num) == len(article_num):
            score += 20  # Bonus pour m√™me longueur de num√©ro
        
        return score

    def search_context(self, query: str, limit: int = 5) -> str:
        """Recherche le contexte dans les documents index√©s (version simple)"""
        result = self.search_context_with_references(query, limit)
        return result.get("context", "")
    
    def should_use_rag(self, message: str) -> bool:
        """Mode RAG strict - Force l'utilisation exclusive des documents index√©s"""
        # Fonction simplifi√©e en mode RAG strict
        return True

    def is_greeting_or_general(self, message: str) -> bool:
        """D√©tecte si le message est une simple salutation - Version minimaliste pour mode RAG strict"""
        message_lower = message.lower().strip()
        
        # En mode RAG strict, seules les salutations tr√®s simples sont trait√©es diff√©remment
        greeting_words = ['salut', 'bonjour', 'bonsoir', 'hello', 'hi', 'hey']
        
        # Salutations simples uniquement
        if any(greeting in message_lower for greeting in greeting_words):
            # Maximum 3 mots pour une salutation
            if len(message_lower.split()) <= 3:
                return True
        return False
    
    def generate_greeting_response(self, message: str) -> str:
        """G√©n√®re une r√©ponse simplifi√©e aux salutations - Mode RAG strict"""
        # En mode RAG strict, r√©ponse unique et courte qui rappelle la sp√©cialisation fiscale
        return """Bonjour ! Je suis LexFin, votre assistant IA sp√©cialis√© UNIQUEMENT en fiscalit√© s√©n√©galaise.

‚ö†Ô∏è MODE RAG STRICT : Je r√©ponds exclusivement sur la base des documents fiscaux index√©s.

üîç Posez-moi vos questions sur :
‚Ä¢ Code G√©n√©ral des Imp√¥ts (CGI) du S√©n√©gal
‚Ä¢ Code des Douanes s√©n√©galais
‚Ä¢ Articles et textes fiscaux s√©n√©galais"""
    def open_file_at_location(self, file_path: str, line_number: int = 1) -> bool:
        """Ouvre un fichier √† une ligne sp√©cifique"""
        try:
            import subprocess
            import sys
            
            # Corriger le chemin du fichier
            corrected_path = file_path
            
            # Si le chemin n'existe pas, essayer de le corriger
            if not os.path.exists(file_path):
                logger.info(f"Correction du chemin: {file_path}")
                
                # Essayer avec le r√©pertoire de travail actuel
                if not os.path.isabs(file_path):
                    corrected_path = os.path.join(os.getcwd(), file_path)
                    logger.info(f"Tentative chemin absolu: {corrected_path}")
                
                # Si toujours pas trouv√©, essayer avec le r√©pertoire documents
                if not os.path.exists(corrected_path):
                    # Extraire juste le nom du fichier
                    filename = os.path.basename(file_path)
                    # Si le nom de fichier semble concat√©n√© avec "documents"
                    if filename.startswith('documents') and len(filename) > 9:
                        filename = filename[9:]  # Enlever "documents"
                    
                    # Construire le chemin correct
                    corrected_path = os.path.join(self.watch_dir, filename)
                    logger.info(f"Tentative avec r√©pertoire surveill√©: {corrected_path}")
                
                # Derni√®re tentative: chercher le fichier dans le r√©pertoire documents
                if not os.path.exists(corrected_path):
                    filename = os.path.basename(file_path)
                    if filename.startswith('documents'):
                        filename = filename[9:]
                    
                    # Chercher tous les fichiers qui correspondent
                    for file_in_dir in self.watch_dir.rglob('*'):
                        if file_in_dir.name == filename:
                            corrected_path = str(file_in_dir)
                            logger.info(f"Fichier trouv√©: {corrected_path}")
                            break
            
            # V√©rifier que le fichier existe maintenant
            if not os.path.exists(corrected_path):
                logger.error(f"Fichier introuvable m√™me apr√®s correction: {file_path} -> {corrected_path}")
                return False
            
            logger.info(f"Ouverture du fichier: {corrected_path} √† la ligne {line_number}")
            
            # D√©terminer l'extension du fichier pour choisir la bonne application
            # Utiliser le chemin original pour d√©tecter l'extension si le corrig√© ne marche pas
            original_extension = Path(file_path).suffix.lower()
            corrected_extension = Path(corrected_path).suffix.lower()
            
            # Prendre l'extension qui a l'air correcte
            if original_extension and original_extension in ['.pdf', '.docx', '.doc', '.xlsx', '.xls', '.txt', '.md']:
                file_extension = original_extension
            else:
                file_extension = corrected_extension
            
            logger.info(f"Extension d√©tect√©e: {file_extension} (original: {original_extension}, corrig√©: {corrected_extension})")
            logger.info(f"Chemin original: {file_path}")
            logger.info(f"Chemin corrig√©: {corrected_path}")
            
            # Ouvrir selon l'OS et le type de fichier
            if sys.platform.startswith('win'):
                # Pour les fichiers PDF
                if file_extension == '.pdf':
                    try:
                        # Essayer Adobe Reader d'abord
                        subprocess.run(['start', '', corrected_path], shell=True, check=False)
                        logger.info(f"Fichier PDF ouvert avec l'application par d√©faut")
                        return True
                    except:
                        # Fallback avec l'explorateur Windows
                        os.startfile(corrected_path)
                        logger.info(f"Fichier PDF ouvert avec l'explorateur")
                        return True
                
                # Pour les fichiers Word (.docx, .doc)
                elif file_extension in ['.docx', '.doc', '.odt']:
                    try:
                        # Ouvrir avec Word ou l'application par d√©faut
                        os.startfile(corrected_path)
                        logger.info(f"Fichier Word ouvert avec l'application par d√©faut")
                        return True
                    except Exception as e:
                        logger.error(f"Erreur ouverture fichier Word: {e}")
                        return False
                
                # Pour les fichiers Excel
                elif file_extension in ['.xlsx', '.xls', '.csv']:
                    try:
                        os.startfile(corrected_path)
                        logger.info(f"Fichier Excel ouvert avec l'application par d√©faut")
                        return True
                    except Exception as e:
                        logger.error(f"Erreur ouverture fichier Excel: {e}")
                        return False
                
                # Pour les fichiers texte - utiliser un √©diteur de texte
                elif file_extension in ['.txt', '.md', '.json', '.py', '.js', '.html', '.css']:
                    try:
                        # Essayer VS Code d'abord (meilleur pour aller √† une ligne)
                        subprocess.run(['code', '-g', f'{corrected_path}:{line_number}'], check=False)
                        logger.info(f"Fichier texte ouvert avec VS Code √† la ligne {line_number}")
                        return True
                    except:
                        try:
                            # Essayer Notepad++ avec num√©ro de ligne
                            subprocess.run(['notepad++', f'-n{line_number}', corrected_path], check=False)
                            logger.info(f"Fichier texte ouvert avec Notepad++ √† la ligne {line_number}")
                            return True
                        except:
                            try:
                                # Fallback Notepad simple
                                subprocess.run(['notepad', corrected_path], check=False)
                                logger.info(f"Fichier texte ouvert avec Notepad")
                                return True
                            except:
                                # Dernier fallback
                                os.startfile(corrected_path)
                                logger.info(f"Fichier ouvert avec application par d√©faut")
                                return True
                
                # Pour tous les autres types de fichiers
                else:
                    try:
                        os.startfile(corrected_path)
                        logger.info(f"Fichier ouvert avec l'application par d√©faut")
                        return True
                    except Exception as e:
                        logger.error(f"Erreur ouverture fichier: {e}")
                        return False
            else:
                # Linux/Mac - ouvrir selon le type de fichier
                if file_extension == '.pdf':
                    # Lecteurs PDF courants sur Linux/Mac
                    pdf_viewers = ['evince', 'okular', 'xpdf', 'open']  # 'open' pour Mac
                    for viewer in pdf_viewers:
                        try:
                            subprocess.run([viewer, corrected_path], check=False)
                            logger.info(f"Fichier PDF ouvert avec {viewer}")
                            return True
                        except:
                            continue
                    
                    # Fallback
                    subprocess.run(['xdg-open', corrected_path], check=False)
                    logger.info(f"Fichier PDF ouvert avec xdg-open")
                    return True
                
                elif file_extension in ['.docx', '.doc', '.odt', '.xlsx', '.xls']:
                    # Documents Office
                    try:
                        subprocess.run(['xdg-open', corrected_path], check=False)
                        logger.info(f"Fichier Office ouvert avec xdg-open")
                        return True
                    except Exception as e:
                        logger.error(f"Erreur ouverture fichier Office: {e}")
                        return False
                
                else:
                    # Fichiers texte - essayer diff√©rents √©diteurs avec support des lignes
                    editors = ['code', 'gedit', 'nano', 'vim']
                    for editor in editors:
                        try:
                            if editor == 'code':
                                subprocess.run([editor, '-g', f'{corrected_path}:{line_number}'], check=False)
                            else:
                                subprocess.run([editor, corrected_path], check=False)
                            logger.info(f"Fichier texte ouvert avec {editor}")
                            return True
                        except:
                            continue
                            
                    # Fallback
                    subprocess.run(['xdg-open', corrected_path], check=False)
                    logger.info(f"Fichier ouvert avec xdg-open")
                    return True
                
        except Exception as e:
            logger.error(f"Erreur ouverture fichier: {e}")
            return False

    def generate_natural_greeting_response(self, message: str) -> str:
        """G√©n√®re une r√©ponse naturelle aux salutations en utilisant Mistral directement"""
        try:
            # Prompt pour que Mistral r√©ponde naturellement aux salutations
            greeting_prompt = f"""Tu es LexFin, un assistant IA intelligent sp√©cialis√© pour les professionnels et citoyens s√©n√©galais.

L'utilisateur te dit: "{message}"

üá´üá∑ LANGUE OBLIGATOIRE: Tu DOIS r√©pondre UNIQUEMENT en fran√ßais. Aucun mot en anglais ou autre langue n'est autoris√©.

IMPORTANT: Tu es un expert polyvalent en droit s√©n√©galais qui ma√Ætrise :
- Code des Imp√¥ts et fiscalit√© (CGI, DGI, TVA, IS, IR)
- Code des Douanes et proc√©dures douani√®res
- Lois de Finances et budget de l'√âtat 
- Documents √©conomiques et financiers publics
- R√©glementations et arr√™t√©s administratifs

R√©ponds de fa√ßon naturelle et professionnelle en fran√ßais uniquement:
- Pr√©sente-toi comme LexFin, l'assistant expert en droit s√©n√©galais
- Pr√©cise tes domaines : fiscal, douanier, budg√©taire, √©conomique, r√©glementaire
- Mentionne que tu peux analyser documents officiels (codes, lois, budgets, rapports)
- Reste professionnel et utilise des √©mojis appropri√©s (üá∏üá≥, üèõÔ∏è, üìã, üíº)
- Invite l'utilisateur √† poser ses questions juridiques/administratives
- Maximum 3-4 lignes
- R√©ponse UNIQUEMENT en fran√ßais

R√©ponse:"""

            payload = {
                "model": self.config.OLLAMA_CHAT_MODEL,
                "prompt": greeting_prompt,
                "stream": False,
                "options": {
                    "num_ctx": 1024,     # Contexte r√©duit pour salutation rapide
                    "num_predict": 150,   # Limite tokens pour r√©ponse courte
                    "temperature": 0.7,  # Plus de cr√©ativit√© pour les salutations
                    "top_p": 0.9,
                    "top_k": 40
                }
            }
            
            response = requests.post(
                f"{self.config.OLLAMA_BASE_URL}/api/generate",
                json=payload,
                timeout=20  # Timeout r√©duit pour salutations rapides
            )
            
            if response.status_code == 200:
                natural_response = response.json()['response']
                logger.info(f"ü§ñ R√©ponse naturelle de salutation g√©n√©r√©e")
                return natural_response.strip()
            else:
                # Fallback vers r√©ponse pr√©d√©finie
                return self.generate_greeting_response(message)
                
        except Exception as e:
            logger.error(f"Erreur g√©n√©ration r√©ponse naturelle: {e}")
            # Fallback vers r√©ponse pr√©d√©finie
            return self.generate_greeting_response(message)

    
    def _format_direct_response(self, message: str, references: list) -> dict:
        """
        Formate une r√©ponse en affichant directement les extraits des documents
        (utilis√© en fallback si Ollama timeout)
        """
        response_parts = []
        
        response_parts.append(f"üìã R√âPONSES TROUV√âES DANS LES DOCUMENTS")
        response_parts.append(f"Question: {message}")
        response_parts.append("=" * 70)
        
        if not references:
            response_parts.append("\n‚ö†Ô∏è Aucune r√©f√©rence trouv√©e.")
            return {
                "response": "\n".join(response_parts),
                "references": []
            }
        
        # Afficher toutes les r√©f√©rences trouv√©es
        for idx, ref in enumerate(references, 1):
            article_ref = ref.get('article_ref', 'Section')
            file_name = ref.get('file_name', 'Document')
            content = ref.get('content', ref.get('snippet', ''))
            page = ref.get('page', 'N/A')
            start_line = ref.get('start_line', 'N/A')
            end_line = ref.get('end_line', 'N/A')
            
            response_parts.append(f"\nüìÑ R√âF√âRENCE {idx}")
            response_parts.append(f"Source: {file_name}")
            response_parts.append(f"Article: {article_ref}")
            response_parts.append(f"Localisation: Page {page}, lignes {start_line}-{end_line}")
            response_parts.append(f"\nüìñ TEXTE EXACT DU DOCUMENT:")
            response_parts.append(f'"{content}"')
            response_parts.append("\n" + "-" * 70)
        
        response_parts.append(f"\n‚ö†Ô∏è IMPORTANT: Les textes ci-dessus sont des extraits EXACTS des documents officiels.")
        response_parts.append(f"Aucune modification n'a √©t√© apport√©e au contenu.")
        response_parts.append(f"\nüìä Total: {len(references)} r√©f√©rence(s) trouv√©e(s) et tri√©e(s) par pertinence.")
        
        return {
            "response": "\n".join(response_parts),
            "references": references
        }
    
    def generate_contextual_reformulations(self, message: str, initial_context: str = "") -> list:
        """G√©n√®re des reformulations intelligentes bas√©es sur le vocabulaire des documents index√©s"""
        try:
            # Si on a un contexte initial des documents, l'utiliser pour guider les reformulations
            context_hint = ""
            if initial_context:
                # Extraire quelques termes cl√©s du contexte pour guider Mistral
                context_hint = f"\n\nVocabulaire trouv√© dans les documents fiscaux index√©s:\n{initial_context[:500]}..."
            
            prompt = f"""Tu es un expert en recherche documentaire fiscale s√©n√©galaise.

Question de l'utilisateur: "{message}"
{context_hint}

üá´üá∑ LANGUE OBLIGATOIRE: Tu DOIS r√©pondre UNIQUEMENT en fran√ßais. Aucun mot en anglais ou autre langue n'est autoris√©.

MISSION: G√©n√®re 5 reformulations de cette question pour am√©liorer la recherche dans les documents fiscaux.

R√àGLES:
1. Utilise le vocabulaire EXACT des documents fiscaux s√©n√©galais (articles, termes juridiques)
2. Inclus des num√©ros d'articles si tu les identifies dans le contexte
3. Varie entre termes techniques et formulations simples
4. Garde les mots-cl√©s importants de la question originale
5. Chaque reformulation sur une ligne, format: "- reformulation"

R√©ponds UNIQUEMENT avec les 5 reformulations (pas d'explication):"""

            payload = {
                "model": self.config.OLLAMA_CHAT_MODEL,
                "prompt": prompt,
                "stream": False,
                "options": {
                    "temperature": 0.3,  # Temp√©rature basse-moyenne pour coh√©rence
                    "top_p": 0.9,
                    "num_ctx": 2048,
                    "num_predict": 200  # Limite pour 5 reformulations courtes
                }
            }
            
            response = requests.post(
                f"{self.config.OLLAMA_BASE_URL}/api/generate",
                json=payload,
                timeout=15  # Timeout court pour ne pas ralentir
            )
            
            if response.status_code == 200:
                reformulations_text = response.json()['response'].strip()
                # Extraire les reformulations (lignes commen√ßant par - ou num√©rot√©es)
                reformulations = []
                for line in reformulations_text.split('\n'):
                    line = line.strip()
                    # Nettoyer les pr√©fixes (-, 1., etc.)
                    if line and (line.startswith('-') or (len(line) > 0 and line[0].isdigit())):
                        clean_line = line.lstrip('-0123456789.¬∞ ').strip()
                        if clean_line and len(clean_line) > 10:  # Ignorer les lignes trop courtes
                            reformulations.append(clean_line)
                
                logger.info(f"üîÑ {len(reformulations)} reformulations contextuelles g√©n√©r√©es par Mistral")
                return reformulations[:5]  # Max 5 reformulations
            else:
                logger.warning(f"‚ö†Ô∏è Erreur g√©n√©ration reformulations (code {response.status_code})")
                return []
                
        except requests.Timeout:
            logger.warning("‚è±Ô∏è Timeout reformulations - continuons sans reformulations contextuelles")
            return []
        except Exception as e:
            logger.error(f"‚ùå Erreur g√©n√©ration reformulations: {e}")
            return []
    
    def is_fiscal_related_question(self, message: str) -> bool:
        """D√©termine si la question est li√©e aux domaines index√©s - Approche permissive"""
        
        # üß† INTELLIGENCE NATURELLE: Laisser le mod√®le comprendre naturellement
        # Seuls les sujets clairement hors domaine sont rejet√©s
        message_lower = message.lower()
        
        # Mots-cl√©s explicitement NON fiscaux (tr√®s restrictif)
        non_fiscal_keywords = [
            'football', 'sport', 'cuisine', 'recette', 'musique', 'film', 'cin√©ma',
            'jeu vid√©o', 'programmation python', 'javascript', 'html', 'css',
            'facebook', 'instagram', 'twitter', 'r√©seau social',
            'm√©t√©o', 'sant√© personnelle', 'm√©decine', 'h√¥pital',
            'voiture', 'automobile', 'transport personnel',
            'mode', 'v√™tement', 'beaut√©', 'coiffure'
        ]
        
        # Rejeter seulement si c'est clairement hors domaine
        for keyword in non_fiscal_keywords:
            if keyword in message_lower:
                logger.info(f"üö´ Question NON FISCALE d√©tect√©e: '{keyword}' dans '{message[:50]}...'")
                return False
        
        # Par d√©faut, ACCEPTER et laisser l'IA juger
        logger.info(f"‚úÖ Question ACCEPT√âE pour analyse IA: '{message[:50]}...'")
        return True

    def chat(self, message: str, conversation_id: str = None) -> Dict:
        """G√©n√®re une r√©ponse bas√©e uniquement sur les documents index√©s (mode RAG strict) avec m√©moire conversationnelle"""
        try:
            # üó®Ô∏è GESTION DE LA CONVERSATION
            if conversation_id is None:
                # Cr√©er une nouvelle conversation si aucune n'est sp√©cifi√©e
                if self.current_conversation_id is None:
                    conversation_id = self.start_new_conversation()
                else:
                    conversation_id = self.current_conversation_id
            else:
                # Utiliser la conversation sp√©cifi√©e
                self.set_conversation(conversation_id)
                conversation_id = self.current_conversation_id or self.start_new_conversation()
            
            # Ajouter le message utilisateur √† l'historique
            self.conversation_manager.add_message(conversation_id, 'user', message)
            
            # Salutations: r√©pondre directement sans recherche documentaire
            if self.is_greeting_or_general(message):
                response_text = self.generate_natural_greeting_response(message)
                
                # Ajouter la r√©ponse √† l'historique
                self.conversation_manager.add_message(conversation_id, 'assistant', response_text)
                
                return {
                    "response": response_text, 
                    "references": [],
                    "conversation_id": conversation_id
                }
            
            # üîó ANALYSER SI C'EST UNE QUESTION DE SUIVI
            is_follow_up, context_hint = self.conversation_manager.analyze_follow_up_question(conversation_id, message)
            
            if is_follow_up:
                logger.info(f"üîó Question de suivi d√©tect√©e dans conversation {conversation_id}")
                
                # Enrichir le message avec le contexte de la conversation
                conversation_context = self.conversation_manager.get_conversation_context(conversation_id)
                enhanced_message = f"{message}\n\nCONTEXTE CONVERSATIONNEL:\n{context_hint}\n{conversation_context}"
                
                # Utiliser le message enrichi pour la recherche
                search_message = enhanced_message
            else:
                search_message = message
            
            # RECHERCHE D'ABORD - On cherche dans tous les documents index√©s
            if not self.is_fiscal_related_question(message):
                error_response = f"""‚ö†Ô∏è QUESTION NON FISCALE D√âTECT√âE

Je suis uniquement con√ßu pour r√©pondre √† des questions li√©es √† la fiscalit√© s√©n√©galaise.
Je ne peux pas r√©pondre √† votre question car elle n'est pas li√©e au domaine fiscal ou douanier.

ÔøΩ **Suggestions :**
- Posez une question sur le Code des Imp√¥ts/Douanes s√©n√©galais
- Utilisez des termes fiscaux pr√©cis (TVA, IS, d√©douanement)
- Mentionnez un article sp√©cifique si possible

‚ÑπÔ∏è En mode RAG strict, je ne r√©ponds qu'aux questions fiscales bas√©es sur les documents."""

                # Ajouter la r√©ponse √† l'historique
                self.conversation_manager.add_message(conversation_id, 'assistant', error_response)
                
                return {
                    "response": error_response,
                    "references": [],
                    "conversation_id": conversation_id
                }
                
# RECHERCHE EN MODE RAG STRICT AVEC REFORMULATIONS ET FILTRAGE TEXTUEL
            logger.info(f"üîç MODE RAG PUR - Recherche HYBRIDE pour: '{message[:50]}...'")
            
            # MODE RAG 100% PUR - Recherche hybride uniquement (vectoriel + BM25)
            # La recherche hybride doit trouver les documents pertinents sans boost manuel
            logger.info("‚ÑπÔ∏è MODE RAG 100% PUR - Recherche hybride (Vectoriel + BM25)")
            
            # Recherche hybride directe avec limite augment√©e pour meilleure couverture
            search_result = self.search_context_with_references(search_message, limit=20)
            
            if search_result.get("context"):
                context = search_result.get("context", "")
                references = search_result.get("references", [])
                content_type = search_result.get("content_type", "general")
                
                logger.info(f"üìä {len(references)} r√©f√©rences trouv√©es par recherche hybride")
                
                # Informer sur le type de contenu d√©tect√©
                if content_type == "economique":
                    logger.info(f"‚úÖ Question √âCONOMIQUE - Acceptation contenu mixte: budget/finances")
                elif content_type == "fiscal":
                    logger.info(f"‚úÖ Question FISCALE - Contenu fiscal d√©tect√©")
                elif content_type == "douanier":
                    logger.info(f"‚úÖ Question DOUANI√àRE - Contenu douanier d√©tect√©")
                else:
                    logger.info(f"‚úÖ Question MIXTE - Contenu vari√© d√©tect√©")
                
                # Trier par score (d√©j√† fait dans search_context_with_references)
                references.sort(key=lambda x: x.get('_score', 0), reverse=True)
                
                # Log des articles trouv√©s
                for ref in references[:10]:  # Top 10
                    article = ref.get('article_ref', 'N/A')
                    score = ref.get('_score', 0)
                    logger.info(f"üìÑ Article {article}, Page {ref.get('page', '?')}, Score {score:.3f}")
                
                logger.info(f"üìÑ {len(references)} extraits envoy√©s au mod√®le")
                logger.info(f"üîç Articles: {[ref.get('article_ref', 'N/A') for ref in references[:5]]}")
            else:
                context = ""
                references = []
            
            # NOUVEAU: Recherche d'expansion pour termes sp√©cifiques non trouv√©s
            if not context or 'senelec' in message.lower():
                logger.info("üîç Recherche d'expansion pour termes sp√©cifiques...")
                
                # Termes d'expansion pour SENELEC
                expansion_queries = [
                    "compensation tarifaire SENELEC milliards",
                    "trente-cinq milliards FCFA √©nergie", 
                    "35000000000 FCFA secteur √©lectricit√©",
                    "loi finances rectificative √©nergie montant",
                    "SENELEC subvention gouvernement",
                    "prix p√©trole compensation √©lectricit√©"
                ]
                
                best_result = None
                best_score = 0
                
                for exp_query in expansion_queries:
                    logger.info(f"  üîç Test expansion: '{exp_query}'")
                    exp_result = self.search_context_with_references(exp_query, limit=5)
                    
                    if exp_result.get("context") and exp_result.get("references"):
                        # Calculer score moyen des r√©f√©rences
                        avg_score = sum(ref.get('_score', 0) for ref in exp_result['references']) / len(exp_result['references'])
                        if avg_score > best_score:
                            best_result = exp_result
                            best_score = avg_score
                            logger.info(f"    ‚úÖ Meilleur r√©sultat trouv√© (score: {avg_score:.3f})")
                
                if best_result and best_score > 0.3:  # Seuil de qualit√©
                    context = best_result.get("context", "")
                    references = best_result.get("references", [])
                    logger.info(f"üéØ Recherche d'expansion r√©ussie avec score {best_score:.3f}")
            
            # Fallback: Si toujours aucun r√©sultat, essai avec mots-cl√©s extraits
            if not context:
                keywords = [word for word in message.split() if len(word) > 3]
                if keywords:
                    keyword_query = " ".join(keywords)
                    logger.info(f"üîÑ Recherche fallback avec mots-cl√©s: '{keyword_query}'")
                    search_result2 = self.search_context_with_references(keyword_query, limit=10)
                    context = search_result2.get("context", "")
                    references = search_result2.get("references", [])
            
            # FORCER l'utilisation du contexte des documents
            if context and context.strip():
                # D√©tecter le domaine de la question pour validation (maintenant informatif seulement)
                query_domain = self.detect_query_domain(message)
                # Note: Cette d√©tection est maintenant utilis√©e pour information uniquement
                # La vraie classification se fait par analyze_search_results()
                
                # Validation simplifi√©e : s'assurer que le contenu est pertinent
                question_keywords = message.lower().split()
                context_lower = context.lower()
                keyword_found = any(kw in context_lower for kw in question_keywords if len(kw) > 3)
                
                if keyword_found or any(keyword in context_lower for keyword in ["impot", "tva", "douane", "fiscal", "cgi", "dgi", "senegal", "s√©n√©gal", "article"]):
                    # Identifier le code source pr√©cis√©ment en analysant TOUS les documents
                    code_source = "Document juridique s√©n√©galais"
                    sources_trouvees = []
                    
                    if references:
                        for ref in references:
                            file_name = ref.get('file_name', '').lower()
                            if 'impot' in file_name and 'Code des Imp√¥ts du S√©n√©gal' not in sources_trouvees:
                                sources_trouvees.append('Code des Imp√¥ts du S√©n√©gal')
                            elif 'douane' in file_name and 'Code des Douanes du S√©n√©gal' not in sources_trouvees:
                                sources_trouvees.append('Code des Douanes du S√©n√©gal')
                    
                    if len(sources_trouvees) == 1:
                        code_source = sources_trouvees[0]
                    elif len(sources_trouvees) > 1:
                        code_source = " ET ".join(sources_trouvees)
                    else:
                        code_source = "Documents juridiques s√©n√©galais"
                    
                    # üó®Ô∏è INT√âGRER LE CONTEXTE CONVERSATIONNEL
                    conversation_context = ""
                    if is_follow_up:
                        conversation_context = f"\n\nüí¨ CONTEXTE DE LA CONVERSATION:\n{self.conversation_manager.get_conversation_context(conversation_id, max_messages=4)}\n"
                    
                    prompt = f"""TEXTE OFFICIEL: {context}

QUESTION ACTUELLE: {message}
{conversation_context}
üá´üá∑ LANGUE OBLIGATOIRE: Tu DOIS r√©pondre UNIQUEMENT en fran√ßais. Aucun mot dans une autre langue n'est autoris√©.

üß† EXPERTISE √âLARGIE: Tu es un expert en droit s√©n√©galais qui ma√Ætrise :
- Code des Imp√¥ts et fiscalit√© (CGI, DGI, TVA, IS, IR)
- Code des Douanes et proc√©dures douani√®res  
- Lois de Finances et budget de l'√âtat
- Documents √©conomiques et financiers publics
- R√©glementations et arr√™t√©s administratifs
- Codes d'investissement et sectoriels

üó®Ô∏è INTELLIGENCE CONVERSATIONNELLE :
- Si la QUESTION ACTUELLE fait r√©f√©rence √† la conversation pr√©c√©dente (ex: "ce taux", "cette taxe", "il", "elle", etc.), utilise le CONTEXTE DE LA CONVERSATION pour comprendre √† quoi l'utilisateur fait r√©f√©rence
- Si l'utilisateur dit "ce taux", identifie de quel taux il parlait dans les messages pr√©c√©dents
- Si l'utilisateur dit "cette marchandise" ou "ces produits", r√©f√®re-toi aux √©l√©ments mentionn√©s pr√©c√©demment
- Assure-toi de faire le lien logique entre la question actuelle et les √©changes pr√©c√©dents

üö® R√àGLES ABSOLUES - AUCUNE EXCEPTION AUTORIS√âE :

üìä VALEURS NUM√âRIQUES - INTERDICTION TOTALE DE MODIFICATION :
‚ùå INTERDIT : Arrondir, estimer, approximer, convertir, reformuler
‚ùå INTERDIT : Dire "environ", "pr√®s de", "approximativement", "autour de"
‚ùå INTERDIT : Changer "2 875 millions" en "2,9 milliards" ou "pr√®s de 3 milliards"
‚ùå INTERDIT : Changer "141 millions et demi" en "141,5 millions" ou "environ 142 millions"
‚ùå INTERDIT : Changer "3,8 milliards et demi" en "3 800 millions" ou "environ 4 milliards"
‚úÖ OBLIGATOIRE : Recopier TRAIT POUR TRAIT chaque chiffre, virgule, espace, unit√©

üí∞ CITATIONS EXACTES OBLIGATOIRES :
- Si le document dit "2 875 millions FCFA" ‚Üí Tu √©cris "2 875 millions FCFA"
- Si le document dit "141 millions et demi d'euros" ‚Üí Tu √©cris "141 millions et demi d'euros"
- Si le document dit "470 millions FCFA" ‚Üí Tu √©cris "470 millions FCFA" 
- Si le document dit "3,8 milliards et demi d'euros" ‚Üí Tu √©cris "3,8 milliards et demi d'euros"
- GARDE le format exact : espaces, virgules, "et demi", devises, unit√©s

ÔøΩ R√àGLES STRICTES POUR TOUS LES NOMBRES :
1. Copie EXACTEMENT chaque chiffre sans modification
2. Conserve les espaces dans les nombres (ex: "2 875" reste "2 875")
3. Conserve les virgules et points (ex: "3,8" reste "3,8")
4. Conserve "et demi" au lieu de ",5" si c'est √©crit ainsi
5. Conserve "millions/milliards" exactement comme √©crit
6. Conserve "FCFA/euros" exactement comme √©crit
7. Ne convertis JAMAIS une devise vers une autre
8. Ne changes JAMAIS l'unit√© (millions vers milliards ou vice-versa)

üö® CONSIGNES G√âN√âRALES ANTI-HALLUCINATION :
1. Tu DOIS utiliser EXCLUSIVEMENT le contenu du TEXTE OFFICIEL ci-dessus
2. Si l'information existe dans le texte, cite-la EXACTEMENT
3. Ne dis JAMAIS "n'est pas mentionn√©" si l'information est dans le texte
4. INTERDIT ABSOLU d'inventer, supposer, extrapoler ou modifier quelque valeur que ce soit
5. INTERDIT de dire "selon mes connaissances" ou "g√©n√©ralement"
6. INTERDIT d'ajouter des informations qui ne sont PAS dans le TEXTE OFFICIEL
7. INTERDIT de parler de "taux r√©duit" ou "0%" s'ils ne sont PAS mentionn√©s dans le texte
8. INTERDIT de mentionner des "exceptions" ou "cas particuliers" non explicites dans le texte
9. INTERDIT de dire "il existe" ou "il y a aussi" sans citation exacte du document
10. Si tu ne trouves PAS l'information exacte dans le texte, dis clairement "cette information n'est pas pr√©cis√©e dans les extraits fournis"

üîç M√âTHODE DE V√âRIFICATION OBLIGATOIRE AVANT R√âPONSE :
- Relis le TEXTE OFFICIEL mot par mot
- V√©rifies que CHAQUE affirmation de ta r√©ponse est DIRECTEMENT trouvable dans le texte
- Supprimes toute phrase qui n'a pas de source directe dans le TEXTE OFFICIEL
- Cites UNIQUEMENT ce qui est √©crit noir sur blanc dans les documents

üö´ EXEMPLES D'INVENTIONS INTERDITES :
‚ùå "Il existe un taux r√©duit de 0%" (si non mentionn√© dans le texte)
‚ùå "Certains √©tablissements b√©n√©ficient d'exon√©rations" (si non explicite)
‚ùå "La loi pr√©voit des exceptions" (si non cit√©es pr√©cis√©ment)
‚ùå "Le taux peut √™tre diff√©rent selon les cas" (si non document√©)

M√âTHODE OBLIGATOIRE:
- Lis attentivement le TEXTE OFFICIEL ligne par ligne
- Trouve l'information demand√©e UNIQUEMENT dans ce texte
- Cite UNIQUEMENT ce qui est √©crit mot pour mot dans le document
- N'AJOUTES AUCUNE information ext√©rieure au texte
- Si l'information DIRECTE n'est pas dans le texte, dis clairement "cette information sp√©cifique n'est pas d√©taill√©e dans les extraits fournis"
- Puis R√âSUME UNIQUEMENT ce que contiennent r√©ellement les articles/sections trouv√©s en citant leurs dispositions EXACTES

üîç AVANT DE R√âPONDRE - V√âRIFICATION OBLIGATOIRE :
1. Chaque phrase de ma r√©ponse a-t-elle une source DIRECTE dans le TEXTE OFFICIEL ?
2. Ai-je invent√© ou ajout√© des informations non pr√©sentes dans le texte ?
3. Ai-je cit√© des taux, pourcentages ou exceptions qui ne sont PAS dans le document ?
4. Ma r√©ponse est-elle une copie fid√®le du contenu du TEXTE OFFICIEL ?

STRUCTURE DE R√âPONSE SI INFORMATION DIRECTE ABSENTE:
"Bien que la proc√©dure sp√©cifique de [sujet] ne soit pas d√©taill√©e dans ces extraits, les documents trouv√©s traitent de :
- [Document/Article X] : [r√©sum√© du contenu avec valeurs EXACTES copi√©es du document]
- [Document/Article Y] : [r√©sum√© du contenu avec montants EXACTS copi√©s du document]
Ces dispositions encadrent les aspects connexes de [domaine g√©n√©ral]."

‚ö†Ô∏è RAPPEL CRITIQUE : CHAQUE VALEUR NUM√âRIQUE DOIT √äTRE UNE COPIE PARFAITE DU DOCUMENT ORIGINAL

R√©ponds maintenant en fran√ßais uniquement et en appliquant CES R√àGLES STRICTEMENT, en particulier la pr√©servation EXACTE ET INT√âGRALE de toutes les valeurs num√©riques:"""
                else:
                    return {
                        "response": f"""‚ö†Ô∏è INFORMATION NON TROUV√âE

Je ne trouve pas d'information sur ce sujet dans les documents juridiques index√©s.

üìå **Suggestions :**
- Utilisez des termes pr√©cis (codes, lois, arr√™t√©s, budget)
- R√©f√©rencez un article sp√©cifique (ex: "Article 19 du CGI", "Loi de Finances 2025")
- Reformulez avec des termes juridiques s√©n√©galais
- Pr√©cisez le domaine : fiscal, douanier, budg√©taire, √©conomique

‚ÑπÔ∏è En mode RAG strict, je r√©ponds uniquement sur la base des documents.""",
                        "references": references
                    }
            else:
                return {
                    "response": f"""‚ö†Ô∏è AUCUN DOCUMENT CORRESPONDANT

Je suis con√ßu pour r√©pondre aux questions li√©es au droit et √† l'administration s√©n√©galaise.

üìä **Domaines couverts :**
- Code des Imp√¥ts et fiscalit√© s√©n√©galaise
- Code des Douanes et proc√©dures commerciales  
- Lois de Finances et budget de l'√âtat
- Documents √©conomiques et financiers publics
- R√©glementations et arr√™t√©s administratifs

üí° **Exemples de questions :**
- "Que dit la l√©gislation douani√®re sur l'importation des marchandises ?"
- "Quels sont les taux de TVA selon le Code des Imp√¥ts ?"
- "Compensation SENELEC dans les lois de finances ?"

‚ÑπÔ∏è En mode RAG strict, je ne r√©ponds qu'aux questions bas√©es sur les documents juridiques.""",
                    "references": []
                }
            
            # G√©n√©rer la r√©ponse avec Ollama - MODE RAG STRICT AVEC CITATIONS
            payload = {
                "model": self.config.OLLAMA_CHAT_MODEL,
                "prompt": prompt,
                "stream": False,
                "options": {
                    "temperature": 0.0,      # Temp√©rature √† 0 pour r√©ponses EXACTES - aucune cr√©ativit√©
                    "top_p": 0.1,           # Top-p tr√®s bas pour forcer la s√©lection des mots les plus probables
                    "top_k": 1,             # Ne garde que le mot le plus probable √† chaque √©tape
                    "repeat_penalty": 1.5,   # P√©nalit√© augment√©e pour √©viter les r√©p√©titions invent√©es
                    "presence_penalty": 0.5, # Encourage la diversit√© bas√©e sur le contexte fourni uniquement
                    "frequency_penalty": 0.3, # √âvite les r√©p√©titions non fond√©es
                    "num_ctx": 4096,        # Contexte limit√© pour se concentrer sur les documents fournis
                    "num_predict": 800,     # Limite la longueur pour √©viter les divagations
                    "stop": ["Article 999", "Code fictif", "n'existe pas", "inexistant", "environ", "pr√®s de", "approximativement", "autour de", "√† peu pr√®s"]  # Mots-cl√©s d'arr√™t d'urgence + mots d'estimation
                }
            }
            
            try:
                # üîÑ M√âCANISME DE RETRY PROGRESSIF avec r√©duction du contexte
                max_retries = 2
                for attempt in range(max_retries + 1):
                    # R√©duire progressivement le contexte si timeout
                    if attempt > 0:
                        logger.info(f"üîÑ Tentative {attempt + 1}: r√©duction du contexte ({len(context)} chars)")
                        # R√©duire le contexte de 50% √† chaque retry
                        context_lines = context.split('\n')
                        max_lines = max(5, len(context_lines) // (2 ** attempt))  # Minimum 5 lignes
                        context = '\n'.join(context_lines[:max_lines])
                        logger.info(f"üîÑ Contexte r√©duit √† {len(context)} caract√®res")
                        
                        # Mettre √† jour le payload avec le contexte r√©duit
                        payload["prompt"] = prompt.replace(prompt.split("QUESTION:")[0], f"""TEXTE OFFICIEL: {context}

""")
                    
                    try:
                        response = requests.post(
                            f"{self.config.OLLAMA_BASE_URL}/api/generate",
                            json=payload,
                            timeout=60  # Timeout r√©duit √† 1 minute pour d√©tecter rapidement les probl√®mes
                        )
                        
                        if response.status_code == 200:
                            ollama_response = response.json()['response']
                            
                            # üõ°Ô∏è V√âRIFICATION ANTI-HALLUCINATION
                            validated_response = self._validate_response_against_context(ollama_response, context, message)
                            
                            # üí¨ Enregistrer la r√©ponse dans l'historique de conversation
                            if conversation_id and self.conversation_manager:
                                self.conversation_manager.add_message(conversation_id, "assistant", validated_response)
                            
                            logger.info(f"‚úÖ Mistral r√©ponse obtenue (tentative {attempt + 1})")
                            return {
                                "response": validated_response,
                                "references": references
                            }
                        elif response.status_code == 504:
                            if attempt < max_retries:
                                logger.warning(f"‚è±Ô∏è Timeout Mistral (504) - Tentative {attempt + 1}/{max_retries + 1}")
                                continue
                            else:
                                # Timeout final - Afficher directement les articles trouv√©s
                                logger.warning("‚è±Ô∏è Timeout Mistral final (504) - Affichage direct des articles trouv√©s")
                                return self._format_direct_response(message, references)
                        else:
                            return {
                                "response": f"‚ùå Erreur technique (code {response.status_code}). Veuillez r√©essayer.",
                                "references": []
                            }
                    except requests.Timeout:
                        if attempt < max_retries:
                            logger.warning(f"‚è±Ô∏è Timeout requ√™te Mistral - Tentative {attempt + 1}/{max_retries + 1}")
                            continue
                        else:
                            # Timeout final de la requ√™te Python - Afficher directement les articles
                            logger.warning("‚è±Ô∏è Timeout requ√™te Mistral final - Affichage direct des articles trouv√©s")
                            return self._format_direct_response(message, references)
            except requests.exceptions.RequestException as e:
                # Autres erreurs r√©seau - Afficher directement les articles
                logger.error(f"‚ùå Erreur r√©seau Mistral: {e}")
                return self._format_direct_response(message, references)
            
            else:
                # Aucun contexte trouv√© dans les documents - V√©rifier si c'est hors domaine
                logger.warning("‚ö†Ô∏è Aucun contexte trouv√© dans les documents index√©s")
                
                # Maintenant on fait la v√©rification du domaine seulement si rien n'est trouv√©
                if not self.is_fiscal_related_question(message):
                    response_text = f"""‚ö†Ô∏è QUESTION HORS DOMAINE

Aucune information trouv√©e dans les documents index√©s pour votre question.

Je suis con√ßu pour r√©pondre aux questions sur :
- üèõÔ∏è Fiscalit√© et douanes s√©n√©galaises (Code des Imp√¥ts, Code des Douanes)
- üí∞ √âconomie et finances publiques (Budget, Loi de Finances)  
- üìä Secteurs √©conomiques (pr√©visions, croissance sectorielle)
- üè≠ Investissements et politique √©conomique
- üìà Dette publique et gestion financi√®re

üí° **Suggestions :**
- Reformulez votre question avec des termes plus sp√©cifiques
- Mentionnez un secteur √©conomique particulier
- Posez une question sur les pr√©visions budg√©taires ou √©conomiques du S√©n√©gal
- Utilisez des mots-cl√©s li√©s aux documents index√©s

‚ÑπÔ∏è Seules les questions ayant des r√©ponses dans les documents index√©s sont trait√©es."""
                    
                    # üí¨ Enregistrer la r√©ponse dans l'historique de conversation
                    if conversation_id and self.conversation_manager:
                        self.conversation_manager.add_message(conversation_id, "assistant", response_text)
                    
                    return {
                        "response": response_text,
                        "references": []
                    }
                else:
                    # Question dans le domaine mais pas de r√©sultats - Sugg√©rer reformulation
                    response_text = f"""üîç AUCUNE INFORMATION TROUV√âE

Votre question semble pertinente mais aucune information correspondante n'a √©t√© trouv√©e dans les documents index√©s.

**Votre question:** {message}

üí° **Suggestions pour am√©liorer votre recherche :**
- Reformulez avec des termes plus g√©n√©raux ou plus sp√©cifiques
- Utilisez des synonymes (ex: "imp√¥t" ‚Üí "fiscalit√©", "croissance" ‚Üí "d√©veloppement")
- Mentionnez un secteur sp√©cifique (chimique, agroalimentaire, etc.)
- Pr√©cisez la p√©riode si pertinente (2025, 2026)

üìö **Exemples de questions qui fonctionnent :**
- "Quelles sont les pr√©visions de croissance pour 2026 ?"
- "Comment √©voluent les investissements dans le secteur industriel ?"
- "Quel est le taux de TVA au S√©n√©gal ?"

üîÑ Essayez de reformuler votre question."""

                    # üí¨ Enregistrer la r√©ponse dans l'historique de conversation
                    if conversation_id and self.conversation_manager:
                        self.conversation_manager.add_message(conversation_id, "assistant", response_text)
                    
                    return {
                        "response": response_text,
                        "references": []
                    }
                
        except Exception as e:
            logger.error(f"Erreur chat: {e}")
            error_response = "Une erreur s'est produite. Veuillez r√©essayer dans un moment."
            
            # üí¨ Enregistrer la r√©ponse d'erreur dans l'historique de conversation
            if conversation_id and self.conversation_manager:
                self.conversation_manager.add_message(conversation_id, "assistant", error_response)
            
            return {
                "response": error_response,
                "references": []
            }
    
    def _validate_response_against_context(self, response: str, context: str, original_question: str) -> str:
        """üõ°Ô∏è Valide la r√©ponse de Ollama contre le contexte fourni pour d√©tecter les hallucinations"""
        
        try:
            # Extraire les articles mentionn√©s dans la r√©ponse
            import re
            article_pattern = r'Article\s+(\d+)'
            response_articles = set(re.findall(article_pattern, response, re.IGNORECASE))
            context_articles = set(re.findall(article_pattern, context, re.IGNORECASE))
            
            # V√©rifier les chiffres/pourcentages
            number_pattern = r'(\d+(?:\.\d+)?%|\d+(?:\.\d+)?\s*(?:FCFA|francs))'
            response_numbers = set(re.findall(number_pattern, response, re.IGNORECASE))
            context_numbers = set(re.findall(number_pattern, context, re.IGNORECASE))
            
            # D√©tecter les hallucinations potentielles
            hallucination_detected = False
            warning_messages = []
            
            # 1. Articles invent√©s - Ajuster la d√©tection pour √©viter les faux positifs
            invented_articles = response_articles - context_articles
            if invented_articles:
                # V√©rifier si ce sont vraiment des inventions ou des extractions l√©gitimes
                critical_inventions = []
                for article in invented_articles:
                    # Ne consid√©rer comme hallucination que si l'article n'est pas dans le contexte du tout
                    if not any(article in line for line in context.split('\n')):
                        critical_inventions.append(article)
                
                if critical_inventions:
                    hallucination_detected = True
                    warning_messages.append(f"‚ö†Ô∏è Articles non trouv√©s dans les documents: {', '.join(critical_inventions)}")
                else:
                    logger.info(f"‚ÑπÔ∏è Articles mentionn√©s mais consid√©r√©s comme l√©gitimes: {', '.join(invented_articles)}")
            
            # 2. Chiffres invent√©s (tol√©rance de 5% pour erreurs de transcription)
            for resp_num in response_numbers:
                found_similar = False
                for ctx_num in context_numbers:
                    # Comparaison exacte d'abord
                    if resp_num == ctx_num:
                        found_similar = True
                        break
                
                if not found_similar:
                    warning_messages.append(f"‚ö†Ô∏è Chiffre suspect non v√©rifi√©: {resp_num}")
            
            # 3. üö® V√âRIFICATION CRITIQUE - Mais plus tol√©rante pour les questions g√©n√©rales
            false_negative_patterns = [
                "n'est pas explicitement mentionn√©", "n'est pas mentionn√©", "ne pr√©cise pas",
                "n'est pas sp√©cifi√©", "pas d'information", "aucune mention"
            ]
            
            for pattern in false_negative_patterns:
                if pattern.lower() in response.lower():
                    # V√©rifier si l'information est VRAIMENT dans le contexte
                    question_lower = original_question.lower()
                    context_lower = context.lower()
                    
                    # Recherche sp√©cifique pour TVA/taux (cas critique)
                    if any(word in question_lower for word in ["tva", "taxe", "taux"]):
                        if any(phrase in context_lower for phrase in ["taux", "18%", "dix-huit pour cent", "fix√© √†"]):
                            hallucination_detected = True
                            warning_messages.append(f"üö® ERREUR CRITIQUE: Le mod√®le dit '{pattern}' mais l'information est PR√âSENTE dans le contexte")
                    
                    # Pour les questions g√©n√©rales, √™tre plus tol√©rant
                    elif "exoneration" in question_lower or "g√©n√©ral" in question_lower or "conditionnelle" in question_lower:
                        # Ne pas d√©clencher d'hallucination pour les questions g√©n√©rales complexes
                        logger.info(f"‚ÑπÔ∏è Question g√©n√©rale d√©tect√©e, tol√©rance accrue pour: {pattern}")
                    else:
                        # Recherche g√©n√©rale pour d'autres sujets (seuil plus √©lev√©)
                        key_words = [word for word in question_lower.split() if len(word) > 3]
                        if key_words:
                            found_matches = sum(1 for word in key_words if word in context_lower)
                            if found_matches >= len(key_words) * 0.8:  # 80% des mots-cl√©s trouv√©s (plus strict)
                                warning_messages.append(f"‚ö†Ô∏è Le mod√®le dit '{pattern}' mais des √©l√©ments pertinents sont dans le contexte")
            
            # 4. Mots-cl√©s suspects d'hallucination - Version plus intelligente
            # Phrases vraiment probl√©matiques (hallucinations claires)
            critical_suspicious_phrases = [
                "selon mes connaissances", "d'apr√®s ce que je sais", 
                "je pense que", "il me semble"
            ]
            
            # Phrases mod√©r√©ment suspectes (contextuel)
            moderate_suspicious_phrases = [
                "g√©n√©ralement", "habituellement", "en r√®gle g√©n√©rale", 
                "il est probable que", "vraisemblablement"
            ]
            
            # Phrases acceptables dans contexte juridique
            acceptable_phrases = [
                "il est possible", "il convient de", "peuvent √™tre", 
                "est susceptible de", "peut √™tre"
            ]
            
            # V√©rifier les phrases critiques
            for phrase in critical_suspicious_phrases:
                if phrase.lower() in response.lower():
                    hallucination_detected = True
                    warning_messages.append(f"‚ö†Ô∏è Formulation probl√©matique d√©tect√©e: '{phrase}'")
            
            # V√©rifier les phrases mod√©r√©es seulement si pas de contexte juridique solide
            response_words = set(response.lower().split())
            context_words = set(context.lower().split())
            common_words = response_words.intersection(context_words)
            
            # Si peu de correspondance avec le contexte, √™tre plus strict
            if len(common_words) < min(5, len(response_words) * 0.2):
                for phrase in moderate_suspicious_phrases:
                    if phrase.lower() in response.lower():
                        warning_messages.append(f"‚ö†Ô∏è Formulation suspecte avec faible correspondance: '{phrase}'")
            
            # 5. V√©rification de la coh√©rence avec le contexte - Seuils assouplis
            response_lower = response.lower()
            context_lower = context.lower()
            
            # V√©rifier que les citations sont pr√©sentes dans le contexte
            if "article" in response_lower and "article" in context_lower:
                # Si la r√©ponse mentionne du contenu d'article, v√©rifier qu'il existe dans le contexte
                response_words = set(response_lower.split())
                context_words = set(context_lower.split())
                
                # V√©rifier un minimum de correspondance lexicale - Seuil abaiss√©
                common_words = response_words.intersection(context_words)
                min_threshold = min(5, len(response_words) * 0.2)  # Au moins 20% de mots en commun ou 5 mots minimum
                if len(common_words) < min_threshold:
                    warning_messages.append("‚ö†Ô∏è Faible correspondance lexicale avec les documents fournis")
                else:
                    logger.info(f"‚úÖ Correspondance lexicale acceptable: {len(common_words)} mots communs")
            
            # Si hallucination d√©tect√©e, mais √™tre plus tol√©rant pour les questions g√©n√©rales
            if hallucination_detected:
                # Mode tol√©rant pour certains types de questions
                question_lower = original_question.lower()
                is_general_question = any(word in question_lower for word in [
                    "parle", "expliquer", "qu'est-ce", "g√©n√©ral", "principe", "r√©sumer", "pr√©senter"
                ])
                
                # Compter les vraies erreurs critiques
                critical_errors = [msg for msg in warning_messages if "ERREUR CRITIQUE" in msg or "Articles non trouv√©s" in msg]
                
                if is_general_question and len(critical_errors) == 0:
                    # Pour les questions g√©n√©rales sans erreurs critiques, laisser passer
                    logger.info(f"‚ÑπÔ∏è Question g√©n√©rale d√©tect√©e, validation assouplie malgr√© {len(warning_messages)} avertissements mineurs")
                    return response
                
                logger.warning(f"üö® HALLUCINATION D√âTECT√âE: {'; '.join(warning_messages)}")
                
                # üö® CAS SP√âCIAL: Correction automatique pour TVA si d√©tect√©e
                if "tva" in original_question.lower() and "18%" in context:
                    return """üìã **TVA AU S√âN√âGAL - INFORMATION OFFICIELLE**

Selon l'Article 369 du Code des Imp√¥ts du S√©n√©gal :
**Le taux de la TVA est fix√© √† 18%.**

Cette information est explicitement mentionn√©e dans le texte officiel.

üö® *Note: R√©ponse corrig√©e automatiquement suite √† d√©tection d'erreur d'interpr√©tation*"""
                
                # üîÑ NOUVELLE APPROCHE: G√©n√©rer une analyse alternative des documents trouv√©s
                logger.info("üîÑ G√©n√©ration d'une analyse alternative des documents trouv√©s...")
                
                alternative_prompt = f"""DOCUMENTS OFFICIELS TROUV√âS: {context}

QUESTION POS√âE: {original_question}

üá´üá∑ LANGUE OBLIGATOIRE: Tu DOIS r√©pondre UNIQUEMENT en fran√ßais. Aucun mot en anglais ou autre langue n'est autoris√©.

üö® MISSION SP√âCIALE: Le syst√®me a d√©tect√© une possible erreur d'interpr√©tation dans une premi√®re r√©ponse.
Tu dois maintenant faire une ANALYSE PRUDENTE ET FACTUELLE des documents fournis.

üî¢ R√àGLE ABSOLUE - AUCUNE EXCEPTION - VALEURS NUM√âRIQUES EXACTES :
‚ùå TOTALEMENT INTERDIT : Modifier, arrondir, estimer, approximer toute valeur
‚ùå INTERDIT : "environ", "pr√®s de", "approximativement", "autour de"
‚úÖ OBLIGATOIRE : Copier EXACTEMENT comme √©crit dans le document source

üí∞ EXEMPLES DE CITATION CORRECTE :
- Document dit "2 875 millions FCFA" ‚Üí Tu √©cris "2 875 millions FCFA"
- Document dit "141 millions et demi d'euros" ‚Üí Tu √©cris "141 millions et demi d'euros"
- Document dit "470 millions FCFA" ‚Üí Tu √©cris "470 millions FCFA"
- JAMAIS de conversion, JAMAIS d'arrondi, JAMAIS d'estimation

CONSIGNES STRICTES:
1. NE PAS inventer d'informations
2. ANALYSER uniquement ce qui est pr√©sent dans les documents
3. üí∞ RECOPIER EXACTEMENT tous les montants, devises, formats num√©riques
4. Si pas d'information directe sur le sujet, chercher des √âL√âMENTS CONNEXES
5. Utiliser des formulations prudentes comme "selon l'article X", "d'apr√®s les documents"
6. JAMAIS d'arrondi ou d'approximation des valeurs (garde "141 millions et demi" EXACTEMENT tel quel)
7. JAMAIS de conversion d'unit√©s (millions vers milliards ou FCFA vers euros)

STRUCTURE DE R√âPONSE OBLIGATOIRE:
‚Ä¢ "Il n'existe pas de disposition sp√©cifique sur [sujet exact] dans ces documents"
‚Ä¢ "Cependant, les articles suivants traitent d'aspects connexes:"
‚Ä¢ [Analyse factuelle des articles pertinents trouv√©s avec valeurs EXACTES copi√©es]
‚Ä¢ "Pour une information compl√®te, consulter directement les textes officiels"

‚ö†Ô∏è V√âRIFICATION FINALE : Chaque valeur num√©rique dans ta r√©ponse doit √™tre une COPIE PARFAITE du document

G√©n√®re maintenant cette analyse factuelle en pr√©servant EXACTEMENT et INT√âGRALEMENT toutes les valeurs num√©riques:"""

                # G√©n√©rer une r√©ponse alternative avec Ollama
                alternative_payload = {
                    "model": self.config.OLLAMA_CHAT_MODEL,
                    "prompt": alternative_prompt,
                    "stream": False,
                    "options": {
                        "temperature": 0.0,      # Temp√©rature √† 0 pour exactitude maximale
                        "top_p": 0.1,           # Tr√®s conservateur
                        "top_k": 1,             # Une seule option la plus probable
                        "repeat_penalty": 1.3,  
                        "num_ctx": 4096,        
                        "num_predict": 600,     # Plus court pour √©viter les d√©rives
                        "stop": ["Code fictif", "n'existe pas vraiment", "invention", "environ", "pr√®s de", "approximativement", "autour de", "√† peu pr√®s"]  # Arr√™t sur mots d'estimation
                    }
                }
                
                try:
                    alternative_response = requests.post(
                        f"{self.config.OLLAMA_BASE_URL}/api/generate",
                        json=alternative_payload,
                        timeout=180  # 3 minutes
                    )
                    
                    if alternative_response.status_code == 200:
                        alternative_text = alternative_response.json()['response']
                        
                        # Ajouter une note explicative
                        final_response = f"""‚ö†Ô∏è **ANALYSE PRUDENTE - MODE S√âCURIS√â ACTIV√â**

{alternative_text}

---
*üõ°Ô∏è Note: Cette r√©ponse a √©t√© g√©n√©r√©e en mode s√©curis√© suite √† la d√©tection de potentielles impr√©cisions dans l'analyse initiale. Seuls les √©l√©ments explicitement pr√©sents dans les documents ont √©t√© analys√©s.*"""
                        
                        return final_response
                    else:
                        logger.error(f"Erreur g√©n√©ration alternative: {alternative_response.status_code}")
                        # Fallback vers l'ancienne m√©thode
                        pass
                        
                except Exception as e:
                    logger.error(f"Erreur appel Ollama alternatif: {e}")
                    # Fallback vers l'ancienne m√©thode
                    pass
                
                # R√©ponse de s√©curit√© avec les documents bruts
                safe_response = f"""üö® **R√âPONSE S√âCURIS√âE - ERREUR D'INTERPR√âTATION D√âTECT√âE**

Le syst√®me a d√©tect√© une possible erreur dans l'interpr√©tation des documents.
Voici le contenu EXACT des documents trouv√©s pour: "{original_question}"

**üìÑ CONTENU BRUT DES DOCUMENTS:**
{context[:1500]}...

**‚ö†Ô∏è PROBL√àMES D√âTECT√âS:**
{chr(10).join(warning_messages)}

**üîç RECOMMANDATION:**
Consultez directement les documents officiels ci-dessus pour obtenir l'information pr√©cise."""
                
                return safe_response
            
            # Si pas d'hallucination d√©tect√©e, retourner la r√©ponse originale
            return response
            
        except Exception as e:
            logger.error(f"Erreur validation anti-hallucination: {e}")
            # En cas d'erreur de validation, retourner la r√©ponse avec avertissement
            return f"""‚ö†Ô∏è **AVERTISSEMENT - VALIDATION IMPOSSIBLE**

{response}

**Note:** La validation automatique anti-hallucination a √©chou√©. Veuillez v√©rifier la r√©ponse avec les documents officiels."""

# Template HTML ultra moderne et responsif avec effets
HTML_TEMPLATE = """
<!DOCTYPE html>
<html lang="fr">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>LexFin - Assistant Fiscal et Douanier S√©n√©gal</title>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">
    <style>
        :root {
            --senegal-green: #00853F;
            --senegal-yellow: #FDEF42;
            --senegal-red: #E31B23;
            --primary-gradient: linear-gradient(135deg, var(--senegal-green) 0%, #006838 100%);
            --secondary-gradient: linear-gradient(135deg, #1a472a 0%, #0d2818 100%);
            --accent-color: var(--senegal-yellow);
            --shadow-soft: 0 8px 32px rgba(0, 0, 0, 0.1);
            --shadow-medium: 0 12px 48px rgba(0, 0, 0, 0.15);
            --shadow-hard: 0 20px 60px rgba(0, 0, 0, 0.25);
            --transition-smooth: all 0.4s cubic-bezier(0.4, 0, 0.2, 1);
            --transition-bounce: all 0.6s cubic-bezier(0.68, -0.55, 0.265, 1.55);
        }

        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Inter', -apple-system, BlinkMacSystemFont, 'Segoe UI', sans-serif;
            background: linear-gradient(135deg, var(--senegal-green) 0%, #006838 30%, #004d2a 100%);
            background-attachment: fixed;
            margin: 0;
            padding: 0;
            height: 100vh;
            overflow: hidden;
            position: relative;
        }

        /* Effet de particules anim√©es en arri√®re-plan */
        body::before {
            content: '';
            position: fixed;
            width: 100%;
            height: 100%;
            background: 
                radial-gradient(circle at 20% 50%, rgba(254, 239, 66, 0.05) 0%, transparent 50%),
                radial-gradient(circle at 80% 80%, rgba(0, 133, 63, 0.08) 0%, transparent 50%);
            animation: backgroundPulse 15s ease-in-out infinite;
            pointer-events: none;
            z-index: 0;
        }

        @keyframes backgroundPulse {
            0%, 100% { opacity: 1; transform: scale(1); }
            50% { opacity: 0.8; transform: scale(1.05); }
        }



        /* Application plein √©cran */
        .chat-app {
            width: 100vw;
            height: 100vh;
            display: flex;
            flex-direction: column;
            background: rgba(255, 255, 255, 0.98);
            backdrop-filter: blur(20px);
            position: relative;
            z-index: 1;
            box-shadow: 0 0 80px rgba(0, 0, 0, 0.15);
        }

        .container {
            display: flex;
            flex-direction: column;
            height: 100vh;
            padding: 0;
            margin: 0;
            width: 100vw;
            max-width: none;
            background: transparent;
        }

        .chat-header {
            background: var(--primary-gradient);
            color: white;
            padding: 40px 50px;
            text-align: center;
            position: relative;
            box-shadow: var(--shadow-hard);
            overflow: hidden;
            z-index: 10;
        }

        /* Drapeau s√©n√©galais anim√© avec effet de vague */
        .chat-header::before {
            content: '';
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            background: 
                linear-gradient(90deg, 
                    var(--senegal-green) 0%, 
                    var(--senegal-green) 33%, 
                    var(--senegal-yellow) 33%, 
                    var(--senegal-yellow) 66%, 
                    var(--senegal-red) 66%, 
                    var(--senegal-red) 100%);
            opacity: 0.15;
            z-index: -1;
            animation: flagWave 8s ease-in-out infinite;
        }

        @keyframes flagWave {
            0%, 100% { transform: translateX(0) scaleX(1); }
            50% { transform: translateX(-2%) scaleX(1.02); }
        }

        /* √âtoile centrale du drapeau (d√©coration subtile) */
        .chat-header::after {
            content: '‚òÖ';
            position: absolute;
            top: 50%;
            left: 50%;
            transform: translate(-50%, -50%);
            font-size: 180px;
            color: var(--senegal-yellow);
            opacity: 0.06;
            z-index: -1;
            animation: starPulse 4s ease-in-out infinite;
        }

        @keyframes starPulse {
            0%, 100% { transform: translate(-50%, -50%) scale(1) rotate(0deg); }
            50% { transform: translate(-50%, -50%) scale(1.1) rotate(10deg); }
        }

        .chat-header h1 {
            margin: 0;
            font-size: 2.8em;
            font-weight: 800;
            text-shadow: 
                2px 2px 4px rgba(0, 0, 0, 0.3),
                0 0 40px rgba(254, 239, 66, 0.3);
            letter-spacing: 1px;
            animation: titleSlideIn 1s cubic-bezier(0.68, -0.55, 0.265, 1.55);
            position: relative;
            z-index: 2;
        }

        @keyframes titleSlideIn {
            from {
                opacity: 0;
                transform: translateY(-30px) scale(0.9);
            }
            to {
                opacity: 1;
                transform: translateY(0) scale(1);
            }
        }

        .chat-header p {
            margin: 15px 0 0 0;
            font-size: 1.15em;
            opacity: 0.95;
            font-weight: 400;
            text-shadow: 1px 1px 3px rgba(0, 0, 0, 0.2);
            animation: subtitleFadeIn 1.2s ease-out 0.3s both;
            position: relative;
            z-index: 2;
        }

        @keyframes subtitleFadeIn {
            from {
                opacity: 0;
                transform: translateY(20px);
            }
            to {
                opacity: 0.95;
                transform: translateY(0);
            }
        }

        .chat-container {
            flex: 1;
            padding: 40px;
            overflow-y: auto;
            background: transparent;
            max-width: 1200px;
            margin: 0 auto;
            width: 100%;
        }



        /* Scrollbar personnalis√©e */
        .chat-container::-webkit-scrollbar {
            width: 8px;
        }

        .chat-container::-webkit-scrollbar-track {
            background: rgba(255, 255, 255, 0.1);
            border-radius: 4px;
        }

        .chat-container::-webkit-scrollbar-thumb {
            background: linear-gradient(135deg, #2D4D5B, #3388ff);
            border-radius: 4px;
            transition: all 0.3s ease;
        }

        .chat-container::-webkit-scrollbar-thumb:hover {
            background: linear-gradient(135deg, #039, #3388ff);
        }

        .message {
            margin-bottom: 24px;
            padding: 20px 28px;
            border-radius: 24px;
            animation: messageSlideIn 0.7s cubic-bezier(0.68, -0.55, 0.265, 1.55);
            position: relative;
            backdrop-filter: blur(15px);
            transition: var(--transition-smooth);
            transform-origin: left center;
        }

        .message:hover {
            transform: translateX(8px) scale(1.02);
            box-shadow: var(--shadow-medium);
        }

        @keyframes messageSlideIn {
            from {
                opacity: 0;
                transform: translateX(-50px) translateY(20px) scale(0.9) rotate(-2deg);
            }
            to {
                opacity: 1;
                transform: translateX(0) translateY(0) scale(1) rotate(0deg);
            }
        }

        .user-message {
            background: var(--primary-gradient);
            color: white;
            margin-left: 20%;
            text-align: right;
            box-shadow: 
                0 8px 24px rgba(0, 133, 63, 0.25),
                inset 0 1px 0 rgba(255, 255, 255, 0.2);
            border: none;
            transform-origin: right center;
            position: relative;
            overflow: hidden;
        }

        .user-message::before {
            content: '';
            position: absolute;
            top: 0;
            right: 0;
            width: 100%;
            height: 100%;
            background: linear-gradient(135deg, transparent 0%, rgba(254, 239, 66, 0.1) 100%);
            pointer-events: none;
        }

        .user-message:hover {
            transform: translateX(-8px) scale(1.02);
        }

        .assistant-message {
            background: linear-gradient(135deg, rgba(255, 255, 255, 0.95) 0%, rgba(248, 250, 252, 0.95) 100%);
            margin-right: 20%;
            box-shadow: 
                0 8px 32px rgba(0, 0, 0, 0.08),
                inset 0 1px 0 rgba(255, 255, 255, 0.8);
            color: #1e293b;
            border: 1px solid rgba(0, 133, 63, 0.1);
            backdrop-filter: blur(15px);
            position: relative;
            overflow: hidden;
        }

        .assistant-message::before {
            content: '';
            position: absolute;
            top: 0;
            left: 0;
            width: 4px;
            height: 100%;
            background: var(--primary-gradient);
            border-radius: 4px 0 0 4px;
        }

        .chat-input-section {
            padding: 30px 40px;
            background: rgba(255, 255, 255, 0.9);
            backdrop-filter: blur(10px);
            border-top: 1px solid rgba(255, 255, 255, 0.3);
            box-shadow: 0 -2px 20px rgba(0, 0, 0, 0.1);
        }

        .input-section {
            display: flex;
            gap: 15px;
            margin: 0;
            max-width: 1200px;
            margin: 0 auto;
        }

        .input-wrapper {
            flex: 1;
            position: relative;
        }

        #messageInput {
            flex: 1;
            padding: 18px 28px;
            border: 2px solid rgba(0, 133, 63, 0.15);
            border-radius: 50px;
            font-size: 16px;
            color: #1e293b;
            outline: none;
            transition: var(--transition-smooth);
            background: rgba(255, 255, 255, 0.95);
            backdrop-filter: blur(15px);
            box-shadow: 
                0 4px 16px rgba(0, 0, 0, 0.04),
                inset 0 1px 0 rgba(255, 255, 255, 0.8);
        }

        #messageInput::placeholder {
            color: #64748b;
            font-weight: 400;
        }

        #messageInput:focus {
            border-color: var(--senegal-green);
            box-shadow: 
                0 0 0 4px rgba(0, 133, 63, 0.12),
                0 8px 24px rgba(0, 133, 63, 0.15);
            transform: translateY(-2px);
            background: rgba(255, 255, 255, 1);
        }

        #messageInput:hover:not(:focus) {
            border-color: rgba(0, 133, 63, 0.25);
            box-shadow: 0 6px 20px rgba(0, 0, 0, 0.06);
        }

        .send-btn {
            background: var(--primary-gradient);
            color: white;
            border: none;
            padding: 18px 36px;
            border-radius: 50px;
            cursor: pointer;
            font-size: 16px;
            font-weight: 700;
            transition: var(--transition-smooth);
            min-width: 140px;
            box-shadow: 
                0 8px 24px rgba(0, 133, 63, 0.3),
                inset 0 1px 0 rgba(255, 255, 255, 0.2);
            position: relative;
            overflow: hidden;
        }

        .send-btn::before {
            content: '';
            position: absolute;
            top: 50%;
            left: 50%;
            width: 0;
            height: 0;
            border-radius: 50%;
            background: rgba(254, 239, 66, 0.3);
            transform: translate(-50%, -50%);
            transition: width 0.6s ease, height 0.6s ease;
        }

        .send-btn:hover::before {
            width: 300px;
            height: 300px;
        }

        .send-btn:hover {
            transform: translateY(-4px) scale(1.05);
            box-shadow: 
                0 12px 36px rgba(0, 133, 63, 0.4),
                0 0 0 4px rgba(254, 239, 66, 0.2);
        }

        .send-btn:active {
            transform: translateY(-2px) scale(1.02);
        }

        .send-btn:disabled {
            opacity: 0.5;
            cursor: not-allowed;
            transform: none;
        }

        .send-btn:disabled:hover {
            box-shadow: 0 8px 24px rgba(0, 133, 63, 0.3);
        }



        .loading {
            display: none;
            text-align: center;
            color: var(--senegal-green);
            font-style: italic;
            font-weight: 600;
            margin: 24px 0;
            animation: loadingPulse 2s ease-in-out infinite;
            padding: 20px;
            background: rgba(0, 133, 63, 0.05);
            border-radius: 20px;
            backdrop-filter: blur(10px);
        }

        @keyframes loadingPulse {
            0%, 100% { 
                opacity: 0.7; 
                transform: scale(0.98);
            }
            50% { 
                opacity: 1; 
                transform: scale(1.02);
            }
        }

        .typing {
            display: inline-block;
            width: 28px;
            height: 28px;
            border: 4px solid rgba(0, 133, 63, 0.2);
            border-radius: 50%;
            border-top-color: var(--senegal-green);
            border-right-color: var(--senegal-yellow);
            border-bottom-color: var(--senegal-red);
            animation: spin 1.2s cubic-bezier(0.68, -0.55, 0.265, 1.55) infinite;
            margin-right: 12px;
            vertical-align: middle;
            box-shadow: 0 0 20px rgba(0, 133, 63, 0.2);
        }

        .loading-dots {
            display: inline-block;
            margin-left: 10px;
        }

        .loading-dots::after {
            content: '';
            animation: dots 1.5s steps(4, end) infinite;
        }

        @keyframes dots {
            0%, 20% { content: '.'; }
            40% { content: '..'; }
            60%, 100% { content: '...'; }
        }

        @keyframes spin {
            to { transform: rotate(360deg); }
        }

        /* ====== ANIMATIONS FLUIDES ET MICROINTERACTIONS ====== */
        
        /* Effet de brillance sur les boutons */
        .send-btn::after,
        .new-conversation-btn::after {
            content: '';
            position: absolute;
            top: -50%;
            left: -50%;
            width: 200%;
            height: 200%;
            background: linear-gradient(
                45deg,
                transparent 30%,
                rgba(255, 255, 255, 0.3) 50%,
                transparent 70%
            );
            transform: translateX(-100%);
            transition: transform 0.6s ease;
        }

        .send-btn:hover::after,
        .new-conversation-btn:hover::after {
            transform: translateX(100%);
        }

        /* Particules flottantes dans le header */
        @keyframes float {
            0%, 100% {
                transform: translateY(0) translateX(0);
                opacity: 0.3;
            }
            50% {
                transform: translateY(-20px) translateX(10px);
                opacity: 0.6;
            }
        }

        .chat-header .particle {
            position: absolute;
            width: 6px;
            height: 6px;
            background: var(--senegal-yellow);
            border-radius: 50%;
            animation: float 4s ease-in-out infinite;
            opacity: 0.3;
        }

        /* Effet de vague sur scroll */
        @keyframes wave {
            0%, 100% { transform: translateX(0) translateY(0); }
            25% { transform: translateX(5px) translateY(-5px); }
            75% { transform: translateX(-5px) translateY(5px); }
        }

        .chat-container::-webkit-scrollbar-thumb:active {
            animation: wave 0.5s ease;
        }

        /* Effet de tape sur les inputs */
        #messageInput:focus {
            animation: inputFocus 0.3s ease;
        }

        @keyframes inputFocus {
            0% { transform: scale(1); }
            50% { transform: scale(1.01); }
            100% { transform: scale(1); }
        }

        /* Transition douce entre les pages de conversation */
        .chat-container.transitioning {
            animation: fadeSlide 0.4s ease;
        }

        @keyframes fadeSlide {
            0% {
                opacity: 0.5;
                transform: translateY(10px);
            }
            100% {
                opacity: 1;
                transform: translateY(0);
            }
        }

        /* Effet de survol premium sur les messages */
        .message::after {
            content: '';
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            border-radius: inherit;
            opacity: 0;
            transition: opacity 0.3s ease;
            pointer-events: none;
        }

        .user-message::after {
            background: radial-gradient(circle at var(--mouse-x, 50%) var(--mouse-y, 50%), 
                rgba(254, 239, 66, 0.2) 0%, 
                transparent 60%);
        }

        .assistant-message::after {
            background: radial-gradient(circle at var(--mouse-x, 50%) var(--mouse-y, 50%), 
                rgba(0, 133, 63, 0.1) 0%, 
                transparent 60%);
        }

        .message:hover::after {
            opacity: 1;
        }

        /* Badge "Nouveau" anim√© */
        @keyframes badgePulse {
            0%, 100% {
                transform: scale(1);
                box-shadow: 0 0 0 0 rgba(227, 27, 35, 0.4);
            }
            50% {
                transform: scale(1.05);
                box-shadow: 0 0 0 6px rgba(227, 27, 35, 0);
            }
        }

        /* Responsive Design Premium */
        @media (max-width: 1024px) {
            .chat-header h1 {
                font-size: 2.4em;
            }
            
            .message {
                margin-left: 10% !important;
                margin-right: 10% !important;
            }
        }

        @media (max-width: 768px) {
            .chat-container {
                padding: 16px;
            }
            
            .chat-header {
                padding: 30px 24px;
            }
            
            .chat-header h1 {
                font-size: 2em;
                letter-spacing: 0.5px;
            }
            
            .chat-header p {
                font-size: 1em;
            }
            
            .chat-input-section {
                padding: 16px;
            }
            
            .input-section {
                flex-direction: row;
                flex-wrap: wrap;
                gap: 10px;
            }
            
            #messageInput {
                width: 100%;
                padding: 16px 24px;
            }
            
            .new-conversation-btn,
            .send-btn {
                flex: 1;
                min-width: 120px;
                padding: 16px 24px;
            }
            
            .message {
                margin-left: 5% !important;
                margin-right: 5% !important;
                padding: 16px 20px;
            }
            
            .theme-toggle,
            .scroll-bottom {
                width: 48px;
                height: 48px;
                font-size: 18px;
            }
            
            .conversations-toggle {
                width: 54px;
                height: 54px;
                font-size: 20px;
                top: 24px;
                left: 24px;
            }
            
            .conversations-panel {
                width: 85%;
            }
        }

        @media (max-width: 480px) {
            .chat-container {
                padding: 12px;
            }
            
            .chat-header {
                padding: 24px 16px;
            }
            
            .chat-header h1 {
                font-size: 1.6em;
            }
            
            .chat-header p {
                font-size: 0.9em;
                margin-top: 10px;
            }
            
            .chat-input-section {
                padding: 12px;
            }
            
            .input-section {
                gap: 8px;
            }
            
            #messageInput {
                padding: 14px 20px;
                font-size: 15px;
            }
            
            .new-conversation-btn,
            .send-btn {
                padding: 14px 20px;
                font-size: 14px;
                min-width: 100px;
            }
            
            .message {
                margin-left: 0 !important;
                margin-right: 0 !important;
                padding: 14px 18px;
                border-radius: 18px;
            }
            
            .message:hover {
                transform: translateX(4px) scale(1.01);
            }
            
            .user-message:hover {
                transform: translateX(-4px) scale(1.01);
            }
            
            .theme-toggle {
                top: 20px;
                right: 20px;
                width: 44px;
                height: 44px;
                font-size: 16px;
            }
            
            .scroll-bottom {
                width: 50px;
                height: 50px;
                font-size: 18px;
                bottom: 120px;
                right: 20px;
            }
            
            .conversations-toggle {
                width: 50px;
                height: 50px;
                font-size: 18px;
                top: 20px;
                left: 20px;
            }
            
            .conversations-panel {
                width: 100%;
            }
            
            .message-actions {
                flex-wrap: wrap;
            }
            
            .message-btn {
                font-size: 12px;
                padding: 6px 12px;
            }
        }

        @media (max-width: 360px) {
            .chat-header h1 {
                font-size: 1.4em;
            }
            
            .input-section {
                flex-direction: column;
            }
            
            .new-conversation-btn,
            .send-btn {
                width: 100%;
            }
        }

        /* ====== THEME TOGGLE + SCROLL TO BOTTOM ====== */
        .theme-toggle {
            position: absolute;
            top: 30px;
            right: 30px;
            width: 52px;
            height: 52px;
            border-radius: 50%;
            border: 2px solid rgba(255, 255, 255, 0.3);
            background: rgba(255, 255, 255, 0.15);
            color: var(--senegal-yellow);
            cursor: pointer;
            display: inline-flex;
            align-items: center;
            justify-content: center;
            box-shadow: 
                0 6px 20px rgba(0, 0, 0, 0.2),
                inset 0 1px 0 rgba(255, 255, 255, 0.3);
            transition: var(--transition-smooth);
            backdrop-filter: blur(10px);
            font-size: 22px;
            z-index: 100;
        }

        .theme-toggle:hover {
            transform: translateY(-4px) rotate(20deg) scale(1.1);
            background: rgba(255, 255, 255, 0.25);
            box-shadow: 
                0 10px 30px rgba(0, 0, 0, 0.25),
                0 0 0 4px rgba(254, 239, 66, 0.3);
        }

        /* Contr√¥les de l'en-t√™te */
        .header-controls {
            position: absolute;
            top: 30px;
            right: 30px;
            display: flex;
            gap: 15px;
            align-items: center;
            z-index: 100;
        }

        .header-btn {
            position: relative !important;
            right: 90px !important;
            top: 35px !important;
        }

        .theme-toggle {
            order: 1;
        }

        .header-btn {
            padding: 12px 20px;
            border-radius: 25px;
            border: 2px solid rgba(255, 255, 255, 0.3);
            background: rgba(255, 255, 255, 0.15);
            color: white;
            cursor: pointer;
            display: inline-flex;
            align-items: center;
            gap: 8px;
            box-shadow: 
                0 6px 20px rgba(0, 0, 0, 0.2),
                inset 0 1px 0 rgba(255, 255, 255, 0.3);
            transition: var(--transition-smooth);
            backdrop-filter: blur(10px);
            font-size: 14px;
            font-weight: 600;
        }

        .header-btn:hover {
            transform: translateY(-2px);
            background: rgba(255, 255, 255, 0.25);
            box-shadow: 
                0 8px 25px rgba(0, 0, 0, 0.25),
                0 0 0 3px rgba(254, 239, 66, 0.3);
        }

        .theme-toggle {
            width: 52px;
            height: 52px;
            border-radius: 50%;
            border: 2px solid rgba(255, 255, 255, 0.3);
            background: rgba(255, 255, 255, 0.15);
            color: var(--senegal-yellow);
            cursor: pointer;
            display: inline-flex;
            align-items: center;
            justify-content: center;
            box-shadow: 
                0 6px 20px rgba(0, 0, 0, 0.2),
                inset 0 1px 0 rgba(255, 255, 255, 0.3);
            transition: var(--transition-smooth);
            backdrop-filter: blur(10px);
            font-size: 22px;
        }

        .scroll-bottom {
            position: fixed;
            right: 30px;
            bottom: 140px;
            width: 56px;
            height: 56px;
            border-radius: 50%;
            border: 2px solid rgba(0, 133, 63, 0.3);
            background: var(--primary-gradient);
            color: #fff;
            display: inline-flex;
            align-items: center;
            justify-content: center;
            cursor: pointer;
            box-shadow: 
                0 8px 28px rgba(0, 133, 63, 0.4),
                inset 0 1px 0 rgba(255, 255, 255, 0.2);
            opacity: 0;
            transform: translateY(20px) scale(0.8);
            visibility: hidden;
            transition: var(--transition-bounce);
            z-index: 1001;
            font-size: 20px;
        }

        .scroll-bottom.visible {
            opacity: 1;
            transform: translateY(0) scale(1);
            visibility: visible;
            animation: bounceIn 0.6s cubic-bezier(0.68, -0.55, 0.265, 1.55);
        }

        @keyframes bounceIn {
            0% {
                transform: translateY(20px) scale(0.8);
                opacity: 0;
            }
            50% {
                transform: translateY(-5px) scale(1.05);
            }
            100% {
                transform: translateY(0) scale(1);
                opacity: 1;
            }
        }

        .scroll-bottom:hover {
            transform: translateY(-6px) scale(1.15);
            box-shadow: 
                0 12px 40px rgba(0, 133, 63, 0.5),
                0 0 0 4px rgba(254, 239, 66, 0.3);
        }

        /* Mode sombre avec couleurs du drapeau s√©n√©galais */
        body.dark-mode {
            background: linear-gradient(135deg, #0a1f0f 0%, #051509 100%);
        }
        
        body.dark-mode::before {
            background: 
                radial-gradient(circle at 20% 50%, rgba(254, 239, 66, 0.08) 0%, transparent 50%),
                radial-gradient(circle at 80% 80%, rgba(227, 27, 35, 0.05) 0%, transparent 50%);
        }
        
        body.dark-mode .chat-app {
            background: rgba(10, 20, 15, 0.95);
            box-shadow: 0 0 100px rgba(0, 133, 63, 0.2);
        }
        
        body.dark-mode .chat-header {
            background: linear-gradient(135deg, #0a2e17 0%, #051509 100%);
            box-shadow: 0 8px 40px rgba(0, 133, 63, 0.4);
        }
        
        body.dark-mode .assistant-message {
            background: linear-gradient(135deg, rgba(17, 24, 39, 0.95) 0%, rgba(15, 23, 42, 0.95) 100%);
            color: #E5E7EB;
            border-color: rgba(0, 133, 63, 0.3);
            box-shadow: 0 8px 32px rgba(0, 0, 0, 0.3);
        }
        
        body.dark-mode .assistant-message::before {
            background: var(--primary-gradient);
        }
        
        body.dark-mode #messageInput {
            background: rgba(17, 24, 39, 0.95);
            color: #E5E7EB;
            border-color: rgba(0, 133, 63, 0.3);
            box-shadow: 0 4px 20px rgba(0, 0, 0, 0.3);
        }
        
        body.dark-mode #messageInput::placeholder {
            color: #94A3B8;
        }
        
        body.dark-mode #messageInput:focus {
            border-color: var(--senegal-yellow);
            box-shadow: 0 0 0 4px rgba(254, 239, 66, 0.15);
        }
        
        body.dark-mode .chat-input-section {
            background: rgba(10, 20, 15, 0.95);
            border-top-color: rgba(0, 133, 63, 0.3);
        }
        
        body.dark-mode .message-btn {
            background: rgba(30, 41, 59, 0.9);
            border-color: rgba(0, 133, 63, 0.3);
            color: #E5E7EB;
        }
        
        body.dark-mode .conversation-item { 
            background: linear-gradient(135deg, rgba(17, 24, 39, 0.9) 0%, rgba(15, 23, 42, 0.9) 100%);
            color: #E5E7EB; 
            border-color: rgba(0, 133, 63, 0.2);
        }
        
        body.dark-mode .conversation-item:hover { 
            background: linear-gradient(135deg, rgba(0, 133, 63, 0.15) 0%, rgba(15, 23, 42, 0.95) 100%);
            border-color: rgba(254, 239, 66, 0.4);
        }
        
        body.dark-mode .conversation-item.active {
            background: linear-gradient(135deg, rgba(0, 133, 63, 0.25) 0%, rgba(254, 239, 66, 0.15) 100%);
            border-color: var(--senegal-yellow);
        }
        
        body.dark-mode .conversations-panel { 
            background: linear-gradient(135deg, rgba(10, 20, 15, 0.98) 0%, rgba(15, 23, 42, 0.98) 100%);
            border-right-color: var(--senegal-green);
        }
        
        body.dark-mode .conversations-header { 
            background: var(--secondary-gradient);
            border-bottom-color: rgba(0, 133, 63, 0.4);
        }
        
        body.dark-mode .loading {
            background: rgba(0, 133, 63, 0.1);
            color: var(--senegal-yellow);
        }
        
        body.dark-mode .modal-content {
            background: linear-gradient(135deg, #1e293b 0%, #0f172a 100%);
            color: #E5E7EB;
            box-shadow: 0 20px 60px rgba(0, 0, 0, 0.6);
        }
        
        body.dark-mode .modal-textarea {
            background: rgba(15, 23, 42, 0.95);
            color: #E5E7EB;
            border-color: rgba(0, 133, 63, 0.3);
        }

        /* ====== BOUTONS CHATGPT ====== */
        .message {
            position: relative;
        }

        .message-actions {
            display: none;
            flex-direction: row;
            gap: 8px;
            margin-top: 12px;
            padding-top: 10px;
            border-top: 1px solid rgba(0, 0, 0, 0.1);
            opacity: 0;
            transform: translateY(5px);
            transition: all 0.3s ease;
        }

        .message:hover .message-actions {
            display: flex;
            opacity: 1;
            transform: translateY(0);
        }

        .message-btn {
            display: inline-flex;
            align-items: center;
            gap: 6px;
            padding: 8px 16px;
            background: rgba(255, 255, 255, 0.95);
            border: 2px solid rgba(0, 133, 63, 0.15);
            border-radius: 12px;
            font-size: 13px;
            color: #334155;
            cursor: pointer;
            transition: var(--transition-smooth);
            font-weight: 600;
            box-shadow: 0 2px 8px rgba(0, 0, 0, 0.05);
            position: relative;
            overflow: hidden;
        }

        .message-btn::before {
            content: '';
            position: absolute;
            top: 50%;
            left: 50%;
            width: 0;
            height: 0;
            border-radius: 50%;
            transform: translate(-50%, -50%);
            transition: width 0.4s ease, height 0.4s ease;
        }

        .message-btn:hover::before {
            width: 200px;
            height: 200px;
        }

        .message-btn:hover {
            transform: translateY(-3px) scale(1.05);
            box-shadow: 0 6px 20px rgba(0, 133, 63, 0.15);
        }

        .message-btn.edit::before {
            background: rgba(251, 146, 60, 0.1);
        }

        .message-btn.edit:hover {
            border-color: rgba(251, 146, 60, 0.4);
            color: #f59e0b;
            box-shadow: 0 6px 20px rgba(251, 146, 60, 0.2);
        }

        .message-btn.regenerate::before {
            background: rgba(0, 133, 63, 0.1);
        }

        .message-btn.regenerate:hover {
            border-color: var(--senegal-green);
            color: var(--senegal-green);
            box-shadow: 0 6px 20px rgba(0, 133, 63, 0.2);
        }

        .message-btn.copy::before {
            background: rgba(254, 239, 66, 0.2);
        }

        .message-btn.copy:hover {
            border-color: var(--senegal-yellow);
            color: #a16207;
            box-shadow: 0 6px 20px rgba(254, 239, 66, 0.3);
        }

        /* Modal d'√©dition */
        .modal-overlay {
            display: none;
            position: fixed;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            background: rgba(0, 0, 0, 0.5);
            backdrop-filter: blur(5px);
            z-index: 1000;
            align-items: center;
            justify-content: center;
        }

        .modal-overlay.show {
            display: flex;
        }

        .modal-content {
            background: white;
            padding: 30px;
            border-radius: 15px;
            width: 90%;
            max-width: 500px;
            box-shadow: 0 20px 60px rgba(0, 0, 0, 0.3);
        }

        .modal-content h3 {
            margin: 0 0 20px 0;
            color: #333;
            font-size: 1.2em;
        }

        .modal-textarea {
            width: 100%;
            height: 120px;
            padding: 12px;
            border: 2px solid rgba(0, 0, 0, 0.1);
            border-radius: 8px;
            font-family: inherit;
            font-size: 14px;
            resize: vertical;
            outline: none;
            margin-bottom: 20px;
            box-sizing: border-box;
        }

        .modal-textarea:focus {
            border-color: #2C5530;
            box-shadow: 0 0 0 3px rgba(44, 85, 48, 0.1);
        }

        .modal-buttons {
            display: flex;
            gap: 12px;
            justify-content: flex-end;
        }

        .modal-btn {
            padding: 10px 20px;
            border: none;
            border-radius: 8px;
            font-size: 14px;
            font-weight: 500;
            cursor: pointer;
            transition: all 0.2s ease;
        }

        .modal-btn.primary {
            background: linear-gradient(135deg, #2C5530 0%, #1B4332 100%);
            color: white;
        }

        .modal-btn.primary:hover {
            transform: translateY(-1px);
            box-shadow: 0 4px 12px rgba(44, 85, 48, 0.3);
        }

        .modal-btn.secondary {
            background: #f3f4f6;
            color: #374151;
            border: 1px solid rgba(0, 0, 0, 0.1);
        }

        .modal-btn.secondary:hover {
            background: #e5e7eb;
        }

        /* ====== STYLES PANNEAU CONVERSATIONS ====== */
        .conversations-toggle {
            position: fixed !important;
            top: 30px;
            left: 30px;
            width: 65px;
            height: 65px;
            border-radius: 50%;
            background: var(--primary-gradient);
            border: 3px solid rgba(254, 239, 66, 0.6);
            color: white;
            font-size: 26px;
            cursor: pointer;
            box-shadow: 
                0 10px 35px rgba(0, 133, 63, 0.5),
                0 0 0 0 rgba(254, 239, 66, 0.7),
                inset 0 2px 0 rgba(255, 255, 255, 0.3);
            z-index: 10000 !important;
            transition: var(--transition-bounce);
            display: flex !important;
            align-items: center;
            justify-content: center;
            overflow: visible;
            animation: conversationPulse 3s ease-in-out infinite;
        }

        @keyframes conversationPulse {
            0%, 100% {
                box-shadow: 
                    0 10px 35px rgba(0, 133, 63, 0.5),
                    0 0 0 0 rgba(254, 239, 66, 0.7),
                    inset 0 2px 0 rgba(255, 255, 255, 0.3);
            }
            50% {
                box-shadow: 
                    0 10px 35px rgba(0, 133, 63, 0.5),
                    0 0 0 8px rgba(254, 239, 66, 0.3),
                    inset 0 2px 0 rgba(255, 255, 255, 0.3);
            }
        }

        .conversations-toggle::before {
            content: '';
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            background: radial-gradient(circle, rgba(254, 239, 66, 0.3) 0%, transparent 70%);
            animation: pulseRing 2s ease-in-out infinite;
        }

        @keyframes pulseRing {
            0%, 100% {
                transform: scale(0.8);
                opacity: 0;
            }
            50% {
                transform: scale(1.2);
                opacity: 1;
            }
        }

        .conversations-toggle:hover {
            transform: scale(1.2) rotate(15deg);
            box-shadow: 
                0 15px 50px rgba(0, 133, 63, 0.6),
                0 0 0 10px rgba(254, 239, 66, 0.4),
                inset 0 2px 0 rgba(255, 255, 255, 0.4);
            animation: none;
        }

        .conversations-toggle i {
            position: relative;
            z-index: 10001 !important;
            filter: drop-shadow(0 2px 4px rgba(0, 0, 0, 0.3));
            display: inline-block;
            color: white;
            font-size: 26px;
        }

        /* S'assurer que le bouton est toujours visible */
        #conversationsToggle {
            visibility: visible !important;
            opacity: 1 !important;
            pointer-events: auto !important;
        }

        .new-conversation-btn {
            background: linear-gradient(135deg, var(--senegal-yellow) 0%, #e6d000 100%);
            border: none;
            color: #1e293b;
            padding: 18px 28px;
            border-radius: 50px;
            cursor: pointer;
            font-size: 15px;
            font-weight: 700;
            transition: var(--transition-smooth);
            margin-right: 12px;
            box-shadow: 
                0 6px 20px rgba(254, 239, 66, 0.3),
                inset 0 1px 0 rgba(255, 255, 255, 0.5);
            display: flex;
            align-items: center;
            justify-content: center;
            white-space: nowrap;
            position: relative;
            overflow: hidden;
        }

        .new-conversation-btn::before {
            content: '';
            position: absolute;
            top: 50%;
            left: 50%;
            width: 0;
            height: 0;
            border-radius: 50%;
            background: rgba(227, 27, 35, 0.2);
            transform: translate(-50%, -50%);
            transition: width 0.5s ease, height 0.5s ease;
        }

        .new-conversation-btn:hover::before {
            width: 300px;
            height: 300px;
        }

        .new-conversation-btn:hover {
            transform: translateY(-4px) scale(1.05);
            box-shadow: 
                0 10px 30px rgba(254, 239, 66, 0.4),
                0 0 0 4px rgba(0, 133, 63, 0.15);
        }

        .new-conversation-btn:active {
            transform: translateY(-2px) scale(1.02);
        }

        .conversations-panel {
            position: fixed;
            top: 0;
            left: 0;
            width: 400px;
            height: 100vh;
            background: linear-gradient(135deg, rgba(255, 255, 255, 0.98) 0%, rgba(248, 250, 252, 0.98) 100%);
            box-shadow: 
                4px 0 40px rgba(0, 133, 63, 0.2),
                inset -1px 0 0 rgba(0, 133, 63, 0.15);
            z-index: 1001;
            display: none;
            flex-direction: column;
            border-right: 4px solid var(--senegal-green);
            backdrop-filter: blur(20px);
            transform: translateX(-100%);
            transition: transform 0.4s cubic-bezier(0.68, -0.55, 0.265, 1.55);
        }

        .conversations-panel.show {
            display: flex;
            transform: translateX(0);
        }

        @keyframes slideInLeft {
            from {
                transform: translateX(-100%);
                opacity: 0;
            }
            to {
                transform: translateX(0);
                opacity: 1;
            }
        }

        .conversations-header {
            padding: 28px 24px;
            border-bottom: 2px solid rgba(0, 133, 63, 0.15);
            background: var(--primary-gradient);
            display: flex;
            justify-content: space-between;
            align-items: center;
            box-shadow: 0 4px 20px rgba(0, 133, 63, 0.2);
        }

        .conversations-header h3 {
            color: white;
            text-shadow: 0 2px 4px rgba(0, 0, 0, 0.2);
        }

        .conversations-header h3 {
            margin: 0;
            font-size: 18px;
            color: #1f2937;
            font-weight: 600;
        }

        .conversations-actions {
            display: flex;
            gap: 8px;
        }

        .conv-btn {
            padding: 10px 18px;
            border: 2px solid transparent;
            border-radius: 12px;
            font-size: 13px;
            cursor: pointer;
            transition: var(--transition-smooth);
            font-weight: 700;
            box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);
        }

        .conv-btn.primary {
            background: linear-gradient(135deg, var(--senegal-yellow) 0%, #e6d000 100%);
            color: #1e293b;
        }

        .conv-btn.primary:hover {
            transform: translateY(-3px) scale(1.05);
            box-shadow: 
                0 6px 20px rgba(254, 239, 66, 0.4),
                0 0 0 3px rgba(0, 133, 63, 0.2);
        }

        .conv-btn.secondary {
            background: rgba(255, 255, 255, 0.9);
            color: #1e293b;
            border-color: rgba(0, 133, 63, 0.2);
        }

        .conv-btn.secondary:hover {
            background: rgba(255, 255, 255, 1);
            border-color: var(--senegal-green);
            transform: translateY(-2px);
            box-shadow: 0 4px 16px rgba(0, 133, 63, 0.2);
        }

        .conversations-list {
            flex: 1;
            overflow-y: auto;
            padding: 10px;
        }

        .conversation-item {
            padding: 16px 20px;
            margin-bottom: 12px;
            border-radius: 16px;
            cursor: pointer;
            transition: var(--transition-smooth);
            border: 2px solid transparent;
            background: linear-gradient(135deg, rgba(255, 255, 255, 0.9) 0%, rgba(249, 250, 251, 0.9) 100%);
            box-shadow: 0 2px 12px rgba(0, 0, 0, 0.05);
            position: relative;
            overflow: hidden;
        }

        .conversation-item::before {
            content: '';
            position: absolute;
            left: 0;
            top: 0;
            width: 4px;
            height: 100%;
            background: var(--primary-gradient);
            transform: scaleY(0);
            transition: transform 0.3s ease;
        }

        .conversation-item:hover::before {
            transform: scaleY(1);
        }

        .conversation-item:hover {
            background: linear-gradient(135deg, rgba(254, 239, 66, 0.1) 0%, rgba(255, 255, 255, 0.95) 100%);
            border-color: rgba(0, 133, 63, 0.3);
            transform: translateX(8px) scale(1.02);
            box-shadow: 0 6px 24px rgba(0, 133, 63, 0.15);
        }

        .conversation-item.active {
            background: linear-gradient(135deg, rgba(0, 133, 63, 0.15) 0%, rgba(254, 239, 66, 0.15) 100%);
            border-color: var(--senegal-green);
            box-shadow: 
                0 6px 24px rgba(0, 133, 63, 0.25),
                inset 0 1px 0 rgba(255, 255, 255, 0.5);
        }

        .conversation-item.active::before {
            transform: scaleY(1);
            width: 6px;
        }

        .conversation-title {
            font-weight: 500;
            color: #1f2937;
            margin-bottom: 4px;
            font-size: 14px;
            line-height: 1.4;
            overflow: hidden;
            text-overflow: ellipsis;
            white-space: nowrap;
        }

        .conversation-meta {
            display: flex;
            justify-content: space-between;
            align-items: center;
        }

        .conversation-date {
            font-size: 12px;
            color: #6b7280;
        }

        .conversation-delete {
            background: none;
            border: none;
            color: #ef4444;
            cursor: pointer;
            padding: 4px;
            border-radius: 4px;
            opacity: 0;
            transition: all 0.2s ease;
            font-size: 14px;
        }

        .conversation-item:hover .conversation-delete {
            opacity: 1;
        }

        .conversation-delete:hover {
            background: #fef2f2;
            transform: scale(1.1);
        }

        /* Responsive pour mobile */
        @media (max-width: 768px) {
            .conversations-panel {
                width: 100%;
            }
            
            .conversations-toggle {
                top: 15px;
                left: 15px;
                width: 45px;
                height: 45px;
                font-size: 18px;
            }
            
            .new-conversation-btn {
                padding: 10px 12px;
                margin-right: 6px;
                font-size: 12px;
            }
            
            .input-section {
                gap: 8px;
            }
        }


    </style>
</head>
<body>
    <!-- Application DOCUMIND plein √©cran -->
    <div class="chat-app">
        <div class="container">
            <div class="chat-header">
                <h1>üá∏üá≥ LexFin - MODE RAG STRICT</h1>
                <p>Assistant IA d√©di√© √† la fiscalit√©  ‚Ä¢  R√©ponses pr√©cises bas√©es sur une base documentaire fiscale sp√©cialis√©e</p>
                <div class="header-controls">
                    <button id="newConversationBtn" class="header-btn" title="Nouvelle conversation" onclick="newConversation()">
                        <i class="fa-solid fa-plus"></i> Nouvelle conversation
                    </button>
                    <button id="themeToggle" class="theme-toggle" title="Changer de th√®me">
                        <i class="fa-solid fa-moon"></i>
                    </button>
                </div>
            </div>

        <div class="chat-container" id="chatContainer">
            <div class="message assistant-message">
                <div style="display: flex; align-items: center; gap: 12px; margin-bottom: 16px;">
                    <span style="font-size: 48px; filter: drop-shadow(0 2px 8px rgba(0, 133, 63, 0.3));">üá∏üá≥</span>
                    <div>
                        <div style="font-size: 1.3em; font-weight: 700; color: var(--senegal-green); margin-bottom: 4px;">
                            Bienvenue sur LexFin
                        </div>
                        <div style="font-size: 0.95em; color: #64748b; font-weight: 500;">
                            Assistant IA d√©di√© √† la fiscalit√©
                        </div>
                    </div>
                </div>
                
                <div style="background: linear-gradient(135deg, rgba(0, 133, 63, 0.08) 0%, rgba(254, 239, 66, 0.08) 100%); 
                            padding: 16px; border-radius: 12px; margin-bottom: 16px; 
                            border-left: 4px solid var(--senegal-green);">
                    <div style="font-weight: 700; color: var(--senegal-green); margin-bottom: 8px; display: flex; align-items: center; gap: 8px;">
                        <span style="font-size: 1.1em;">‚ö°</span> Mode RAG Strict Activ√©
                    </div>
                    <div style="font-size: 0.9em; color: #475569; line-height: 1.6;">
                        R√©ponses exclusivement bas√©es sur les documents fiscaux officiels index√©s
                    </div>
                </div>
                
                <div style="margin-bottom: 16px;">
                    <div style="font-weight: 700; color: #1e293b; margin-bottom: 12px; font-size: 1.05em;">
                        üìö Domaines d'Expertise
                    </div>
                    <div style="display: grid; gap: 8px; margin-left: 8px;">
                        <div style="display: flex; align-items: start; gap: 8px;">
                            <span style="color: var(--senegal-green); font-weight: 700;">‚úì</span>
                            <span style="line-height: 1.5;">Code G√©n√©ral des Imp√¥ts (CGI) du S√©n√©gal</span>
                        </div>
                        <div style="display: flex; align-items: start; gap: 8px;">
                            <span style="color: var(--senegal-green); font-weight: 700;">‚úì</span>
                            <span style="line-height: 1.5;">Code des Douanes de la R√©publique du S√©n√©gal</span>
                        </div>
                        <div style="display: flex; align-items: start; gap: 8px;">
                            <span style="color: var(--senegal-green); font-weight: 700;">‚úì</span>
                            <span style="line-height: 1.5;">Textes fiscaux et r√©glementations douani√®res officielles</span>
                        </div>
                    </div>
                </div>
                
                <div style="background: linear-gradient(135deg, rgba(254, 239, 66, 0.1) 0%, rgba(255, 255, 255, 0.5) 100%); 
                            padding: 14px; border-radius: 12px; border: 2px solid rgba(254, 239, 66, 0.3);">
                    <div style="font-weight: 700; color: #854d0e; margin-bottom: 10px; display: flex; align-items: center; gap: 8px;">
                        <span style="font-size: 1.1em;">üí°</span> Exemples de Questions
                    </div>
                    <div style="display: grid; gap: 6px; font-size: 0.9em; color: #475569; margin-left: 8px;">
                        <div style="line-height: 1.5;">‚Ä¢ "Que dit l'article 45 du code g√©n√©ral des imp√¥ts ?"</div>
                        <div style="line-height: 1.5;">‚Ä¢ "Quel est le taux de la TVA au S√©n√©gal ?"</div>
                        <div style="line-height: 1.5;">‚Ä¢ "Comment calculer l'imp√¥t minimum forfaitaire ?"</div>
                        <div style="line-height: 1.5;">‚Ä¢ "Quelles sont les conditions d'exon√©ration de droits de douane ?"</div>
                        <div style="line-height: 1.5;">‚Ä¢ "Qu'est-ce que le r√©gime de l'entrep√¥t de stockage ?"</div>
                        <div style="line-height: 1.5;">‚Ä¢ "Comment fonctionne la proc√©dure de d√©douanement ?"</div>
                    </div>
                </div>
                
                <div style="margin-top: 16px; padding-top: 16px; border-top: 2px solid rgba(0, 133, 63, 0.1); 
                            text-align: center; color: var(--senegal-green); font-weight: 600; font-size: 1.05em;">
                    üöÄ Pr√™t √† r√©pondre √† vos questions fiscales et douani√®res !
                </div>
            </div>
        </div>

            <div class="loading" id="loading">
                <div class="typing"></div>
                <span>LexFin analyse votre question fiscal/douani√®re<span class="loading-dots"></span></span>
            </div>

            <div class="chat-input-section">
                <div class="input-section">
                    <input type="text" id="messageInput" placeholder="Posez votre question sur le Code des Imp√¥ts ou Code des Douanes uniquement..." onkeypress="checkEnter(event)">
                    <button class="send-btn" id="sendBtn" onclick="sendMessage()">
                         Envoyer
                    </button>
                </div>
            </div>
        </div>
    </div>

    <!-- Bouton flottant pour ouvrir le panneau des conversations (POSITION FIXE) -->
    <button id="conversationsToggle" class="conversations-toggle" onclick="toggleConversationsPanel()" title="üí¨ Historique des Conversations" style="position: fixed !important; top: 30px !important; left: 30px !important; z-index: 10000 !important; display: flex !important;">
        <i class="fa-solid fa-comments" style="color: white; font-size: 26px;"></i>
    </button>

    <!-- Bouton scroll vers le bas -->
    <button id="scrollBottom" class="scroll-bottom" title="Aller en bas">
        <i class="fa-solid fa-arrow-down"></i>
    </button>

    <!-- Modal d'√©dition -->
    <div class="modal-overlay" id="editModal" onclick="closeEditModal()">
        <div class="modal-content" onclick="event.stopPropagation()">
            <h3>‚úèÔ∏è Modifier le message</h3>
            <textarea class="modal-textarea" id="editTextarea" placeholder="Modifiez votre message..."></textarea>
            <div class="modal-buttons">
                <button class="modal-btn secondary" onclick="closeEditModal()">Annuler</button>
                <button class="modal-btn primary" onclick="saveEditMessage()">üí´ Envoyer</button>
            </div>
        </div>
    </div>

    <!-- Panneau de gestion des conversations -->
    <div id="conversationsPanel" class="conversations-panel">
        <div class="conversations-header">
            <h3>üí¨ Conversations</h3>
            <div class="conversations-actions">
                <button class="conv-btn primary" onclick="startNewConversation()" title="Nouvelle conversation">
                     Nouveau
                </button>
                <button class="conv-btn secondary" onclick="toggleConversationsPanel()" title="Fermer">
                    ‚úï
                </button>
            </div>
        </div>
        <div class="conversations-list" id="conversationsList">
            <!-- Liste des conversations g√©n√©r√©e dynamiquement -->
        </div>
    </div>

    <script>
        // DOCUMIND - Application plein √©cran
        
        // Variable globale pour l'ID de conversation actuelle
        let currentConversationId = null;

        function checkEnter(event) {
            if (event.key === 'Enter') {
                sendMessage();
            }
        }

        async function sendMessage() {
            const input = document.getElementById('messageInput');
            const message = input.value.trim();
            
            if (!message) return;

            const chatContainer = document.getElementById('chatContainer');
            const sendBtn = document.getElementById('sendBtn');
            const loading = document.getElementById('loading');

            // Ajouter le message utilisateur
            const userMessage = document.createElement('div');
            userMessage.className = 'message user-message';
            userMessage.textContent = message;
            chatContainer.appendChild(userMessage);

            // Vider l'input et d√©sactiver le bouton
            input.value = '';
            sendBtn.disabled = true;
            loading.style.display = 'block';
            
            // Faire d√©filer vers le bas
            chatContainer.scrollTop = chatContainer.scrollHeight;
            // Mettre √† jour le bouton de scroll
            try { chatContainer.dispatchEvent(new Event('scroll')); } catch (e) {}

            try {
                // Cr√©er une nouvelle conversation si n√©cessaire
                if (!currentConversationId) {
                    const convResponse = await fetch('/conversation/new', {
                        method: 'POST',
                        headers: {
                            'Content-Type': 'application/json',
                        },
                        body: JSON.stringify({ title: message.substring(0, 50) + '...' })
                    });
                    const convData = await convResponse.json();
                    currentConversationId = convData.conversation_id;
                }
                
                // Envoyer le message avec l'ID de conversation
                const response = await fetch('/chat', {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json',
                    },
                    body: JSON.stringify({ 
                        message: message,
                        conversation_id: currentConversationId 
                    })
                });

                const data = await response.json();

                // Ajouter la r√©ponse de l'assistant avec effet de frappe
                const assistantMessage = document.createElement('div');
                assistantMessage.className = 'message assistant-message';
                assistantMessage.innerHTML = '';
                chatContainer.appendChild(assistantMessage);
                
                // Effet de frappe
                const textSpan = document.createElement('span');
                assistantMessage.appendChild(textSpan);
                typewriterEffect(textSpan, data.response, 20);
                
                // Ajouter les r√©f√©rences si disponibles
                if (data.references && data.references.length > 0) {
                    setTimeout(() => {
                        addReferencesSection(assistantMessage, data.references);
                    }, 1500);
                }
                
                // Ajouter les effets de survol
                setTimeout(() => addMessageEffects(), 1000);
                // Mettre √† jour le bouton de scroll apr√®s ajout de la r√©ponse
                setTimeout(() => { try { chatContainer.dispatchEvent(new Event('scroll')); } catch (e) {} }, 50);

            } catch (error) {
                const errorMessage = document.createElement('div');
                errorMessage.className = 'message assistant-message';
                errorMessage.textContent = 'D√©sol√©, une erreur s\\'est produite. Veuillez r√©essayer.';
                errorMessage.style.color = '#e74c3c';
                chatContainer.appendChild(errorMessage);
            }

            // R√©activer le bouton et cacher le loading
            sendBtn.disabled = false;
            loading.style.display = 'none';
            
            // Faire d√©filer vers le bas
            chatContainer.scrollTop = chatContainer.scrollHeight;
            // Mettre √† jour le bouton de scroll
            try { chatContainer.dispatchEvent(new Event('scroll')); } catch (e) {}
            
            // Ajouter les boutons aux nouveaux messages
            setTimeout(() => {
                addChatButtons();
                // Sauvegarder automatiquement la conversation
                saveCurrentConversation();
            }, 300);
        }

        // Fonction pour d√©marrer une nouvelle conversation
        function newConversation() {
            // R√©initialiser l'ID de conversation
            currentConversationId = null;
            
            // Vider le chat
            clearChat();
            
            console.log('Nouvelle conversation d√©marr√©e');
        }

        function clearChat() {
            const chatContainer = document.getElementById('chatContainer');
            
            // Animation √©labor√©e de sortie
            chatContainer.style.transition = 'all 0.4s cubic-bezier(0.4, 0, 1, 1)';
            chatContainer.style.opacity = '0';
            chatContainer.style.transform = 'scale(0.95) translateY(20px)';
            
            setTimeout(() => {
                chatContainer.innerHTML = `
                    <div class="message assistant-message" style="opacity: 0; transform: translateY(20px);">
                        <div style="display: flex; align-items: center; gap: 12px; margin-bottom: 16px;">
                            <span style="font-size: 48px; filter: drop-shadow(0 2px 8px rgba(0, 133, 63, 0.3));">üá∏üá≥</span>
                            <div>
                                <div style="font-size: 1.3em; font-weight: 700; color: var(--senegal-green); margin-bottom: 4px;">
                                    Bienvenue sur LexFin
                                </div>
                                <div style="font-size: 0.95em; color: #64748b; font-weight: 500;">
                                    Assistant IA d√©di√© √† la fiscalit√©
                                </div>
                            </div>
                        </div>
                        
                        <div style="background: linear-gradient(135deg, rgba(0, 133, 63, 0.08) 0%, rgba(254, 239, 66, 0.08) 100%); 
                                    padding: 16px; border-radius: 12px; margin-bottom: 16px; 
                                    border-left: 4px solid var(--senegal-green);">
                            <div style="font-weight: 700; color: var(--senegal-green); margin-bottom: 8px; display: flex; align-items: center; gap: 8px;">
                                <span style="font-size: 1.1em;">‚ö°</span> Mode RAG Strict Activ√©
                            </div>
                            <div style="font-size: 0.9em; color: #475569; line-height: 1.6;">
                                R√©ponses exclusivement bas√©es sur les documents fiscaux officiels index√©s
                            </div>
                        </div>
                        
                        <div style="margin-bottom: 16px;">
                            <div style="font-weight: 700; color: #1e293b; margin-bottom: 12px; font-size: 1.05em;">
                                üìö Domaines d'Expertise
                            </div>
                            <div style="display: grid; gap: 8px; margin-left: 8px;">
                                <div style="display: flex; align-items: start; gap: 8px;">
                                    <span style="color: var(--senegal-green); font-weight: 700;">‚úì</span>
                                    <span style="line-height: 1.5;">Code G√©n√©ral des Imp√¥ts (CGI) du S√©n√©gal</span>
                                </div>
                                <div style="display: flex; align-items: start; gap: 8px;">
                                    <span style="color: var(--senegal-green); font-weight: 700;">‚úì</span>
                                    <span style="line-height: 1.5;">Code des Douanes de la R√©publique du S√©n√©gal</span>
                                </div>
                                <div style="display: flex; align-items: start; gap: 8px;">
                                    <span style="color: var(--senegal-green); font-weight: 700;">‚úì</span>
                                    <span style="line-height: 1.5;">Textes fiscaux et r√©glementations douani√®res officielles</span>
                                </div>
                            </div>
                        </div>
                        
                        <div style="background: linear-gradient(135deg, rgba(254, 239, 66, 0.1) 0%, rgba(255, 255, 255, 0.5) 100%); 
                                    padding: 14px; border-radius: 12px; border: 2px solid rgba(254, 239, 66, 0.3);">
                            <div style="font-weight: 700; color: #854d0e; margin-bottom: 10px; display: flex; align-items: center; gap: 8px;">
                                <span style="font-size: 1.1em;">üí°</span> Exemples de Questions
                            </div>
                            <div style="display: grid; gap: 6px; font-size: 0.9em; color: #475569; margin-left: 8px;">
                                <div style="line-height: 1.5;">‚Ä¢ "Que dit l'article 45 du code g√©n√©ral des imp√¥ts ?"</div>
                                <div style="line-height: 1.5;">‚Ä¢ "Quel est le taux de la TVA au S√©n√©gal ?"</div>
                                <div style="line-height: 1.5;">‚Ä¢ "Comment calculer l'imp√¥t minimum forfaitaire ?"</div>
                                <div style="line-height: 1.5;">‚Ä¢ "Quelles sont les conditions d'exon√©ration de droits de douane ?"</div>
                                <div style="line-height: 1.5;">‚Ä¢ "Qu'est-ce que le r√©gime de l'entrep√¥t de stockage ?"</div>
                                <div style="line-height: 1.5;">‚Ä¢ "Comment fonctionne la proc√©dure de d√©douanement ?"</div>
                            </div>
                        </div>
                        
                        <div style="margin-top: 16px; padding-top: 16px; border-top: 2px solid rgba(0, 133, 63, 0.1); 
                                    text-align: center; color: var(--senegal-green); font-weight: 600; font-size: 1.05em;">
                            üöÄ Pr√™t √† r√©pondre √† vos questions fiscales et douani√®res !
                        </div>
                    </div>
                `;
                
                // Animation √©labor√©e d'entr√©e avec rebond
                setTimeout(() => {
                    chatContainer.style.transition = 'all 0.8s cubic-bezier(0.68, -0.55, 0.265, 1.55)';
                    chatContainer.style.opacity = '1';
                    chatContainer.style.transform = 'scale(1) translateY(0)';
                    
                    const welcomeMsg = chatContainer.querySelector('.message');
                    if (welcomeMsg) {
                        welcomeMsg.style.transition = 'all 0.8s cubic-bezier(0.68, -0.55, 0.265, 1.55)';
                        welcomeMsg.style.opacity = '1';
                        welcomeMsg.style.transform = 'translateY(0)';
                    }
                    
                    addMessageEffects();
                    try { chatContainer.dispatchEvent(new Event('scroll')); } catch (e) {}
                }, 50);
            }, 400);
        }

        // Effets au survol des messages avec tracking de souris
        function addMessageEffects() {
            const messages = document.querySelectorAll('.message');
            messages.forEach(message => {
                // Effet de survol avec transformation fluide
                message.addEventListener('mouseenter', function(e) {
                    const isUser = this.classList.contains('user-message');
                    if (isUser) {
                        this.style.transform = 'translateX(-8px) scale(1.02)';
                    } else {
                        this.style.transform = 'translateX(8px) scale(1.02)';
                    }
                });
                
                message.addEventListener('mouseleave', function() {
                    this.style.transform = 'translateX(0) scale(1)';
                });

                // Tracking de position de souris pour effet radial
                message.addEventListener('mousemove', function(e) {
                    const rect = this.getBoundingClientRect();
                    const x = ((e.clientX - rect.left) / rect.width) * 100;
                    const y = ((e.clientY - rect.top) / rect.height) * 100;
                    this.style.setProperty('--mouse-x', x + '%');
                    this.style.setProperty('--mouse-y', y + '%');
                });
            });
        }

        // Ajouter des particules d√©coratives au header
        function addHeaderParticles() {
            const header = document.querySelector('.chat-header');
            if (!header || header.querySelector('.particle')) return;

            for (let i = 0; i < 8; i++) {
                const particle = document.createElement('div');
                particle.className = 'particle';
                particle.style.left = Math.random() * 100 + '%';
                particle.style.top = Math.random() * 100 + '%';
                particle.style.animationDelay = Math.random() * 4 + 's';
                particle.style.animationDuration = (3 + Math.random() * 3) + 's';
                header.appendChild(particle);
            }
        }

        // Effet de frappe pour les r√©ponses
        function typewriterEffect(element, text, speed = 30) {
            element.textContent = '';
            let i = 0;
            const timer = setInterval(() => {
                if (i < text.length) {
                    element.textContent += text.charAt(i);
                    i++;
                } else {
                    clearInterval(timer);
                }
            }, speed);
        }

        // Ajouter une section de r√©f√©rences avec liens
        function addReferencesSection(messageElement, references) {
            const referencesDiv = document.createElement('div');
            referencesDiv.style.cssText = `
                margin-top: 15px;
                padding: 12px;
                background: rgba(102, 126, 234, 0.1);
                border-left: 3px solid #667eea;
                border-radius: 8px;
                font-size: 13px;
            `;
            
            referencesDiv.innerHTML = '<strong> R√©f√©rences pr√©cises :</strong>';
            
            references.forEach((ref, index) => {
                const refItem = document.createElement('div');
                refItem.style.cssText = `
                    margin: 8px 0;
                    padding: 8px;
                    background: rgba(255, 255, 255, 0.7);
                    border-radius: 5px;
                    cursor: pointer;
                    transition: all 0.2s ease;
                `;
                
                refItem.innerHTML = `
                    <div style="font-weight: 600; color: #667eea;"> ${ref.file_name}</div>
                    <div style="color: #666; margin: 4px 0;">
                         ${ref.page_info} ‚Ä¢ ${ref.location}
                    </div>
                    <div style="color: #888; font-size: 12px; font-style: italic;">
                        "${ref.snippet}"
                    </div>
                    <div style="margin-top: 5px;">
                        <button onclick="openFile('${ref.file_path}', ${ref.line_start}, '${ref.page_info || ''}')" 
                                style="background: #667eea; color: white; border: none; padding: 4px 8px; border-radius: 4px; font-size: 11px; cursor: pointer;">
                             Ouvrir √† cette position
                        </button>
                    </div>
                `;
                
                refItem.addEventListener('mouseenter', function() {
                    this.style.background = 'rgba(102, 126, 234, 0.2)';
                    this.style.transform = 'translateX(5px)';
                });
                
                refItem.addEventListener('mouseleave', function() {
                    this.style.background = 'rgba(255, 255, 255, 0.7)';
                    this.style.transform = 'translateX(0)';
                });
                
                referencesDiv.appendChild(refItem);
            });
            
            messageElement.appendChild(referencesDiv);
            // Mise √† jour scroll apr√®s ajout des r√©f√©rences
            const container = document.getElementById('chatContainer');
            try { container.dispatchEvent(new Event('scroll')); } catch (e) {}
        }

        // Fonction pour ouvrir un fichier √† une position sp√©cifique
        async function openFile(filePath, lineNumber, pageInfo = '') {
            try {
                const response = await fetch('/open_file', {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json',
                    },
                    body: JSON.stringify({
                        file_path: filePath,
                        line_number: lineNumber,
                        page_info: pageInfo
                    })
                });

                const data = await response.json();
                
                if (data.success) {
                    // Ouvrir le fichier dans un nouvel onglet
                    window.open(data.file_url, '_blank');
                    
                    // Animation de succ√®s
                    const btn = event.target;
                    const originalText = btn.textContent;
                    btn.textContent = '‚úì Ouvert!';
                    btn.style.background = '#27ae60';
                    
                    setTimeout(() => {
                        btn.textContent = originalText;
                        btn.style.background = '#667eea';
                    }, 2000);
                } else {
                    alert('Impossible d\\'ouvrir le fichier: ' + data.error);
                }
            } catch (error) {
                alert('Erreur lors de l\\'ouverture du fichier');
                console.error('Erreur ouverture fichier:', error);
            }
        }

        // Initialisation au chargement avec animations √©l√©gantes
        window.onload = function() {
            addMessageEffects();
            addHeaderParticles();
            
            // Focus automatique sur l'input avec animation
            const messageInput = document.getElementById('messageInput');
            setTimeout(() => {
                messageInput.focus();
                messageInput.style.animation = 'inputFocus 0.5s ease';
            }, 800);
            
            // Animation d'entr√©e en cascade
            const container = document.querySelector('.container');
            const chatHeader = document.querySelector('.chat-header');
            const chatContainer = document.getElementById('chatContainer');
            const inputSection = document.querySelector('.chat-input-section');
            
            // √âtats initiaux
            container.style.opacity = '0';
            chatHeader.style.opacity = '0';
            chatHeader.style.transform = 'translateY(-30px)';
            chatContainer.style.opacity = '0';
            chatContainer.style.transform = 'translateY(20px)';
            inputSection.style.opacity = '0';
            inputSection.style.transform = 'translateY(30px)';
            
            // Animations en cascade
            setTimeout(() => {
                container.style.transition = 'opacity 0.6s ease';
                container.style.opacity = '1';
                
                setTimeout(() => {
                    chatHeader.style.transition = 'all 0.8s cubic-bezier(0.68, -0.55, 0.265, 1.55)';
                    chatHeader.style.opacity = '1';
                    chatHeader.style.transform = 'translateY(0)';
                }, 100);
                
                setTimeout(() => {
                    chatContainer.style.transition = 'all 0.8s cubic-bezier(0.4, 0, 0.2, 1)';
                    chatContainer.style.opacity = '1';
                    chatContainer.style.transform = 'translateY(0)';
                }, 300);
                
                setTimeout(() => {
                    inputSection.style.transition = 'all 0.8s cubic-bezier(0.68, -0.55, 0.265, 1.55)';
                    inputSection.style.opacity = '1';
                    inputSection.style.transform = 'translateY(0)';
                }, 500);
            }, 100);
        };

        // ====== THEME (clair/sombre) ======
        function updateThemeIcon() {
            const toggle = document.getElementById('themeToggle');
            if (!toggle) return;
            const isDark = document.body.classList.contains('dark-mode');
            toggle.innerHTML = isDark
                ? '<i class="fa-solid fa-sun"></i>'
                : '<i class="fa-solid fa-moon"></i>';
        }

        function toggleTheme() {
            document.body.classList.toggle('dark-mode');
            const isDark = document.body.classList.contains('dark-mode');
            localStorage.setItem('srmt_theme', isDark ? 'dark' : 'light');
            updateThemeIcon();
        }

        // ====== FONCTIONS BOUTONS CHATGPT ======

        // Ajouter les boutons aux messages existants et nouveaux
        function addChatButtons() {
            const messages = document.querySelectorAll('.message');
            messages.forEach(message => {
                if (message.querySelector('.message-actions')) return;
                
                const actionsDiv = document.createElement('div');
                actionsDiv.className = 'message-actions';
                
                if (message.classList.contains('user-message')) {
                    actionsDiv.innerHTML = `
                        <button class="message-btn edit" onclick="editMessage(this)">‚úèÔ∏è Modifier</button>
                        <button class="message-btn copy" onclick="copyMessage(this)">üìã Copier</button>
                    `;
                } else if (message.classList.contains('assistant-message')) {
                    actionsDiv.innerHTML = `
                        <button class="message-btn regenerate" onclick="regenerateMessage(this)"> R√©g√©n√©rer</button>
                        <button class="message-btn copy" onclick="copyMessage(this)"> Copier</button>
                    `;
                }
                
                message.appendChild(actionsDiv);
            });
        }

        // Modifier un message
        function editMessage(btn) {
            console.log(' Bouton modifier cliqu√©');
            
            const message = btn.closest('.message');
            if (!message) {
                console.error(' Message parent non trouv√©');
                alert('Erreur: Message non trouv√©');
                return;
            }
            
            console.log(' Message trouv√©:', message);
            
            // Extraire le texte (plusieurs m√©thodes)
            let text = '';
            
            // M√©thode 1: Premier n≈ìud texte
            if (message.childNodes[0] && message.childNodes[0].textContent) {
                text = message.childNodes[0].textContent.trim();
                console.log(' Texte m√©thode 1:', text);
            }
            
            // M√©thode 2: Span avec effet de frappe
            if (!text && message.querySelector('span')) {
                text = message.querySelector('span').textContent.trim();
                console.log(' Texte m√©thode 2 (span):', text);
            }
            
            // M√©thode 3: Tout le texte moins les boutons
            if (!text) {
                const clone = message.cloneNode(true);
                const actionsDiv = clone.querySelector('.message-actions');
                if (actionsDiv) actionsDiv.remove();
                text = clone.textContent.trim();
                console.log(' Texte m√©thode 3 (clone):', text);
            }
            
            if (!text) {
                console.error(' Aucun texte extrait');
                alert('Erreur: Impossible d\\'extraire le texte du message');
                return;
            }
            
            console.log(' Texte final √† √©diter:', text);
            
            // Ouvrir le modal
            const modal = document.getElementById('editModal');
            const textarea = document.getElementById('editTextarea');
            
            if (!modal || !textarea) {
                console.error(' √âl√©ments du modal non trouv√©s', {modal, textarea});
                alert('Erreur: Modal ou textarea non trouv√©');
                return;
            }
            
            textarea.value = text;
            modal.classList.add('show');
            modal.messageElement = message;
            
            // Focus sur la textarea
            setTimeout(() => {
                textarea.focus();
                textarea.setSelectionRange(textarea.value.length, textarea.value.length);
            }, 100);
            
            console.log(' Modal ouvert avec succ√®s');
        }

        // Fermer le modal
        function closeEditModal() {
            console.log(' Fermeture du modal d\\'√©dition');
            const modal = document.getElementById('editModal');
            if (modal) {
                modal.classList.remove('show');
                console.log(' Modal ferm√©');
            } else {
                console.error(' Modal non trouv√© pour fermeture');
            }
        }

        // Sauvegarder le message modifi√©
        function saveEditMessage() {
            console.log(' Sauvegarde du message modifi√©');
            
            const modal = document.getElementById('editModal');
            const textarea = document.getElementById('editTextarea');
            
            if (!modal || !textarea) {
                console.error(' √âl√©ments manquants', {modal, textarea});
                alert('Erreur: √âl√©ments du modal manquants');
                return;
            }
            
            const newText = textarea.value.trim();
            console.log(' Nouveau texte:', newText);
            
            if (!newText) {
                console.log(' Texte vide, abandon');
                alert('Veuillez saisir un message');
                return;
            }
            
            const messageElement = modal.messageElement;
            if (!messageElement) {
                console.error(' Message element manquant');
                alert('Erreur: Message √† modifier non trouv√©');
                return;
            }
            
            console.log(' Suppression des messages √† partir de:', messageElement);
            
            closeEditModal();
            
            // Supprimer les messages √† partir de celui modifi√©
            const chatContainer = document.getElementById('chatContainer');
            const messages = Array.from(chatContainer.children);
            const messageIndex = messages.indexOf(messageElement);
            
            console.log(` Index du message: ${messageIndex}, Total messages: ${messages.length}`);
            
            for (let i = messages.length - 1; i >= messageIndex; i--) {
                if (messages[i] && messages[i].classList && messages[i].classList.contains('message')) {
                    console.log(` Suppression message ${i}`);
                    chatContainer.removeChild(messages[i]);
                }
            }
            
            // Renvoyer le nouveau message
            console.log(' Envoi du nouveau message:', newText);
            const messageInput = document.getElementById('messageInput');
            messageInput.value = newText;
            sendMessage();
        }

        // R√©g√©n√©rer une r√©ponse
        function regenerateMessage(btn) {
            const assistantMsg = btn.closest('.message');
            let userMsg = assistantMsg.previousElementSibling;
            
            while (userMsg && !userMsg.classList.contains('user-message')) {
                userMsg = userMsg.previousElementSibling;
            }
            
            if (userMsg) {
                const userText = userMsg.childNodes[0].textContent || userMsg.querySelector('span')?.textContent || '';
                assistantMsg.remove();
                document.getElementById('messageInput').value = userText.trim();
                sendMessage();
            }
        }

        // Copier un message
        function copyMessage(btn) {
            const message = btn.closest('.message');
            const text = message.childNodes[0].textContent || message.querySelector('span')?.textContent || '';
            
            navigator.clipboard.writeText(text.trim()).then(() => {
                const originalText = btn.innerHTML;
                btn.innerHTML = '‚úÖ Copi√©!';
                btn.style.background = 'rgba(34, 197, 94, 0.1)';
                btn.style.color = '#22c55e';
                
                setTimeout(() => {
                    btn.innerHTML = originalText;
                    btn.style.background = '';
                    btn.style.color = '';
                }, 2000);
            }).catch(() => alert('Erreur de copie'));
        }

        // ====== SYST√àME DE M√âMOIRE DES CONVERSATIONS ======
        
        // Gestionnaire de m√©moire des conversations
        class ConversationMemory {
            constructor() {
                this.currentConversationId = null;
                this.conversations = this.loadConversations();
                this.autoSaveEnabled = true;
            }
            
            // Charger toutes les conversations depuis localStorage
            loadConversations() {
                try {
                    const saved = localStorage.getItem('srmt_conversations');
                    return saved ? JSON.parse(saved) : {};
                } catch (e) {
                    console.error('‚ùå Erreur chargement conversations:', e);
                    return {};
                }
            }
            
            // Sauvegarder toutes les conversations
            saveConversations() {
                try {
                    localStorage.setItem('srmt_conversations', JSON.stringify(this.conversations));
                    console.log('üíæ Conversations sauvegard√©es');
                } catch (e) {
                    console.error('‚ùå Erreur sauvegarde conversations:', e);
                }
            }
            
            // Cr√©er une nouvelle conversation
            createNewConversation() {
                const id = 'conv_' + Date.now() + '_' + Math.random().toString(36).substr(2, 9);
                const conversation = {
                    id: id,
                    title: 'Nouvelle conversation',
                    messages: [],
                    createdAt: new Date().toISOString(),
                    updatedAt: new Date().toISOString()
                };
                
                this.conversations[id] = conversation;
                this.currentConversationId = id;
                this.saveConversations();
                
                console.log('üÜï Nouvelle conversation cr√©√©e:', id);
                return id;
            }
            
            // Sauvegarder la conversation actuelle
            saveCurrentConversation() {
                if (!this.currentConversationId || !this.autoSaveEnabled) return;
                
                const chatContainer = document.getElementById('chatContainer');
                const messages = [];
                
                chatContainer.querySelectorAll('.message').forEach(msg => {
                    const isUser = msg.classList.contains('user-message');
                    let text = '';
                    
                    // Extraire le texte proprement
                    const span = msg.querySelector('span');
                    if (span && span.textContent.trim()) {
                        text = span.textContent.trim();
                    } else if (msg.childNodes[0] && msg.childNodes[0].textContent) {
                        text = msg.childNodes[0].textContent.trim();
                    } else {
                        const clone = msg.cloneNode(true);
                        const actions = clone.querySelector('.message-actions');
                        if (actions) actions.remove();
                        text = clone.textContent.trim();
                    }
                    
                    if (text && !text.includes('üá∏üá≥ Bonjour ! Je suis LexFin')) {
                        messages.push({
                            type: isUser ? 'user' : 'assistant',
                            content: text,
                            timestamp: new Date().toISOString()
                        });
                    }
                });
                
                if (this.conversations[this.currentConversationId]) {
                    this.conversations[this.currentConversationId].messages = messages;
                    this.conversations[this.currentConversationId].updatedAt = new Date().toISOString();
                    
                    // G√©n√©rer un titre automatique bas√© sur le premier message
                    if (messages.length > 0 && this.conversations[this.currentConversationId].title === 'Nouvelle conversation') {
                        const firstUserMsg = messages.find(m => m.type === 'user');
                        if (firstUserMsg) {
                            this.conversations[this.currentConversationId].title = 
                                firstUserMsg.content.substring(0, 50) + (firstUserMsg.content.length > 50 ? '...' : '');
                        }
                    }
                    
                    this.saveConversations();
                    console.log('üíæ Conversation sauvegard√©e:', this.currentConversationId);
                }
            }
            
            // Charger une conversation sp√©cifique
            loadConversation(conversationId) {
                if (!this.conversations[conversationId]) {
                    console.error('‚ùå Conversation non trouv√©e:', conversationId);
                    return;
                }
                
                this.currentConversationId = conversationId;
                const conversation = this.conversations[conversationId];
                const chatContainer = document.getElementById('chatContainer');
                
                // Vider le chat actuel
                chatContainer.innerHTML = '';
                
                // Restaurer les messages
                conversation.messages.forEach(msg => {
                    const messageDiv = document.createElement('div');
                    messageDiv.className = `message ${msg.type === 'user' ? 'user-message' : 'assistant-message'}`;
                    
                    if (msg.type === 'assistant') {
                        const span = document.createElement('span');
                        span.textContent = msg.content;
                        messageDiv.appendChild(span);
                    } else {
                        messageDiv.textContent = msg.content;
                    }
                    
                    chatContainer.appendChild(messageDiv);
                });
                
                // Ajouter les boutons aux messages restaur√©s
                setTimeout(() => {
                    addChatButtons();
                    chatContainer.scrollTop = chatContainer.scrollHeight;
                }, 100);
                
                console.log('üìÇ Conversation charg√©e:', conversationId, conversation.title);
            }
            
            // Supprimer une conversation
            deleteConversation(conversationId) {
                if (this.conversations[conversationId]) {
                    delete this.conversations[conversationId];
                    this.saveConversations();
                    
                    if (this.currentConversationId === conversationId) {
                        this.currentConversationId = null;
                        clearChat();
                    }
                    
                    console.log('üóëÔ∏è Conversation supprim√©e:', conversationId);
                }
            }
            
            // Obtenir la liste des conversations tri√©es
            getConversationsList() {
                return Object.values(this.conversations)
                    .sort((a, b) => new Date(b.updatedAt) - new Date(a.updatedAt));
            }
        }
        
        // Instance globale du gestionnaire de m√©moire
        const conversationMemory = new ConversationMemory();
        
        // Fonctions globales pour la gestion des conversations
        function startNewConversation() {
            console.log('üÜï D√©marrage nouvelle conversation');
            conversationMemory.createNewConversation();
            clearChat();
            updateConversationsUI();
        }
        
        function saveCurrentConversation() {
            conversationMemory.saveCurrentConversation();
            updateConversationsUI();
        }
        
        function loadConversation(conversationId) {
            console.log('üìÇ Chargement conversation:', conversationId);
            conversationMemory.loadConversation(conversationId);
            updateConversationsUI();
        }
        
        function deleteConversation(conversationId) {
            if (confirm('√ätes-vous s√ªr de vouloir supprimer cette conversation ?')) {
                conversationMemory.deleteConversation(conversationId);
                updateConversationsUI();
            }
        }
        
        function toggleConversationsPanel() {
            const panel = document.getElementById('conversationsPanel');
            if (panel) {
                const isOpen = panel.classList.contains('show');
                if (isOpen) {
                    panel.classList.remove('show');
                    setTimeout(() => {
                        panel.style.display = 'none';
                    }, 400);
                } else {
                    panel.style.display = 'flex';
                    setTimeout(() => {
                        panel.classList.add('show');
                        updateConversationsUI();
                    }, 10);
                }
            }
        }
        
        function updateConversationsUI() {
            const conversationsList = document.getElementById('conversationsList');
            if (!conversationsList) return;
            
            const conversations = conversationMemory.getConversationsList();
            
            conversationsList.innerHTML = conversations.map(conv => `
                <div class="conversation-item ${conv.id === conversationMemory.currentConversationId ? 'active' : ''}" 
                     onclick="loadConversation('${conv.id}')">
                    <div class="conversation-title">${conv.title}</div>
                    <div class="conversation-meta">
                        <span class="conversation-date">${new Date(conv.updatedAt).toLocaleDateString('fr-FR')}</span>
                        <button class="conversation-delete" onclick="event.stopPropagation(); deleteConversation('${conv.id}')">üóëÔ∏è</button>
                    </div>
                </div>
            `).join('');
        }

        // Ajouter les boutons au chargement et apr√®s chaque message
        document.addEventListener('DOMContentLoaded', () => {
            setTimeout(addChatButtons, 500);
            
            // Initialiser la m√©moire des conversations
            if (!conversationMemory.currentConversationId) {
                conversationMemory.createNewConversation();
            }
            updateConversationsUI();
            
            // G√©rer les touches dans le modal
            document.addEventListener('keydown', (e) => {
                const modal = document.getElementById('editModal');
                if (modal && modal.classList.contains('show')) {
                    if (e.key === 'Escape') {
                        console.log('‚å®Ô∏è Touche √âchap - Fermeture modal');
                        closeEditModal();
                        e.preventDefault();
                    } else if (e.key === 'Enter' && e.ctrlKey) {
                        console.log('‚å®Ô∏è Ctrl+Entr√©e - Sauvegarde modal');
                        saveEditMessage();
                        e.preventDefault();
                    }
                }
            });

            // Appliquer le th√®me sauvegard√©
            const savedTheme = localStorage.getItem('srmt_theme') || 'light';
            if (savedTheme === 'dark') {
                document.body.classList.add('dark-mode');
            }
            const themeToggle = document.getElementById('themeToggle');
            if (themeToggle) {
                updateThemeIcon();
                themeToggle.addEventListener('click', toggleTheme);
            }

            // Gestion du bouton "aller en bas"
            const chatContainer = document.getElementById('chatContainer');
            const scrollBtn = document.getElementById('scrollBottom');
            if (chatContainer && scrollBtn) {
                const updateScrollBtn = () => {
                    const delta = chatContainer.scrollHeight - chatContainer.scrollTop - chatContainer.clientHeight;
                    const nearBottom = delta < 80;
                    if (nearBottom) {
                        scrollBtn.classList.remove('visible');
                    } else {
                        scrollBtn.classList.add('visible');
                    }
                };
                chatContainer.addEventListener('scroll', updateScrollBtn);
                scrollBtn.addEventListener('click', () => {
                    chatContainer.scrollTo({ top: chatContainer.scrollHeight, behavior: 'smooth' });
                });
                // Initial state
                setTimeout(updateScrollBtn, 300);
            }
        });




    </script>
    
    <!-- Footer LexFin avec drapeau anim√© -->
    <div class="srmt-footer" style="position: fixed; bottom: 20px; right: 25px; 
                color: white; font-size: 13px; font-weight: 600;
                background: linear-gradient(135deg, var(--senegal-green) 0%, #006838 100%);
                padding: 12px 24px; 
                border-radius: 30px; 
                backdrop-filter: blur(15px);
                border: 2px solid rgba(254, 239, 66, 0.3);
                box-shadow: 0 8px 28px rgba(0, 133, 63, 0.4);
                z-index: 999;
                transition: all 0.4s cubic-bezier(0.68, -0.55, 0.265, 1.55);
                display: flex;
                align-items: center;
                gap: 10px;">
        <span style="font-size: 20px; animation: wave 2s ease-in-out infinite;">üá∏üá≥</span>
        <span style="text-shadow: 0 2px 4px rgba(0, 0, 0, 0.3);">
            Powered by <strong style="color: var(--senegal-yellow); text-shadow: 0 0 10px rgba(254, 239, 66, 0.5);">ACCEL-TECH</strong>
        </span>
    </div>
    
    <style>
        .srmt-footer:hover {
            transform: translateY(-4px) scale(1.05);
            box-shadow: 0 12px 40px rgba(0, 133, 63, 0.6);
            border-color: var(--senegal-yellow);
        }
        
        @keyframes wave {
            0%, 100% { transform: rotate(-5deg); }
            50% { transform: rotate(5deg); }
        }
        
        @media (max-width: 768px) {
            .srmt-footer {
                bottom: 10px;
                right: 10px;
                font-size: 11px;
                padding: 8px 16px;
            }
        }
    </style>
</body>
</html>
"""

# Application Flask
app = Flask(__name__)

# Configuration CORS pour permettre l'int√©gration dans d'autres sites web
@app.after_request
def after_request(response):
    response.headers.add('Access-Control-Allow-Origin', '*')
    response.headers.add('Access-Control-Allow-Headers', 'Content-Type,Authorization')
    response.headers.add('Access-Control-Allow-Methods', 'GET,PUT,POST,DELETE,OPTIONS')
    return response

lexfin_client = LexFinClient()

@app.route('/')
def home():
    """Page d'accueil"""
    return render_template_string(HTML_TEMPLATE)

@app.route('/chat', methods=['POST'])
def chat():
    """Endpoint pour le chat avec r√©f√©rences pr√©cises et gestion des conversations"""
    try:
        data = request.get_json()
        message = data.get('message', '')
        conversation_id = data.get('conversation_id', None)  # ID de conversation optionnel
        
        if not message:
            return jsonify({
                'response': 'Veuillez saisir un message.',
                'references': []
            }), 400
        
        # Transmettre le conversation_id √† la m√©thode chat
        result = lexfin_client.chat(message, conversation_id=conversation_id)
        
        # üîß DEBUG: Log des r√©f√©rences pour diagnostiquer le probl√®me "undefined"
        references = result.get('references', [])
        logger.info(f"üîç DEBUG R√âF√âRENCES - Nombre: {len(references)}")
        for i, ref in enumerate(references[:3]):  # Log des 3 premi√®res
            logger.info(f"  Ref {i+1}:")
            logger.info(f"    file_name: '{ref.get('file_name', 'MISSING')}'")
            logger.info(f"    page_info: '{ref.get('page_info', 'MISSING')}'")
            logger.info(f"    location: '{ref.get('location', 'MISSING')}'")
            logger.info(f"    snippet: '{ref.get('snippet', 'MISSING')[:50]}...'")
        
        return jsonify({
            'response': result.get('response', ''),
            'references': references,
            'conversation_id': conversation_id  # Retourner l'ID de conversation
        })
        
    except Exception as e:
        logger.error(f"Erreur chat endpoint: {e}")
        return jsonify({
            'response': 'Une erreur s\'est produite.',
            'references': []
        }), 500

@app.route('/conversation/new', methods=['POST'])
def new_conversation():
    """Cr√©er une nouvelle conversation"""
    try:
        data = request.get_json() or {}
        title = data.get('title', 'Nouvelle conversation')
        
        conversation_id = lexfin_client.conversation_manager.create_conversation(title)
        
        return jsonify({
            'conversation_id': conversation_id,
            'title': title,
            'created_at': datetime.now().isoformat()
        })
        
    except Exception as e:
        logger.error(f"Erreur cr√©ation conversation: {e}")
        return jsonify({'error': 'Erreur lors de la cr√©ation de la conversation'}), 500

@app.route('/conversation/<conversation_id>/history', methods=['GET'])
def get_conversation_history(conversation_id):
    """R√©cup√©rer l'historique d'une conversation"""
    try:
        history = lexfin_client.conversation_manager.get_conversation_history(conversation_id)
        
        if history is None:
            return jsonify({'error': 'Conversation non trouv√©e'}), 404
        
        return jsonify({
            'conversation_id': conversation_id,
            'messages': history
        })
        
    except Exception as e:
        logger.error(f"Erreur r√©cup√©ration historique: {e}")
        return jsonify({'error': 'Erreur lors de la r√©cup√©ration de l\'historique'}), 500

@app.route('/conversations', methods=['GET'])
def list_conversations():
    """Lister toutes les conversations"""
    try:
        conversations = lexfin_client.conversation_manager.list_conversations()
        
        return jsonify({
            'conversations': conversations
        })
        
    except Exception as e:
        logger.error(f"Erreur liste conversations: {e}")
        return jsonify({'error': 'Erreur lors de la r√©cup√©ration des conversations'}), 500

@app.route('/conversation/<conversation_id>', methods=['DELETE'])
def delete_conversation(conversation_id):
    """Supprimer une conversation"""
    try:
        success = lexfin_client.conversation_manager.delete_conversation(conversation_id)
        
        if not success:
            return jsonify({'error': 'Conversation non trouv√©e'}), 404
        
        return jsonify({'message': 'Conversation supprim√©e avec succ√®s'})
        
    except Exception as e:
        logger.error(f"Erreur suppression conversation: {e}")
        return jsonify({'error': 'Erreur lors de la suppression de la conversation'}), 500

@app.route('/regenerate', methods=['POST'])
def regenerate():
    try:
        data = request.json
        message = data.get('message', '')
        
        if not message:
            return jsonify({'response': 'Message vide re√ßu.', 'references': []}), 400
        
        # Prompt de simplification en fran√ßais uniquement
        simplification_prompt = f"""üá´üá∑ LANGUE OBLIGATOIRE: Tu DOIS r√©pondre UNIQUEMENT en fran√ßais. Aucun mot en anglais ou autre langue n'est autoris√©.

Question √† simplifier: "{message}"

MISSION: Reformule cette question de mani√®re plus simple et claire, en fran√ßais uniquement:
- Utilise un vocabulaire accessible 
- Garde le sens original intact
- Raccourcis les phrases longues
- Supprime les mots inutiles
- Maximum 2 lignes
- R√©ponse UNIQUEMENT en fran√ßais

Reformulation simplifi√©e:"""

        # Appel √† Mistral pour simplification
        payload = {
            "model": lexfin_client.config.OLLAMA_CHAT_MODEL,
            "prompt": simplification_prompt,
            "stream": False
        }
        
        response = requests.post(
            f"{lexfin_client.config.OLLAMA_BASE_URL}/api/generate",
            json=payload,
            timeout=30
        )
        
        if response.status_code == 200:
            simplified_message = response.json()['response'].strip()
            
            # Traiter la question simplifi√©e avec le syst√®me normal
            result = lexfin_client.chat(simplified_message)
            
            return jsonify({
                'response': result.get('response', ''),
                'references': result.get('references', []),
                'simplified_question': simplified_message
            })
        else:
            # Si √©chec de simplification, relancer avec question originale
            result = lexfin_client.chat(message)
            
            return jsonify({
                'response': result.get('response', ''),
                'references': result.get('references', []),
                'simplified_question': message
            })
            
    except Exception as e:
        logger.error(f"Erreur regenerate endpoint: {e}")
        return jsonify({
            'response': 'Erreur lors de la r√©g√©n√©ration.',
            'references': []
        }), 500

@app.route('/open_file', methods=['POST'])
def open_file():
    """Endpoint pour ouvrir un fichier √† une position sp√©cifique via le navigateur"""
    try:
        data = request.get_json()
        file_path = data.get('file_path', '')
        line_number = data.get('line_number', 1)
        page_info = data.get('page_info', '')
        
        logger.info(f"üîß DEBUG open_file - file_path re√ßu: '{file_path}'")
        logger.info(f"üîß DEBUG open_file - line_number: {line_number}")
        logger.info(f"üîß DEBUG open_file - page_info: '{page_info}'")
        
        if not file_path:
            return jsonify({'error': 'Chemin de fichier manquant'}), 400
        
        # Extraire le nom du fichier - g√©rer les cas avec ou sans s√©parateur
        if '/' in file_path:
            filename = Path(file_path).name
        elif file_path.startswith('documents'):
            # Cas probl√©matique: "documentsSenegal-Code-des-impot.pdf"
            filename = file_path.replace('documents', '', 1)
        else:
            filename = file_path
            
        logger.info(f"üîß DEBUG open_file - filename extrait: '{filename}'")
        
        # V√©rifier que le fichier existe dans le r√©pertoire documents
        documents_dir = Path('./documents')
        target_file = documents_dir / filename
        
        if not target_file.exists():
            return jsonify({
                'error': f'Fichier non trouv√©: {filename}',
                'success': False
            }), 404
        
        # G√©n√©rer l'URL pour servir le fichier
        file_url = f'/files/{filename}'
        
        # Si on a des informations de page, les inclure
        page_fragment = ""
        if page_info and 'page' in page_info.lower():
            # Extraire le num√©ro de page de page_info (ex: "page 128" -> 128 ou "pages 194-195" -> 194)
            import re
            page_match = re.search(r'pages?\s+(\d+)', page_info.lower())
            if page_match:
                page_num = page_match.group(1)
                page_fragment = f"#page={page_num}"
                logger.info(f"üîß DEBUG open_file - page_info: '{page_info}' -> page_num: {page_num}")
            else:
                logger.info(f"üîß DEBUG open_file - Aucun num√©ro de page trouv√© dans: '{page_info}'")
        else:
            logger.info(f"üîß DEBUG open_file - page_info vide ou invalide: '{page_info}'")
        
        return jsonify({
            'message': f'Ouverture de {filename}',
            'success': True,
            'file_url': file_url + page_fragment,
            'filename': filename,
            'page_info': page_info,
            'line_number': line_number
        })
            
    except Exception as e:
        logger.error(f"Erreur open_file endpoint: {e}")
        return jsonify({'error': f'Erreur ouverture fichier: {str(e)}'}), 500

@app.route('/files/<filename>')
def serve_file(filename):
    """Sert les fichiers PDF depuis le r√©pertoire documents"""
    try:
        documents_dir = Path('./documents')
        file_path = documents_dir / filename
        
        if not file_path.exists():
            return jsonify({'error': f'Fichier non trouv√©: {filename}'}), 404
        
        if not filename.lower().endswith('.pdf'):
            return jsonify({'error': 'Seuls les fichiers PDF sont autoris√©s'}), 403
        
        # Servir le fichier PDF
        from flask import send_file
        return send_file(
            file_path,
            as_attachment=False,  # Pour affichage dans le navigateur
            mimetype='application/pdf'
        )
        
    except Exception as e:
        logger.error(f"Erreur service fichier {filename}: {e}")
        return jsonify({'error': f'Erreur service fichier: {str(e)}'}), 500

@app.route('/health', methods=['GET'])
def health_check():
    """V√©rifie la sant√© de la connexion Ollama"""
    try:
        # Test rapide de connexion Ollama
        test_response = requests.get(
            f"{lexfin_client.config.OLLAMA_BASE_URL}/api/tags",
            timeout=5
        )
        ollama_status = "üü¢ Connect√©" if test_response.status_code == 200 else "üü° R√©ponse inattendue"
    except:
        ollama_status = "üî¥ D√©connect√©"
    
    return jsonify({
        'ollama_status': ollama_status,
        'server_url': lexfin_client.config.OLLAMA_BASE_URL,
        'timestamp': time.strftime("%Y-%m-%d %H:%M:%S")
    })

@app.route('/status', methods=['GET'])
def get_status():
    """Endpoint pour obtenir le statut de l'indexation"""
    try:
        # V√©rifier le statut de la surveillance
        surveillance_status = "Inactive"
        auto_indexing = False
        if lexfin_client.observer:
            if lexfin_client.observer.is_alive():
                surveillance_status = "üîÑ Active (Auto-indexation ON)"
                auto_indexing = True
            else:
                surveillance_status = "‚è∏Ô∏è Arr√™t√©"
        
        # Lister les fichiers r√©cents non index√©s
        recent_files = []
        for file_path in lexfin_client.watch_dir.rglob('*'):
            if file_path.is_file() and lexfin_client.is_supported_file(str(file_path)):
                if not lexfin_client.is_file_already_indexed(str(file_path)):
                    recent_files.append(str(file_path))
        
        status = {
            'indexed_files_count': len(lexfin_client.indexed_files),
            'watch_directory': str(lexfin_client.watch_dir.absolute()),
            'supported_extensions': lexfin_client.config.SUPPORTED_EXTENSIONS,
            'indexed_files': [Path(f).name for f in lexfin_client.indexed_files.keys()],
            'non_indexed_files': [Path(f).name for f in recent_files],
            'surveillance_status': surveillance_status,
            'auto_indexing': auto_indexing
        }
        return jsonify(status)
    except Exception as e:
        logger.error(f"Erreur status endpoint: {e}")
        return jsonify({'error': 'Erreur r√©cup√©ration statut'}), 500

@app.route('/restart_watcher', methods=['POST'])
def restart_watcher():
    """Red√©marre la surveillance automatique des fichiers"""
    try:
        logger.info("üîÑ Red√©marrage manuel de la surveillance automatique...")
        
        # Red√©marrer la surveillance
        success = lexfin_client.start_file_watcher()
        
        if success:
            return jsonify({
                'message': 'Surveillance automatique red√©marr√©e avec succ√®s',
                'status': 'active',
                'watch_directory': str(lexfin_client.watch_dir)
            })
        else:
            return jsonify({
                'message': '√âchec du red√©marrage de la surveillance',
                'status': 'inactive',
                'error': 'Impossible de d√©marrer l\'observer'
            }), 500
            
    except Exception as e:
        logger.error(f"Erreur restart_watcher: {e}")
        return jsonify({'error': f'Erreur red√©marrage surveillance: {str(e)}'}), 500

@app.route('/force_check_new', methods=['POST'])
def force_check_new():
    """Force la v√©rification et indexation des nouveaux fichiers"""
    try:
        logger.info("üîç V√©rification manuelle des nouveaux fichiers...")
        
        new_files_indexed = 0
        for file_path in lexfin_client.watch_dir.rglob('*'):
            if file_path.is_file() and lexfin_client.is_supported_file(str(file_path)):
                if not lexfin_client.is_file_already_indexed(str(file_path)):
                    logger.info(f"üÜï Indexation nouveau fichier: {file_path.name}")
                    lexfin_client.index_file(str(file_path))
                    new_files_indexed += 1
        
        return jsonify({
            'message': f'{new_files_indexed} nouveaux fichiers index√©s',
            'total_indexed': len(lexfin_client.indexed_files)
        })
        
    except Exception as e:
        logger.error(f"Erreur check nouveaux fichiers: {e}")
        return jsonify({'error': str(e)}), 500

@app.route('/force_full_reindex', methods=['POST'])
def force_full_reindex():
    """Force la r√©indexation compl√®te de TOUS les fichiers (ignore le cache)"""
    try:
        # Diagnostic avant indexation
        logger.info(f"üîç R√âINDEXATION FORC√âE COMPL√àTE")
        
        # Lister tous les fichiers support√©s
        supported_files = []
        for file_path in lexfin_client.watch_dir.rglob('*'):
            if file_path.is_file() and lexfin_client.is_supported_file(str(file_path)):
                supported_files.append(str(file_path))
        
        # VIDER COMPL√àTEMENT le cache et ChromaDB
        lexfin_client.indexed_files.clear()
        try:
            if hasattr(lexfin_client, 'collection') and lexfin_client.collection:
                lexfin_client.create_vector_store()
                logger.info("üóëÔ∏è Base vectorielle et cache compl√®tement vid√©s")
        except Exception as e:
            logger.warning(f"  Erreur vidage: {e}")
        
        # Indexation compl√®te
        lexfin_client.scan_existing_files()
        
        return jsonify({
            'message': f'R√©indexation COMPL√àTE termin√©e: {len(supported_files)} fichiers retrait√©s',
            'indexed_count': len(lexfin_client.indexed_files),
            'files_found': len(supported_files),
            'cache_cleared': True
        })
    except Exception as e:
        logger.error(f"Erreur force_full_reindex: {e}")
        return jsonify({'error': 'Erreur r√©indexation compl√®te'}), 500

@app.route('/reindex', methods=['POST'])
def smart_reindex():
    """R√©indexation intelligente (respecte le cache des fichiers d√©j√† index√©s)"""
    try:
        # Diagnostic avant indexation
        logger.info(f"üîç Scan du dossier: {lexfin_client.config.WATCH_DIRECTORY}")
        
        # Lister tous les fichiers support√©s
        supported_files = []
        for file_path in lexfin_client.watch_dir.rglob('*'):
            if file_path.is_file() and lexfin_client.is_supported_file(str(file_path)):
                supported_files.append(str(file_path))
        
        logger.info(f"   {len(supported_files)} fichiers support√©s trouv√©s:")
        for file_path in supported_files:
            logger.info(f"   - {Path(file_path).name}")
        
        # Vider le cache ChromaDB compl√®tement
        try:
            if hasattr(lexfin_client, 'collection') and lexfin_client.collection:
                lexfin_client.create_vector_store()
                logger.info("üóëÔ∏è Base vectorielle vid√©e compl√®tement")
            else:
                logger.info("üîÑ Cr√©ation nouvelle base vectorielle")
                lexfin_client.create_vector_store()
        except Exception as e:
            logger.warning(f"  Erreur vidage base: {e}")
            # Fallback : cr√©er une nouvelle collection
            try:
                lexfin_client.create_vector_store()
            except Exception as e2:
                logger.error(f"  Erreur cr√©ation base: {e2}")
        
        # NE PAS vider le cache local - garder la m√©moire des fichiers index√©s
        # lexfin_client.indexed_files.clear()  # COMMENT√â pour √©viter r√©indexation
        
        # Relancer le scan avec respect du cache
        try:
            lexfin_client.scan_existing_files()
            already_indexed = len([f for f in supported_files if lexfin_client.is_file_already_indexed(f)])
            newly_indexed = len(lexfin_client.indexed_files) - already_indexed
            message = f'Scan termin√©: {already_indexed} d√©j√† index√©s, {newly_indexed} nouveaux fichiers trait√©s'
            logger.info(f"‚úÖ Indexation termin√©e: {len(lexfin_client.indexed_files)} fichiers au total")
        except Exception as e:
            logger.error(f"Erreur lors de l'indexation: {e}")
            message = f'R√©indexation √©chou√©e: V√©rifiez la connexion Ollama'
        
        return jsonify({
            'message': message,
            'indexed_count': len(lexfin_client.indexed_files),
            'files_found': len(supported_files),
            'files_list': [Path(f).name for f in supported_files[:5]]  # Top 5 files
        })
    except Exception as e:
        logger.error(f"Erreur reindex endpoint: {e}")
        return jsonify({'error': 'Erreur r√©indexation'}), 500

@app.route('/start_indexing', methods=['POST'])
def start_indexing():
    """D√©marre l'indexation initiale"""
    try:
        lexfin_client.scan_existing_files()
        return jsonify({
            'message': 'Indexation d√©marr√©e',
            'indexed_count': len(lexfin_client.indexed_files)
        })
    except Exception as e:
        logger.error(f"Erreur start_indexing: {e}")
        return jsonify({'error': f'Erreur indexation: {str(e)}'}), 500

@app.route('/diagnostic', methods=['GET'])
def diagnostic_files():
    """Diagnostic des fichiers index√©s"""
    try:
        # Lister tous les fichiers du dossier
        all_files = []
        supported_files = []
        indexed_files = list(lexfin_client.indexed_files.keys())
        
        for file_path in lexfin_client.watch_dir.rglob('*'):
            if file_path.is_file():
                all_files.append(str(file_path))
                if lexfin_client.is_supported_file(str(file_path)):
                    supported_files.append(str(file_path))
        
        # Compter les √©l√©ments dans ChromaDB avec diagnostic
        try:
            collection_count = lexfin_client.vector_store.count()
            logger.info(f"üìä ChromaDB count: {collection_count}")
        except Exception as e:
            logger.error(f"  Erreur ChromaDB count: {e}")
            collection_count = 0
            
        # V√©rifier la collection elle-m√™me
        try:
            # Essayer de r√©cup√©rer quelques documents pour tester
            test_results = lexfin_client.vector_store.peek(limit=5)
            actual_chunks = len(test_results.get('documents', []))
            logger.info(f"üîç Documents r√©els dans ChromaDB: {actual_chunks}")
            if actual_chunks > collection_count:
                collection_count = actual_chunks
        except Exception as e:
            logger.warning(f"  Erreur peek ChromaDB: {e}")
        
        return jsonify({
            'dossier_surveille': lexfin_client.config.WATCH_DIRECTORY,
            'fichiers_totaux': len(all_files),
            'fichiers_supportes': len(supported_files),
            'fichiers_indexes': len(indexed_files),
            'chunks_chromadb': collection_count,
            'liste_supportes': [Path(f).name for f in supported_files],
            'liste_indexes': [Path(f).name for f in indexed_files],
            'formats_supportes': ['.pdf', '.txt', '.docx', '.odt']
        })
    except Exception as e:
        logger.error(f"Erreur diagnostic: {e}")
        return jsonify({'error': f'Erreur diagnostic: {str(e)}'}), 500



@app.route('/debug_context', methods=['POST'])
def debug_context():
    """Debug endpoint pour voir le contexte r√©el"""
    try:
        data = request.get_json()
        query = data.get('query', '')
        
        if not query:
            return jsonify({'error': 'Query manquante'}), 400
        
        # Recherche avec debug
        context = lexfin_client.search_context(query, limit=3)
        
        # R√©cup√©rer aussi quelques documents de ChromaDB
        try:
            sample_docs = lexfin_client.collection.peek(limit=3)
            sample_content = sample_docs.get('documents', [])[:3] if sample_docs else []
        except:
            sample_content = []
        
        return jsonify({
            'query': query,
            'context_found': context,
            'context_length': len(context) if context else 0,
            'sample_documents': sample_content,
            'collection_count': lexfin_client.collection.count() if lexfin_client.collection else 0
        })
        
    except Exception as e:
        logger.error(f"Erreur debug_context: {e}")
        return jsonify({'error': f'Erreur: {str(e)}'}), 500

def cleanup():
    """Nettoyage √† la fermeture"""
    try:
        if hasattr(lexfin_client, 'observer') and lexfin_client.observer:
            lexfin_client.observer.stop()
            lexfin_client.observer.join()
            logger.info("üõë Surveillance arr√™t√©e proprement")
    except Exception as e:
        logger.error(f"Erreur lors de l'arr√™t: {e}")

def app_lexfin():
    """Lance l'application LexFin"""
    print("üá∏üá≥ D√©marrage de LexFin - Assistant Fiscal & Douanier S√©n√©gal...")
    print("=" * 70)
    print(f"üîó URL Ollama: {LexFinConfig.OLLAMA_BASE_URL}")
    print(f"ü§ñ Mod√®le IA: {LexFinConfig.OLLAMA_CHAT_MODEL}")
    print(f"üìÅ R√©pertoire surveill√©: {LexFinConfig.WATCH_DIRECTORY}")
    print("üèõÔ∏è Sp√©cialisation: Code des Imp√¥ts & Code des Douanes S√©n√©gal")
    print("üåê D√©marrage de l'interface web...")
    
    try:
        app.run(
            host="0.0.0.0",
            port=8505,
            debug=False
        )
    except KeyboardInterrupt:
        print("\nüëã Arr√™t de LexFin...")
        cleanup()
    except Exception as e:
        print(f"‚ùå Erreur: {e}")
        cleanup()

if __name__ == "__main__":
    import atexit
    atexit.register(cleanup)
    app_lexfin()
